{"nodes":[{"pos":[66,228],"content":"This topic shows how to use the FaceDetector to detect faces in an image. The FaceTracker is optimized for tracking faces over time in a sequence of video frames.","needQuote":true,"needEscape":true,"nodes":[{"content":"This topic shows how to use the FaceDetector to detect faces in an image. The FaceTracker is optimized for tracking faces over time in a sequence of video frames.","pos":[0,162],"nodes":[{"content":"This topic shows how to use the FaceDetector to detect faces in an image.","pos":[0,73]},{"content":"The FaceTracker is optimized for tracking faces over time in a sequence of video frames.","pos":[74,162]}]}]},{"pos":[236,268],"content":"Detect faces in images or videos","needQuote":true,"needEscape":true,"nodes":[{"content":"Detect faces in images or videos","pos":[0,32]}]},{"content":"Detect faces in images or videos","pos":[276,308]},{"content":"\\[ Updated for UWP apps on Windows 10.","pos":[310,348]},{"content":"For Windows 8.x articles, see the <bpt id=\"p1\">[</bpt>archive<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept> \\]","pos":[349,444],"source":" For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]"},{"content":"\\[Some information relates to pre-released product which may be substantially modified before it's commercially released.","pos":[447,568]},{"content":"Microsoft makes no warranties, express or implied, with respect to the information provided here.\\]","pos":[569,668]},{"content":"This topic shows how to use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FaceDetector<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> to detect faces in an image.","pos":[670,807],"source":"This topic shows how to use the [**FaceDetector**](https://msdn.microsoft.com/library/windows/apps/dn974129) to detect faces in an image."},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FaceTracker<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> is optimized for tracking faces over time in a sequence of video frames.","pos":[808,960],"source":" The [**FaceTracker**](https://msdn.microsoft.com/library/windows/apps/dn974150) is optimized for tracking faces over time in a sequence of video frames."},{"pos":[962,1177],"content":"For an alternative method of tracking faces using the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FaceDetectionEffect<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn948776)</ept>, see <bpt id=\"p3\">[</bpt>Scene analysis for media capture<ept id=\"p3\">](scene-analysis-for-media-capture.md)</ept>.","source":"For an alternative method of tracking faces using the [**FaceDetectionEffect**](https://msdn.microsoft.com/library/windows/apps/dn948776), see [Scene analysis for media capture](scene-analysis-for-media-capture.md)."},{"content":"The code in this article was adapted from the <bpt id=\"p1\">[</bpt>Basic Face Detection<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?LinkId=620512&amp;clcid=0x409)</ept> and <bpt id=\"p2\">[</bpt>Basic Face Tracking<ept id=\"p2\">](http://go.microsoft.com/fwlink/p/?LinkId=620513&amp;clcid=0x409)</ept> samples.","pos":[1179,1404],"source":"The code in this article was adapted from the [Basic Face Detection](http://go.microsoft.com/fwlink/p/?LinkId=620512&clcid=0x409) and [Basic Face Tracking](http://go.microsoft.com/fwlink/p/?LinkId=620513&clcid=0x409) samples."},{"content":"You can download these samples to see the code used in context or to use the sample as a starting point for your own app.","pos":[1405,1526]},{"content":"Detect faces in a single image","pos":[1531,1561]},{"pos":[1563,1706],"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FaceDetector<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> class allows you to detect one or more faces in a still image.","source":"The [**FaceDetector**](https://msdn.microsoft.com/library/windows/apps/dn974129) class allows you to detect one or more faces in a still image."},{"content":"This example uses APIs from the following namespaces.","pos":[1708,1761]},{"pos":[1773,1791],"content":"FaceDetectionUsing"},{"pos":[1869,2133],"content":"Declare a class member variable for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FaceDetector<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> object and for the list of <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>DetectedFace<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects that will be detected in the image.","source":"Declare a class member variable for the [**FaceDetector**](https://msdn.microsoft.com/library/windows/apps/dn974129) object and for the list of [**DetectedFace**](https://msdn.microsoft.com/library/windows/apps/dn974123) objects that will be detected in the image."},{"pos":[2145,2160],"content":"ClassVariables1"},{"content":"Face detection operates on a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SoftwareBitmap<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn887358)</ept> object which can be created in a variety of ways.","pos":[2235,2392],"source":"Face detection operates on a [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn887358) object which can be created in a variety of ways."},{"content":"In this example a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FileOpenPicker<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br207847)</ept> is used to allow the user to pick an image file in which faces will be detected.","pos":[2393,2570],"source":" In this example a [**FileOpenPicker**](https://msdn.microsoft.com/library/windows/apps/br207847) is used to allow the user to pick an image file in which faces will be detected."},{"content":"For more information on working with software bitmaps, see <bpt id=\"p1\">[</bpt>Imaging<ept id=\"p1\">](imaging.md)</ept>.","pos":[2571,2652],"source":" For more information on working with software bitmaps, see [Imaging](imaging.md)."},{"pos":[2664,2670],"content":"Picker"},{"content":"Use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>BitmapDecoder<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br226176)</ept> class to decode the image file into a <bpt id=\"p3\">**</bpt>SoftwareBitmap<ept id=\"p3\">**</ept>.","pos":[2736,2879],"source":"Use the [**BitmapDecoder**](https://msdn.microsoft.com/library/windows/apps/br226176) class to decode the image file into a **SoftwareBitmap**."},{"content":"The face detection process is quicker with a smaller image and so you may want to scale the source image down to a smaller size.","pos":[2880,3008]},{"content":"This can be performed during decoding by creating a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>BitmapTransform<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br226254)</ept> object, setting the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>ScaledWidth<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br226261)</ept> and <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>ScaledHeight<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br226260)</ept> properties and passing it into the call to <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>GetSoftwareBitmapAsync<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/dn887332)</ept>, which returns the decoded and scaled <bpt id=\"p9\">**</bpt>SoftwareBitmap<ept id=\"p9\">**</ept>.","pos":[3009,3505],"source":" This can be performed during decoding by creating a [**BitmapTransform**](https://msdn.microsoft.com/library/windows/apps/br226254) object, setting the [**ScaledWidth**](https://msdn.microsoft.com/library/windows/apps/br226261) and [**ScaledHeight**](https://msdn.microsoft.com/library/windows/apps/br226260) properties and passing it into the call to [**GetSoftwareBitmapAsync**](https://msdn.microsoft.com/library/windows/apps/dn887332), which returns the decoded and scaled **SoftwareBitmap**."},{"pos":[3517,3523],"content":"Decode"},{"content":"In the current version, the <bpt id=\"p1\">**</bpt>FaceDetector<ept id=\"p1\">**</ept> class only supports images in Gray8 or Nv12.","pos":[3589,3678],"source":"In the current version, the **FaceDetector** class only supports images in Gray8 or Nv12."},{"content":"The <bpt id=\"p1\">**</bpt>SoftwareBitmap<ept id=\"p1\">**</ept> class provides the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>Convert<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn887362)</ept> method, which converts a bitmap from one format to another.","pos":[3679,3852],"source":" The **SoftwareBitmap** class provides the [**Convert**](https://msdn.microsoft.com/library/windows/apps/dn887362) method, which converts a bitmap from one format to another."},{"content":"This example converts the source image into the Gray8 pixel format if it is not already in that format.","pos":[3853,3956]},{"content":"If you want, you can use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>GetSupportedBitmapPixelFormats<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974140)</ept> and <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IsBitmapPixelFormatSupported<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn974142)</ept> methods to determine at runtime if a pixel format is supported, in case the set of supported formats is expanded in future versions.","pos":[3957,4310],"source":" If you want, you can use the [**GetSupportedBitmapPixelFormats**](https://msdn.microsoft.com/library/windows/apps/dn974140) and [**IsBitmapPixelFormatSupported**](https://msdn.microsoft.com/library/windows/apps/dn974142) methods to determine at runtime if a pixel format is supported, in case the set of supported formats is expanded in future versions."},{"pos":[4322,4328],"content":"Format"},{"content":"Instantiate the <bpt id=\"p1\">**</bpt>FaceDetector<ept id=\"p1\">**</ept> object by calling <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>CreateAsync<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn974132)</ept> and then call <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>DetectFacesAsync<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/dn974134)</ept>, passing in the bitmap that has been scaled to a reasonable size and converted to a supported pixel format.","pos":[4394,4723],"source":"Instantiate the **FaceDetector** object by calling [**CreateAsync**](https://msdn.microsoft.com/library/windows/apps/dn974132) and then call [**DetectFacesAsync**](https://msdn.microsoft.com/library/windows/apps/dn974134), passing in the bitmap that has been scaled to a reasonable size and converted to a supported pixel format."},{"content":"This method returns a list of <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>DetectedFace<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects.","pos":[4724,4839],"source":" This method returns a list of [**DetectedFace**](https://msdn.microsoft.com/library/windows/apps/dn974123) objects."},{"content":"<bpt id=\"p1\">**</bpt>ShowDetectedFaces<ept id=\"p1\">**</ept> is a helper method, shown below, that draws squares around the faces in the image.","pos":[4840,4944],"source":"**ShowDetectedFaces** is a helper method, shown below, that draws squares around the faces in the image."},{"pos":[4956,4962],"content":"Detect"},{"content":"Be sure to dispose of the objects that were created during the face detection process.","pos":[5028,5114]},{"pos":[5126,5133],"content":"Dispose"},{"pos":[5200,5366],"content":"To display the image and draw boxes around the detected faces, add a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Canvas<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br209267)</ept> element to your XAML page.","source":"To display the image and draw boxes around the detected faces, add a [**Canvas**](https://msdn.microsoft.com/library/windows/apps/br209267) element to your XAML page."},{"pos":[5379,5385],"content":"Canvas"},{"content":"Define some member variables to style the squares that will be drawn.","pos":[5448,5517]},{"pos":[5529,5544],"content":"ClassVariables2"},{"content":"In the <bpt id=\"p1\">**</bpt>ShowDetectedFaces<ept id=\"p1\">**</ept> helper method, a new <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>ImageBrush<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/br210101)</ept> is created and the source is set to a <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>SoftwareBitmapSource<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/dn997854)</ept> created from the <bpt id=\"p6\">**</bpt>SoftwareBitmap<ept id=\"p6\">**</ept> representing the source image.","pos":[5619,5933],"source":"In the **ShowDetectedFaces** helper method, a new [**ImageBrush**](https://msdn.microsoft.com/library/windows/apps/br210101) is created and the source is set to a [**SoftwareBitmapSource**](https://msdn.microsoft.com/library/windows/apps/dn997854) created from the **SoftwareBitmap** representing the source image."},{"content":"The background of the XAML <bpt id=\"p1\">**</bpt>Canvas<ept id=\"p1\">**</ept> control is set to the image brush.","pos":[5934,6006],"source":" The background of the XAML **Canvas** control is set to the image brush."},{"content":"If the list of faces passed into the helper method isn't empty, loop through each face in the list and use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FaceBox<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974126)</ept> property of the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>DetectedFace<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> class to determine the position and size of the rectangle within the image that contains the face.","pos":[6008,6382],"source":"If the list of faces passed into the helper method isn't empty, loop through each face in the list and use the [**FaceBox**](https://msdn.microsoft.com/library/windows/apps/dn974126) property of the [**DetectedFace**](https://msdn.microsoft.com/library/windows/apps/dn974123) class to determine the position and size of the rectangle within the image that contains the face."},{"content":"Because the <bpt id=\"p1\">**</bpt>Canvas<ept id=\"p1\">**</ept> control is very likely to be a different size than the source image, you should multiply both the X and Y coordinates and the width and height of the <bpt id=\"p2\">**</bpt>FaceBox<ept id=\"p2\">**</ept> by a scaling value which is the ratio of the source image size to the actual size of the <bpt id=\"p3\">**</bpt>Canvas<ept id=\"p3\">**</ept> control.","pos":[6383,6676],"source":" Because the **Canvas** control is very likely to be a different size than the source image, you should multiply both the X and Y coordinates and the width and height of the **FaceBox** by a scaling value which is the ratio of the source image size to the actual size of the **Canvas** control."},{"pos":[6688,6705],"content":"ShowDetectedFaces"},{"content":"Track faces in a sequence of frames","pos":[6785,6820]},{"content":"If you want to detect faces in video, it is more efficient to use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FaceTracker<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> class rather than the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>FaceDetector<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> class, although the implementation steps are very similar.","pos":[6822,7125],"source":"If you want to detect faces in video, it is more efficient to use the [**FaceTracker**](https://msdn.microsoft.com/library/windows/apps/dn974150) class rather than the [**FaceDetector**](https://msdn.microsoft.com/library/windows/apps/dn974129) class, although the implementation steps are very similar."},{"content":"The <bpt id=\"p1\">**</bpt>FaceTracker<ept id=\"p1\">**</ept> uses information about previously processed frames to optimize the detection process.","pos":[7126,7231],"source":" The **FaceTracker** uses information about previously processed frames to optimize the detection process."},{"pos":[7243,7260],"content":"FaceTrackingUsing"},{"content":"Declare a class variable for the <bpt id=\"p1\">**</bpt>FaceTracker<ept id=\"p1\">**</ept> object.","pos":[7337,7393],"source":"Declare a class variable for the **FaceTracker** object."},{"content":"This example uses a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ThreadPoolTimer<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br230587)</ept> to initiate face tracking on a defined interval.","pos":[7394,7542],"source":" This example uses a [**ThreadPoolTimer**](https://msdn.microsoft.com/library/windows/apps/br230587) to initiate face tracking on a defined interval."},{"content":"A <bpt id=\"p1\">[</bpt>SemaphoreSlim<ept id=\"p1\">](https://msdn.microsoft.com/library/system.threading.semaphoreslim.aspx)</ept> is used to make sure that only one face tracking operation is running at a time.","pos":[7543,7713],"source":" A [SemaphoreSlim](https://msdn.microsoft.com/library/system.threading.semaphoreslim.aspx) is used to make sure that only one face tracking operation is running at a time."},{"pos":[7725,7740],"content":"ClassVariables3"},{"content":"To initialize the face tracking operation, create a new <bpt id=\"p1\">**</bpt>FaceTracker<ept id=\"p1\">**</ept> object by calling <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>CreateAsync<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn974151)</ept>.","pos":[7815,7981],"source":"To initialize the face tracking operation, create a new **FaceTracker** object by calling [**CreateAsync**](https://msdn.microsoft.com/library/windows/apps/dn974151)."},{"content":"Initialize the desired timer interval and then create the timer.","pos":[7982,8046]},{"content":"The <bpt id=\"p1\">**</bpt>ProcessCurrentVideoFrame<ept id=\"p1\">**</ept> helper method will be called every time the specified interval elapses.","pos":[8047,8151],"source":" The **ProcessCurrentVideoFrame** helper method will be called every time the specified interval elapses."},{"pos":[8163,8175],"content":"TrackingInit"},{"content":"The <bpt id=\"p1\">**</bpt>ProcessCurrentVideoFrame<ept id=\"p1\">**</ept> helper is called asynchronously by the timer, so the method first calls the semaphore's <bpt id=\"p2\">**</bpt>Wait<ept id=\"p2\">**</ept> method to see if a tracking operation is ongoing, and if it is the method returns without trying to detect faces.","pos":[8247,8490],"source":"The **ProcessCurrentVideoFrame** helper is called asynchronously by the timer, so the method first calls the semaphore's **Wait** method to see if a tracking operation is ongoing, and if it is the method returns without trying to detect faces."},{"content":"At the end of this method, the semaphore's <bpt id=\"p1\">**</bpt>Release<ept id=\"p1\">**</ept> method is called, which allows the subsequent call to <bpt id=\"p2\">**</bpt>ProcessCurrentVideoFrame<ept id=\"p2\">**</ept> to continue.","pos":[8491,8641],"source":" At the end of this method, the semaphore's **Release** method is called, which allows the subsequent call to **ProcessCurrentVideoFrame** to continue."},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>FaceTracker<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> class operates on <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>VideoFrame<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn930917)</ept> objects.","pos":[8643,8824],"source":"The [**FaceTracker**](https://msdn.microsoft.com/library/windows/apps/dn974150) class operates on [**VideoFrame**](https://msdn.microsoft.com/library/windows/apps/dn930917) objects."},{"content":"There are multiple ways you can obtain a <bpt id=\"p1\">**</bpt>VideoFrame<ept id=\"p1\">**</ept> including capturing a preview frame from a running <bpt id=\"p2\">[</bpt>MediaCapture<ept id=\"p2\">](capture-photos-and-video-with-mediacapture.md)</ept> object or by implementing the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>ProcessFrame<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn764784)</ept> method of the <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>IBasicVideoEffect<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/dn764788)</ept>.","pos":[8825,9197],"source":" There are multiple ways you can obtain a **VideoFrame** including capturing a preview frame from a running [MediaCapture](capture-photos-and-video-with-mediacapture.md) object or by implementing the [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764784) method of the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788)."},{"content":"This example uses an undefined helper method that returns a video frame, <bpt id=\"p1\">**</bpt>GetLatestFrame<ept id=\"p1\">**</ept>, as a placeholder for this operation.","pos":[9198,9327],"source":" This example uses an undefined helper method that returns a video frame, **GetLatestFrame**, as a placeholder for this operation."},{"content":"For information on getting video frames from the preview stream of a running media capture device, see <bpt id=\"p1\">[</bpt>Get a preview frame<ept id=\"p1\">](get-a-preview-frame.md)</ept>.","pos":[9328,9477],"source":" For information on getting video frames from the preview stream of a running media capture device, see [Get a preview frame](get-a-preview-frame.md)."},{"content":"As with <bpt id=\"p1\">**</bpt>FaceDetector<ept id=\"p1\">**</ept>, the <bpt id=\"p2\">**</bpt>FaceTracker<ept id=\"p2\">**</ept> supports a limited set of pixel formats.","pos":[9479,9565],"source":"As with **FaceDetector**, the **FaceTracker** supports a limited set of pixel formats."},{"content":"This example abandons face detection if the supplied frame is not in the Nv12 format.","pos":[9566,9651]},{"content":"Call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ProcessNextFrameAsync<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974157)</ept> to retrieve a list of <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>DetectedFace<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects representing the faces in the frame.","pos":[9653,9887],"source":"Call [**ProcessNextFrameAsync**](https://msdn.microsoft.com/library/windows/apps/dn974157) to retrieve a list of [**DetectedFace**](https://msdn.microsoft.com/library/windows/apps/dn974123) objects representing the faces in the frame."},{"content":"Once you have the list of faces, you can display them in the same manner described above for face detection.","pos":[9888,9996]},{"content":"Note that, because the face tracking helper method is not called on the UI thread, you must make any UI updates in within a call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>CoredDispatcher.RunAsync<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/hh750317)</ept>.","pos":[9997,10215],"source":" Note that, because the face tracking helper method is not called on the UI thread, you must make any UI updates in within a call [**CoredDispatcher.RunAsync**](https://msdn.microsoft.com/library/windows/apps/hh750317)."},{"pos":[10227,10251],"content":"ProcessCurrentVideoFrame"},{"content":"Related topics","pos":[10338,10352]},{"content":"Scene analysis for media capture","pos":[10357,10389]},{"content":"Basic Face Detection sample","pos":[10431,10458]},{"content":"Basic Face Tracking sample","pos":[10524,10550]},{"content":"Capture photos and video with MediaCapture","pos":[10616,10658]}],"content":"---\nms.assetid: 84729E44-10E9-4D7D-8575-6A9D97467ECD\ndescription: This topic shows how to use the FaceDetector to detect faces in an image. The FaceTracker is optimized for tracking faces over time in a sequence of video frames.\ntitle: Detect faces in images or videos\n---\n\n# Detect faces in images or videos\n\n\\[ Updated for UWP apps on Windows 10. For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]\n\n\n\\[Some information relates to pre-released product which may be substantially modified before it's commercially released. Microsoft makes no warranties, express or implied, with respect to the information provided here.\\]\n\nThis topic shows how to use the [**FaceDetector**](https://msdn.microsoft.com/library/windows/apps/dn974129) to detect faces in an image. The [**FaceTracker**](https://msdn.microsoft.com/library/windows/apps/dn974150) is optimized for tracking faces over time in a sequence of video frames.\n\nFor an alternative method of tracking faces using the [**FaceDetectionEffect**](https://msdn.microsoft.com/library/windows/apps/dn948776), see [Scene analysis for media capture](scene-analysis-for-media-capture.md).\n\nThe code in this article was adapted from the [Basic Face Detection](http://go.microsoft.com/fwlink/p/?LinkId=620512&clcid=0x409) and [Basic Face Tracking](http://go.microsoft.com/fwlink/p/?LinkId=620513&clcid=0x409) samples. You can download these samples to see the code used in context or to use the sample as a starting point for your own app.\n\n## Detect faces in a single image\n\nThe [**FaceDetector**](https://msdn.microsoft.com/library/windows/apps/dn974129) class allows you to detect one or more faces in a still image.\n\nThis example uses APIs from the following namespaces.\n\n[!code-cs[FaceDetectionUsing](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetFaceDetectionUsing)]\n\nDeclare a class member variable for the [**FaceDetector**](https://msdn.microsoft.com/library/windows/apps/dn974129) object and for the list of [**DetectedFace**](https://msdn.microsoft.com/library/windows/apps/dn974123) objects that will be detected in the image.\n\n[!code-cs[ClassVariables1](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetClassVariables1)]\n\nFace detection operates on a [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn887358) object which can be created in a variety of ways. In this example a [**FileOpenPicker**](https://msdn.microsoft.com/library/windows/apps/br207847) is used to allow the user to pick an image file in which faces will be detected. For more information on working with software bitmaps, see [Imaging](imaging.md).\n\n[!code-cs[Picker](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetPicker)]\n\nUse the [**BitmapDecoder**](https://msdn.microsoft.com/library/windows/apps/br226176) class to decode the image file into a **SoftwareBitmap**. The face detection process is quicker with a smaller image and so you may want to scale the source image down to a smaller size. This can be performed during decoding by creating a [**BitmapTransform**](https://msdn.microsoft.com/library/windows/apps/br226254) object, setting the [**ScaledWidth**](https://msdn.microsoft.com/library/windows/apps/br226261) and [**ScaledHeight**](https://msdn.microsoft.com/library/windows/apps/br226260) properties and passing it into the call to [**GetSoftwareBitmapAsync**](https://msdn.microsoft.com/library/windows/apps/dn887332), which returns the decoded and scaled **SoftwareBitmap**.\n\n[!code-cs[Decode](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetDecode)]\n\nIn the current version, the **FaceDetector** class only supports images in Gray8 or Nv12. The **SoftwareBitmap** class provides the [**Convert**](https://msdn.microsoft.com/library/windows/apps/dn887362) method, which converts a bitmap from one format to another. This example converts the source image into the Gray8 pixel format if it is not already in that format. If you want, you can use the [**GetSupportedBitmapPixelFormats**](https://msdn.microsoft.com/library/windows/apps/dn974140) and [**IsBitmapPixelFormatSupported**](https://msdn.microsoft.com/library/windows/apps/dn974142) methods to determine at runtime if a pixel format is supported, in case the set of supported formats is expanded in future versions.\n\n[!code-cs[Format](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetFormat)]\n\nInstantiate the **FaceDetector** object by calling [**CreateAsync**](https://msdn.microsoft.com/library/windows/apps/dn974132) and then call [**DetectFacesAsync**](https://msdn.microsoft.com/library/windows/apps/dn974134), passing in the bitmap that has been scaled to a reasonable size and converted to a supported pixel format. This method returns a list of [**DetectedFace**](https://msdn.microsoft.com/library/windows/apps/dn974123) objects. **ShowDetectedFaces** is a helper method, shown below, that draws squares around the faces in the image.\n\n[!code-cs[Detect](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetDetect)]\n\nBe sure to dispose of the objects that were created during the face detection process.\n\n[!code-cs[Dispose](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetDispose)]\n\nTo display the image and draw boxes around the detected faces, add a [**Canvas**](https://msdn.microsoft.com/library/windows/apps/br209267) element to your XAML page.\n\n[!code-xml[Canvas](./code/FaceDetection_Win10/cs/MainPage.xaml#SnippetCanvas)]\n\nDefine some member variables to style the squares that will be drawn.\n\n[!code-cs[ClassVariables2](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetClassVariables2)]\n\nIn the **ShowDetectedFaces** helper method, a new [**ImageBrush**](https://msdn.microsoft.com/library/windows/apps/br210101) is created and the source is set to a [**SoftwareBitmapSource**](https://msdn.microsoft.com/library/windows/apps/dn997854) created from the **SoftwareBitmap** representing the source image. The background of the XAML **Canvas** control is set to the image brush.\n\nIf the list of faces passed into the helper method isn't empty, loop through each face in the list and use the [**FaceBox**](https://msdn.microsoft.com/library/windows/apps/dn974126) property of the [**DetectedFace**](https://msdn.microsoft.com/library/windows/apps/dn974123) class to determine the position and size of the rectangle within the image that contains the face. Because the **Canvas** control is very likely to be a different size than the source image, you should multiply both the X and Y coordinates and the width and height of the **FaceBox** by a scaling value which is the ratio of the source image size to the actual size of the **Canvas** control.\n\n[!code-cs[ShowDetectedFaces](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetShowDetectedFaces)]\n\n## Track faces in a sequence of frames\n\nIf you want to detect faces in video, it is more efficient to use the [**FaceTracker**](https://msdn.microsoft.com/library/windows/apps/dn974150) class rather than the [**FaceDetector**](https://msdn.microsoft.com/library/windows/apps/dn974129) class, although the implementation steps are very similar. The **FaceTracker** uses information about previously processed frames to optimize the detection process.\n\n[!code-cs[FaceTrackingUsing](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetFaceTrackingUsing)]\n\nDeclare a class variable for the **FaceTracker** object. This example uses a [**ThreadPoolTimer**](https://msdn.microsoft.com/library/windows/apps/br230587) to initiate face tracking on a defined interval. A [SemaphoreSlim](https://msdn.microsoft.com/library/system.threading.semaphoreslim.aspx) is used to make sure that only one face tracking operation is running at a time.\n\n[!code-cs[ClassVariables3](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetClassVariables3)]\n\nTo initialize the face tracking operation, create a new **FaceTracker** object by calling [**CreateAsync**](https://msdn.microsoft.com/library/windows/apps/dn974151). Initialize the desired timer interval and then create the timer. The **ProcessCurrentVideoFrame** helper method will be called every time the specified interval elapses.\n\n[!code-cs[TrackingInit](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetTrackingInit)]\n\nThe **ProcessCurrentVideoFrame** helper is called asynchronously by the timer, so the method first calls the semaphore's **Wait** method to see if a tracking operation is ongoing, and if it is the method returns without trying to detect faces. At the end of this method, the semaphore's **Release** method is called, which allows the subsequent call to **ProcessCurrentVideoFrame** to continue.\n\nThe [**FaceTracker**](https://msdn.microsoft.com/library/windows/apps/dn974150) class operates on [**VideoFrame**](https://msdn.microsoft.com/library/windows/apps/dn930917) objects. There are multiple ways you can obtain a **VideoFrame** including capturing a preview frame from a running [MediaCapture](capture-photos-and-video-with-mediacapture.md) object or by implementing the [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764784) method of the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788). This example uses an undefined helper method that returns a video frame, **GetLatestFrame**, as a placeholder for this operation. For information on getting video frames from the preview stream of a running media capture device, see [Get a preview frame](get-a-preview-frame.md).\n\nAs with **FaceDetector**, the **FaceTracker** supports a limited set of pixel formats. This example abandons face detection if the supplied frame is not in the Nv12 format.\n\nCall [**ProcessNextFrameAsync**](https://msdn.microsoft.com/library/windows/apps/dn974157) to retrieve a list of [**DetectedFace**](https://msdn.microsoft.com/library/windows/apps/dn974123) objects representing the faces in the frame. Once you have the list of faces, you can display them in the same manner described above for face detection. Note that, because the face tracking helper method is not called on the UI thread, you must make any UI updates in within a call [**CoredDispatcher.RunAsync**](https://msdn.microsoft.com/library/windows/apps/hh750317).\n\n[!code-cs[ProcessCurrentVideoFrame](./code/FaceDetection_Win10/cs/MainPage.xaml.cs#SnippetProcessCurrentVideoFrame)]\n\n## Related topics\n\n* [Scene analysis for media capture](scene-analysis-for-media-capture.md)\n* [Basic Face Detection sample](http://go.microsoft.com/fwlink/p/?LinkId=620512&clcid=0x409)\n* [Basic Face Tracking sample](http://go.microsoft.com/fwlink/p/?LinkId=620513&clcid=0x409)\n* [Capture photos and video with MediaCapture](capture-photos-and-video-with-mediacapture.md)\n"}
{"nodes":[{"pos":[11,49],"content":"Adding audio to the Marble Maze sample","needQuote":true,"needEscape":true,"nodes":[{"content":"Adding audio to the Marble Maze sample","pos":[0,38]}]},{"pos":[63,192],"content":"This document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices.","needQuote":true,"needEscape":true,"nodes":[{"content":"This document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices.","pos":[0,129]}]},{"content":"Adding audio to the Marble Maze sample","pos":[249,287]},{"content":"\\[ Updated for UWP apps on Windows 10.","pos":[290,328]},{"content":"For Windows 8.x articles, see the <bpt id=\"p1\">[</bpt>archive<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept> \\]","pos":[329,424],"source":" For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]"},{"content":"This document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices.","pos":[427,556]},{"content":"Marble Maze uses Microsoft Media Foundation to load audio resources from file, and XAudio2 to mix and play audio and to apply effects to audio.","pos":[557,700]},{"content":"Marble Maze plays music in the background, and also uses game-play sounds to indicate game events, such as when the marble hits a wall.","pos":[702,837]},{"content":"An important part of the implementation is that Marble Maze uses a reverb, or echo, effect to simulate the sound of a marble when it bounces.","pos":[838,979]},{"content":"The reverb effect implementation causes echoes to reach you more quickly and loudly in small rooms; echoes are quieter and reach you more slowly in larger rooms.","pos":[980,1141]},{"pos":[1145,1303],"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>   The sample code that corresponds to this document is found in the <bpt id=\"p2\">[</bpt>DirectX Marble Maze game sample<ept id=\"p2\">](http://go.microsoft.com/fwlink/?LinkId=624011)</ept>.","source":"**Note**   The sample code that corresponds to this document is found in the [DirectX Marble Maze game sample](http://go.microsoft.com/fwlink/?LinkId=624011)."},{"content":"Here are some of the key points that this document discusses for when you work with audio in your game:","pos":[1305,1408]},{"content":"Consider using Media Foundation to decode audio assets and XAudio2 to play audio.","pos":[1414,1495]},{"content":"However, if you have an existing audio asset-loading mechanism that works in a Universal Windows Platform (UWP) app, you can use it.","pos":[1496,1628]},{"content":"An audio graph contains one source voice for each active sound, zero or more submix voices, and one mastering voice.","pos":[1633,1749]},{"content":"Source voices can feed into submix voices and/or the mastering voice.","pos":[1750,1819]},{"content":"Submix voices feed into other submix voices or the mastering voice.","pos":[1820,1887]},{"content":"If your background music files are large, consider streaming your music into smaller buffers so that less memory is used.","pos":[1892,2013]},{"content":"If it makes sense to do so, pause audio playback when the app loses focus or visibility, or is suspended.","pos":[2018,2123]},{"content":"Resume playback when your app regains focus, becomes visible, or is resumed.","pos":[2124,2200]},{"content":"Set audio categories to reflect the role of each sound.","pos":[2205,2260]},{"content":"For example, you typically use <bpt id=\"p1\">**</bpt>AudioCategory\\_GameMedia<ept id=\"p1\">**</ept> for game background audio and <bpt id=\"p2\">**</bpt>AudioCategory\\_GameEffects<ept id=\"p2\">**</ept> for sound effects.","pos":[2261,2400],"source":" For example, you typically use **AudioCategory\\_GameMedia** for game background audio and **AudioCategory\\_GameEffects** for sound effects."},{"content":"Handle device changes, including headphones, by releasing and recreating all audio resources and interfaces.","pos":[2405,2513]},{"content":"Consider whether to compress audio files when minimizing disk space and streaming costs is a requirement.","pos":[2518,2623]},{"content":"Otherwise, you can leave audio uncompressed so that it loads faster.","pos":[2624,2692]},{"content":"Introducing XAudio2 and Microsoft Media Foundation","pos":[2697,2747]},{"content":"XAudio2 is a low-level audio library for Windows that specifically supports game audio.","pos":[2750,2837]},{"content":"It provides a digital signal processing (DSP) and audio-graph engine for games.","pos":[2838,2917]},{"content":"XAudio2 expands on its predecessors, DirectSound and XAudio, by supporting computing trends such as SIMD floating-point architectures and HD audio.","pos":[2918,3065]},{"content":"It also supports the more complex sound processing demands of todayâ€™s games.","pos":[3066,3142]},{"content":"The document <bpt id=\"p1\">[</bpt>XAudio2 Key Concepts<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415764)</ept> explains the key concepts for using XAudio2.","pos":[3144,3285],"source":"The document [XAudio2 Key Concepts](https://msdn.microsoft.com/library/windows/desktop/ee415764) explains the key concepts for using XAudio2."},{"content":"In brief, the concepts are:","pos":[3286,3313]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</ept> interface is the core of the XAudio2 engine.","pos":[3319,3443],"source":"The [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) interface is the core of the XAudio2 engine."},{"content":"Marble Maze uses this interface to create voices and to receive notification when the output device changes or fails.","pos":[3444,3561]},{"content":"A voice processes, adjusts, and plays audio data.","pos":[3566,3615]},{"content":"A source voice is a collection of audio channels (mono, 5.1, and so on) and represents one stream of audio data.","pos":[3620,3732]},{"content":"In XAudio2, a source voice is where audio processing begins.","pos":[3733,3793]},{"content":"Typically, sound data is loaded from an external source, such as a file or a network, and is sent to a source voice.","pos":[3794,3910]},{"content":"Marble Maze uses <bpt id=\"p1\">[</bpt>Media Foundation<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ms694197)</ept> to load sound data from files.","pos":[3911,4038],"source":" Marble Maze uses [Media Foundation](https://msdn.microsoft.com/library/windows/desktop/ms694197) to load sound data from files."},{"content":"Media Foundation is introduced later in this document.","pos":[4039,4093]},{"content":"A submix voice processes audio data.","pos":[4098,4134]},{"content":"This processing can include changing the audio stream or combining multiple streams into one.","pos":[4135,4228]},{"content":"Marble Maze uses submixes to create the reverb effect.","pos":[4229,4283]},{"content":"A mastering voice combines data from source and submix voices and sends that data to the audio hardware.","pos":[4288,4392]},{"content":"An audio graph contains one source voice for each active sound, zero or more submix voices, and only one mastering voice.","pos":[4397,4518]},{"content":"A callback informs client code that some event has occurred in a voice or in an engine object.","pos":[4523,4617]},{"content":"By using callbacks, you can reuse memory when XAudio2 is finished with a buffer, react when the audio device changes (for example, when you connect or disconnect headphones), and more.","pos":[4618,4802]},{"content":"The <bpt id=\"p1\">[</bpt>Handling headphones and device changes section<ept id=\"p1\">](#phones)</ept> later in this document explains how Marble Maze uses this mechanism to handle device changes.","pos":[4803,4958],"source":" The [Handling headphones and device changes section](#phones) later in this document explains how Marble Maze uses this mechanism to handle device changes."},{"content":"Marble Maze uses two audio engines (in other words, two <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</ept> objects) to process audio.","pos":[4960,5118],"source":"Marble Maze uses two audio engines (in other words, two [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) objects) to process audio."},{"content":"One engine processes the background music, and the other engine processes game-play sounds.","pos":[5119,5210]},{"content":"Marble Maze must also create one mastering voice for each engine.","pos":[5212,5277]},{"content":"Recall that a mastering engine combines audio streams into one stream and sends that stream to the audio hardware.","pos":[5278,5392]},{"content":"The background music stream, a source voice, outputs data to a mastering voice and to two submix voices.","pos":[5393,5497]},{"content":"The submix voices perform the reverb effect.","pos":[5498,5542]},{"content":"Media Foundation is a multimedia library that supports many audio and video formats.","pos":[5544,5628]},{"content":"XAudio2 and Media Foundation complement each other.","pos":[5629,5680]},{"content":"Marble Maze uses Media Foundation to load audio assets from file and uses XAudio2 to play audio.","pos":[5681,5777]},{"content":"You don't have to use Media Foundation to load audio assets.","pos":[5778,5838]},{"content":"If you have an existing audio asset loading mechanism that works in Universal Windows Platform (UWP) apps, use it.","pos":[5839,5953]},{"content":"For more information about XAudio2, see <bpt id=\"p1\">[</bpt>Programming Guide<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415737)</ept>.","pos":[5955,6076],"source":"For more information about XAudio2, see [Programming Guide](https://msdn.microsoft.com/library/windows/desktop/ee415737)."},{"content":"For more information about Media Foundation, see <bpt id=\"p1\">[</bpt>Microsoft Media Foundation<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ms694197)</ept>.","pos":[6077,6216],"source":" For more information about Media Foundation, see [Microsoft Media Foundation](https://msdn.microsoft.com/library/windows/desktop/ms694197)."},{"content":"Initializing audio resources","pos":[6221,6249]},{"content":"Marble Mazes uses a Windows Media Audio (.wma) file for the background music, and WAV (.wav) files for game play sounds.","pos":[6252,6372]},{"content":"These formats are supported by Media Foundation.","pos":[6373,6421]},{"content":"Although the .wav file format is natively supported by XAudio2, a game has to parse the file format manually to fill out the appropriate XAudio2 data structures.","pos":[6422,6583]},{"content":"Marble Maze uses Media Foundation to more easily work with .wav files.","pos":[6584,6654]},{"content":"For the complete list of the media formats that are supported by Media Foundation, see <bpt id=\"p1\">[</bpt>Supported Media Formats in Media Foundation<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/dd757927)</ept>.","pos":[6655,6849],"source":" For the complete list of the media formats that are supported by Media Foundation, see [Supported Media Formats in Media Foundation](https://msdn.microsoft.com/library/windows/desktop/dd757927)."},{"content":"Marble Maze does not use separate design-time and run-time audio formats, and does not use XAudio2 ADPCM compression support.","pos":[6850,6975]},{"content":"For more information about ADPCM compression in XAudio2, see <bpt id=\"p1\">[</bpt>ADPCM Overview<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415711)</ept>.","pos":[6976,7115],"source":" For more information about ADPCM compression in XAudio2, see [ADPCM Overview](https://msdn.microsoft.com/library/windows/desktop/ee415711)."},{"pos":[7117,7355],"content":"The <bpt id=\"p1\">**</bpt>Audio::CreateResources<ept id=\"p1\">**</ept> method, which is called from <bpt id=\"p2\">**</bpt>MarbleMaze::CreateDeviceIndependentResources<ept id=\"p2\">**</ept>, loads the audio streams from file, initializes the XAudio2 engine objects, and creates the source, submix, and mastering voices.","source":"The **Audio::CreateResources** method, which is called from **MarbleMaze::CreateDeviceIndependentResources**, loads the audio streams from file, initializes the XAudio2 engine objects, and creates the source, submix, and mastering voices."},{"content":"Creating the XAudio2 engines","pos":[7362,7390]},{"content":"Recall that Marble Maze creates one <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</ept> object to represent each audio engine that it uses.","pos":[7392,7555],"source":"Recall that Marble Maze creates one [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) object to represent each audio engine that it uses."},{"content":"To create an audio engine, call the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAudio2Create<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419212)</ept> function.","pos":[7556,7682],"source":" To create an audio engine, call the [**XAudio2Create**](https://msdn.microsoft.com/library/windows/desktop/ee419212) function."},{"content":"The following example shows how Marble Maze creates the audio engine that processes background music.","pos":[7683,7784]},{"content":"Marble Maze performs a similar step to create the audio engine that plays game-play sounds.","pos":[7858,7949]},{"content":"How to work with the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</ept> interface in a UWP app differs from a desktop app in two ways.","pos":[7951,8110],"source":"How to work with the [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) interface in a UWP app differs from a desktop app in two ways."},{"content":"First, you don't have to call <bpt id=\"p1\">**</bpt>CoInitializeEx<ept id=\"p1\">**</ept> before you call <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>XAudio2Create<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ee419212)</ept>.","pos":[8111,8257],"source":" First, you don't have to call **CoInitializeEx** before you call [**XAudio2Create**](https://msdn.microsoft.com/library/windows/desktop/ee419212)."},{"content":"In addition, <bpt id=\"p1\">**</bpt>IXAudio2<ept id=\"p1\">**</ept> no longer supports device enumeration.","pos":[8258,8322],"source":" In addition, **IXAudio2** no longer supports device enumeration."},{"content":"For information about how to enumerate audio devices, see <bpt id=\"p1\">[</bpt>Enumerating devices<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/hh464977)</ept>.","pos":[8323,8461],"source":" For information about how to enumerate audio devices, see [Enumerating devices](https://msdn.microsoft.com/library/windows/apps/hh464977)."},{"content":"Creating the mastering voices","pos":[8468,8497]},{"content":"The following example shows how the <bpt id=\"p1\">**</bpt>Audio::CreateResources<ept id=\"p1\">**</ept> method creates the mastering voice for the background music.","pos":[8499,8622],"source":"The following example shows how the **Audio::CreateResources** method creates the mastering voice for the background music."},{"content":"The call to <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2::CreateMasteringVoice<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/hh405048)</ept> specifies two input channels.","pos":[8623,8762],"source":" The call to [**IXAudio2::CreateMasteringVoice**](https://msdn.microsoft.com/library/windows/desktop/hh405048) specifies two input channels."},{"content":"This simplifies the logic for the reverb effect.","pos":[8763,8811]},{"content":"The <bpt id=\"p1\">**</bpt>XAUDIO2\\_DEFAULT\\_SAMPLERATE<ept id=\"p1\">**</ept> specification tells the audio engine to use the sample rate that is specified in the Sound Control Panel.","pos":[8812,8954],"source":" The **XAUDIO2\\_DEFAULT\\_SAMPLERATE** specification tells the audio engine to use the sample rate that is specified in the Sound Control Panel."},{"content":"In this example, <bpt id=\"p1\">**</bpt>m\\_musicMasteringVoice<ept id=\"p1\">**</ept> is an <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IXAudio2MasteringVoice<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ee415912)</ept> object.","pos":[8955,9102],"source":" In this example, **m\\_musicMasteringVoice** is an [**IXAudio2MasteringVoice**](https://msdn.microsoft.com/library/windows/desktop/ee415912) object."},{"content":"The <bpt id=\"p1\">**</bpt>Audio::CreateResources<ept id=\"p1\">**</ept> method performs a similar step to create the mastering voice for the game play sounds, except that it specifies <bpt id=\"p2\">**</bpt>AudioCategory\\_GameEffects<ept id=\"p2\">**</ept> for the <bpt id=\"p3\">*</bpt>StreamCategory<ept id=\"p3\">*</ept> parameter, which is the default.","pos":[9906,10137],"source":"The **Audio::CreateResources** method performs a similar step to create the mastering voice for the game play sounds, except that it specifies **AudioCategory\\_GameEffects** for the *StreamCategory* parameter, which is the default."},{"content":"Marble Maze specifies <bpt id=\"p1\">**</bpt>AudioCategory\\_GameMedia<ept id=\"p1\">**</ept> for background music so that users can listen to music from a different application as they play the game.","pos":[10138,10295],"source":" Marble Maze specifies **AudioCategory\\_GameMedia** for background music so that users can listen to music from a different application as they play the game."},{"content":"When a music app is playing, Windows mutes any voices that are created by the <bpt id=\"p1\">**</bpt>AudioCategory\\_GameMedia<ept id=\"p1\">**</ept> option.","pos":[10296,10410],"source":" When a music app is playing, Windows mutes any voices that are created by the **AudioCategory\\_GameMedia** option."},{"content":"The user still hears game-play sounds because they are created by the <bpt id=\"p1\">**</bpt>AudioCategory\\_GameEffects<ept id=\"p1\">**</ept> option.","pos":[10411,10519],"source":" The user still hears game-play sounds because they are created by the **AudioCategory\\_GameEffects** option."},{"content":"For more info about audio categories, see <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>AUDIO\\_STREAM\\_CATEGORY<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/hh404178)</ept> enumeration.","pos":[10520,10665],"source":" For more info about audio categories, see [**AUDIO\\_STREAM\\_CATEGORY**](https://msdn.microsoft.com/library/windows/desktop/hh404178) enumeration."},{"content":"Creating the reverb effect","pos":[10672,10698]},{"content":"For each voice, you can use XAudio2 to create sequences of effects that process audio.","pos":[10700,10786]},{"content":"Such a sequence is known as an effect chain.","pos":[10787,10831]},{"content":"Use effect chains when you want to apply one or more effects to a voice.","pos":[10832,10904]},{"content":"Effect chains can be destructive; that is, each effect in the chain can overwrite the audio buffer.","pos":[10905,11004]},{"content":"This property is important because XAudio2 makes no guarantee that output buffers are initialized with silence.","pos":[11005,11116]},{"content":"Effect objects are represented in XAudio2 by cross-platform audio processing objects (XAPO).","pos":[11117,11209]},{"content":"For more information about XAPO, see <bpt id=\"p1\">[</bpt>XAPO Overviews<ept id=\"p1\">](o:microsoft.directx_sdk.xapo.audio_overview_xapo)</ept>.","pos":[11210,11314],"source":" For more information about XAPO, see [XAPO Overviews](o:microsoft.directx_sdk.xapo.audio_overview_xapo)."},{"content":"When you create an effect chain, follow these steps:","pos":[11316,11368]},{"content":"Create the effect object.","pos":[11374,11399]},{"pos":[11404,11538],"content":"Populate an <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2\\_EFFECT\\_DESCRIPTOR<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419236)</ept> structure with effect data.","source":"Populate an [**XAUDIO2\\_EFFECT\\_DESCRIPTOR**](https://msdn.microsoft.com/library/windows/desktop/ee419236) structure with effect data."},{"pos":[11543,11665],"content":"Populate an <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2\\_EFFECT\\_CHAIN<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419235)</ept> structure with data.","source":"Populate an [**XAUDIO2\\_EFFECT\\_CHAIN**](https://msdn.microsoft.com/library/windows/desktop/ee419235) structure with data."},{"content":"Apply the effect chain to a voice.","pos":[11670,11704]},{"content":"Populate an effect parameter structure and apply it to the effect.","pos":[11709,11775]},{"content":"Disable or enable the effect whenever appropriate.","pos":[11780,11830]},{"content":"The <bpt id=\"p1\">**</bpt>Audio<ept id=\"p1\">**</ept> class defines the <bpt id=\"p2\">**</bpt>CreateReverb<ept id=\"p2\">**</ept> method to create the effect chain that implements reverb.","pos":[11832,11938],"source":"The **Audio** class defines the **CreateReverb** method to create the effect chain that implements reverb."},{"content":"This method calls the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAudio2CreateReverb<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419213)</ept> function to create a <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IXAudio2SubmixVoice<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/desktop/ee415915)</ept> object, which acts as the submix voice for the reverb effect.","pos":[11939,12217],"source":" This method calls the [**XAudio2CreateReverb**](https://msdn.microsoft.com/library/windows/desktop/ee419213) function to create a [**IXAudio2SubmixVoice**](https://msdn.microsoft.com/library/windows/desktop/ee415915) object, which acts as the submix voice for the reverb effect."},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2\\_EFFECT\\_DESCRIPTOR<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419236)</ept> structure contains information about an XAPO for use in an effect chain, for example, the target number of output channels.","pos":[12299,12521],"source":"The [**XAUDIO2\\_EFFECT\\_DESCRIPTOR**](https://msdn.microsoft.com/library/windows/desktop/ee419236) structure contains information about an XAPO for use in an effect chain, for example, the target number of output channels."},{"content":"The <bpt id=\"p1\">**</bpt>Audio::CreateReverb<ept id=\"p1\">**</ept> method creates an <bpt id=\"p2\">**</bpt>XAUDIO2\\_EFFECT\\_DESCRIPTOR<ept id=\"p2\">**</ept> object that is set to the disabled state, uses two output channels, and references the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IXAudio2SubmixVoice<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/desktop/ee415915)</ept> object for the reverb effect.","pos":[12522,12803],"source":" The **Audio::CreateReverb** method creates an **XAUDIO2\\_EFFECT\\_DESCRIPTOR** object that is set to the disabled state, uses two output channels, and references the [**IXAudio2SubmixVoice**](https://msdn.microsoft.com/library/windows/desktop/ee415915) object for the reverb effect."},{"content":"The <bpt id=\"p1\">**</bpt>XAUDIO2\\_EFFECT\\_DESCRIPTOR<ept id=\"p1\">**</ept> object starts in the disabled state because the game must set parameters before the effect starts modifying game sounds.","pos":[12804,12960],"source":" The **XAUDIO2\\_EFFECT\\_DESCRIPTOR** object starts in the disabled state because the game must set parameters before the effect starts modifying game sounds."},{"content":"Marble Maze uses two output channels to simplify the logic for the reverb effect.","pos":[12961,13042]},{"content":"If your effect chain has multiple effects, each effect requires an object.","pos":[13197,13271]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2\\_EFFECT\\_CHAIN<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419235)</ept> structure holds the array of <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>XAUDIO2\\_EFFECT\\_DESCRIPTOR<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/desktop/ee419236)</ept> objects that participate in the effect.","pos":[13272,13529],"source":" The [**XAUDIO2\\_EFFECT\\_CHAIN**](https://msdn.microsoft.com/library/windows/desktop/ee419235) structure holds the array of [**XAUDIO2\\_EFFECT\\_DESCRIPTOR**](https://msdn.microsoft.com/library/windows/desktop/ee419236) objects that participate in the effect."},{"content":"The following example shows how the <bpt id=\"p1\">**</bpt>Audio::CreateReverb<ept id=\"p1\">**</ept> method specifies the one effect to implement reverb.","pos":[13530,13642],"source":" The following example shows how the **Audio::CreateReverb** method specifies the one effect to implement reverb."},{"content":"The <bpt id=\"p1\">**</bpt>Audio::CreateReverb<ept id=\"p1\">**</ept> method calls the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IXAudio2::CreateSubmixVoice<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ee418608)</ept> method to create the submix voice for the effect.","pos":[13752,13941],"source":"The **Audio::CreateReverb** method calls the [**IXAudio2::CreateSubmixVoice**](https://msdn.microsoft.com/library/windows/desktop/ee418608) method to create the submix voice for the effect."},{"content":"It specifies the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2\\_EFFECT\\_CHAIN<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419235)</ept> object for the <bpt id=\"p3\">*</bpt>pEffectChain<ept id=\"p3\">*</ept> parameter to associate the effect chain with the voice.","pos":[13942,14134],"source":" It specifies the [**XAUDIO2\\_EFFECT\\_CHAIN**](https://msdn.microsoft.com/library/windows/desktop/ee419235) object for the *pEffectChain* parameter to associate the effect chain with the voice."},{"content":"Marble Maze also specifies two output channels and a sample rate of 48 kilohertz.","pos":[14135,14216]},{"content":"We chose this sample rate because it represented a balance between audio quality and the amount of required CPU processing.","pos":[14217,14340]},{"content":"A greater sample rate would have required more CPU processing without having a noticeable quality benefit.","pos":[14341,14447]},{"pos":[14574,14821],"content":"<bpt id=\"p1\">**</bpt>Tip<ept id=\"p1\">**</ept>   If you want to attach an existing effect chain to an existing submix voice, or you want to replace the current effect chain, use the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IXAudio2Voice::SetEffectChain<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ee418594)</ept> method.","source":"**Tip**   If you want to attach an existing effect chain to an existing submix voice, or you want to replace the current effect chain, use the [**IXAudio2Voice::SetEffectChain**](https://msdn.microsoft.com/library/windows/desktop/ee418594) method."},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Audio::XAudio2CreateReverb<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419213)</ept> method calls <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IXAudio2Voice::SetEffectParameters<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/desktop/ee418595)</ept> to set additional parameters that are associated with the effect.","pos":[14826,15104],"source":"The [**Audio::XAudio2CreateReverb**](https://msdn.microsoft.com/library/windows/desktop/ee419213) method calls [**IXAudio2Voice::SetEffectParameters**](https://msdn.microsoft.com/library/windows/desktop/ee418595) to set additional parameters that are associated with the effect."},{"content":"This method takes a parameter structure that is specific to the effect.","pos":[15105,15176]},{"content":"An <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2FX\\_REVERB\\_PARAMETERS<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419224)</ept> object, which contains the effect parameters for reverb, is initialized in the <bpt id=\"p3\">**</bpt>Audio::Initialize<ept id=\"p3\">**</ept> method because every reverb effect shares the same parameters.","pos":[15177,15440],"source":" An [**XAUDIO2FX\\_REVERB\\_PARAMETERS**](https://msdn.microsoft.com/library/windows/desktop/ee419224) object, which contains the effect parameters for reverb, is initialized in the **Audio::Initialize** method because every reverb effect shares the same parameters."},{"content":"The following example shows how the <bpt id=\"p1\">**</bpt>Audio::Initialize<ept id=\"p1\">**</ept> method initializes the reverb parameters for near-field reverb.","pos":[15441,15562],"source":" The following example shows how the **Audio::Initialize** method initializes the reverb parameters for near-field reverb."},{"content":"This example uses the default values for most of the reverb parameters, but it sets <bpt id=\"p1\">**</bpt>DisableLateField<ept id=\"p1\">**</ept> to TRUE to specify near-field reverb, <bpt id=\"p2\">**</bpt>EarlyDiffusion<ept id=\"p2\">**</ept> to 4 to simulate flat near surfaces, and <bpt id=\"p3\">**</bpt>LateDiffusion<ept id=\"p3\">**</ept> to 15 to simulate very diffuse distant surfaces.","pos":[17276,17545],"source":"This example uses the default values for most of the reverb parameters, but it sets **DisableLateField** to TRUE to specify near-field reverb, **EarlyDiffusion** to 4 to simulate flat near surfaces, and **LateDiffusion** to 15 to simulate very diffuse distant surfaces."},{"content":"Flat near surfaces cause echoes to reach you more quickly and loudly; diffuse distant surfaces cause echoes to be quieter and reach you more slowly.","pos":[17546,17694]},{"content":"You can experiment with reverb values to get the desired effect in your game or use the <bpt id=\"p1\">**</bpt>ReverbConvertI3DL2ToNative<ept id=\"p1\">**</ept> function to use industry-standard I3DL2 (Interactive 3D Audio Rendering Guidelines Level 2.0) parameters.","pos":[17695,17919],"source":" You can experiment with reverb values to get the desired effect in your game or use the **ReverbConvertI3DL2ToNative** function to use industry-standard I3DL2 (Interactive 3D Audio Rendering Guidelines Level 2.0) parameters."},{"content":"The following example shows how <bpt id=\"p1\">**</bpt>Audio::CreateReverb<ept id=\"p1\">**</ept> sets the reverb parameters.","pos":[17921,18004],"source":"The following example shows how **Audio::CreateReverb** sets the reverb parameters."},{"content":"The parameters parameter is an <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2FX\\_REVERB\\_PARAMETERS<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419224)</ept> object.","pos":[18005,18140],"source":" The parameters parameter is an [**XAUDIO2FX\\_REVERB\\_PARAMETERS**](https://msdn.microsoft.com/library/windows/desktop/ee419224) object."},{"content":"The <bpt id=\"p1\">**</bpt>Audio::CreateReverb<ept id=\"p1\">**</ept> method finishes by enabling the effect if the <bpt id=\"p2\">**</bpt>enableEffect<ept id=\"p2\">**</ept> flag is set and by setting its volume and output matrix.","pos":[18266,18413],"source":"The **Audio::CreateReverb** method finishes by enabling the effect if the **enableEffect** flag is set and by setting its volume and output matrix."},{"content":"This part sets the volume to full (1.0) and then specifies the volume matrix to be silence for both left and right inputs and left and right output speakers.","pos":[18414,18571]},{"content":"We do this because other code later cross-fades between the two reverbs (simulating the transition from being near a wall to being in a large room), or mutes both reverbs if required.","pos":[18572,18755]},{"content":"When the reverb path is later unmuted, the game sets a matrix of {1.0f, 0.0f, 0.0f, 1.0f} to route left reverb output to the left input of the mastering voice and right reverb output to the right input of the mastering voice.","pos":[18756,18981]},{"content":"Marble Maze calls the <bpt id=\"p1\">**</bpt>CreateReverb<ept id=\"p1\">**</ept> method four times; two times for the background music and two times for the game-play sounds.","pos":[19290,19422],"source":"Marble Maze calls the **CreateReverb** method four times; two times for the background music and two times for the game-play sounds."},{"content":"The following shows how Marble Maze calls the <bpt id=\"p1\">**</bpt>CreateReverb<ept id=\"p1\">**</ept> method for the background music.","pos":[19423,19518],"source":" The following shows how Marble Maze calls the **CreateReverb** method for the background music."},{"pos":[19820,19973],"content":"For a list of possible sources of effects for use with XAudio2, see <bpt id=\"p1\">[</bpt>XAudio2 Audio Effects<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415756)</ept>.","source":"For a list of possible sources of effects for use with XAudio2, see [XAudio2 Audio Effects](https://msdn.microsoft.com/library/windows/desktop/ee415756)."},{"content":"Loading audio data from file","pos":[19979,20007]},{"content":"Marble Maze defines the <bpt id=\"p1\">**</bpt>MediaStreamer<ept id=\"p1\">**</ept> class, which uses Media Foundation to load audio resources from file.","pos":[20009,20120],"source":"Marble Maze defines the **MediaStreamer** class, which uses Media Foundation to load audio resources from file."},{"content":"Marble Maze uses one <bpt id=\"p1\">**</bpt>MediaStreamer<ept id=\"p1\">**</ept> object to load each audio file.","pos":[20121,20191],"source":" Marble Maze uses one **MediaStreamer** object to load each audio file."},{"content":"Marble Maze calls the <bpt id=\"p1\">**</bpt>MediaStreamer::Initialize<ept id=\"p1\">**</ept> method to initialize each audio stream.","pos":[20193,20284],"source":"Marble Maze calls the **MediaStreamer::Initialize** method to initialize each audio stream."},{"content":"Here's how the <bpt id=\"p1\">**</bpt>Audio::CreateResources<ept id=\"p1\">**</ept> method calls <bpt id=\"p2\">**</bpt>MediaStreamer::Initialize<ept id=\"p2\">**</ept> to initialize the audio stream for the background music:","pos":[20285,20426],"source":" Here's how the **Audio::CreateResources** method calls **MediaStreamer::Initialize** to initialize the audio stream for the background music:"},{"pos":[20694,20874],"content":"The <bpt id=\"p1\">**</bpt>MediaStreamer::Initialize<ept id=\"p1\">**</ept> method starts by calling the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>MFStartup<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ms702238)</ept> function to initialize Media Foundation.","source":"The **MediaStreamer::Initialize** method starts by calling the [**MFStartup**](https://msdn.microsoft.com/library/windows/desktop/ms702238) function to initialize Media Foundation."},{"content":"<bpt id=\"p1\">**</bpt>MediaStreamer::Initialize<ept id=\"p1\">**</ept> then calls <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>MFCreateSourceReaderFromURL<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/dd388110)</ept> to create an <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>IMFSourceReader<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/desktop/dd374655)</ept> object.","pos":[20940,21179],"source":"**MediaStreamer::Initialize** then calls [**MFCreateSourceReaderFromURL**](https://msdn.microsoft.com/library/windows/desktop/dd388110) to create an [**IMFSourceReader**](https://msdn.microsoft.com/library/windows/desktop/dd374655) object."},{"content":"An <bpt id=\"p1\">**</bpt>IMFSourceReader<ept id=\"p1\">**</ept> object reads media data from the file that is specified by url.","pos":[21180,21266],"source":" An **IMFSourceReader** object reads media data from the file that is specified by url."},{"content":"The <bpt id=\"p1\">**</bpt>MediaStreamer::Initialize<ept id=\"p1\">**</ept> method then creates an <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IMFMediaType<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ms704850)</ept> object to describe the format of the audio stream.","pos":[21363,21550],"source":"The **MediaStreamer::Initialize** method then creates an [**IMFMediaType**](https://msdn.microsoft.com/library/windows/desktop/ms704850) object to describe the format of the audio stream."},{"content":"An audio format has two types: a major type and a subtype.","pos":[21551,21609]},{"content":"The major type defines the overall format of the media, such as video, audio, script, and so on.","pos":[21610,21706]},{"content":"The subtype defines the format, such as PCM, ADPCM, or WMA.","pos":[21707,21766]},{"content":"The <bpt id=\"p1\">**</bpt>MediaStreamer::Initialize<ept id=\"p1\">**</ept> method uses the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IMFMediaType::SetGUID<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/bb970530)</ept> method to specify the major type as audio (<bpt id=\"p4\">**</bpt>MFMediaType\\_Audio<ept id=\"p4\">**</ept>) and the minor type as uncompressed PCM audio (<bpt id=\"p5\">**</bpt>MFAudioFormat\\_PCM<ept id=\"p5\">**</ept>).","pos":[21767,22043],"source":" The **MediaStreamer::Initialize** method uses the [**IMFMediaType::SetGUID**](https://msdn.microsoft.com/library/windows/desktop/bb970530) method to specify the major type as audio (**MFMediaType\\_Audio**) and the minor type as uncompressed PCM audio (**MFAudioFormat\\_PCM**)."},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IMFSourceReader::SetCurrentMediaType<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/bb970432)</ept> method associates the media type with the stream reader.","pos":[22044,22208],"source":" The [**IMFSourceReader::SetCurrentMediaType**](https://msdn.microsoft.com/library/windows/desktop/bb970432) method associates the media type with the stream reader."},{"content":"The <bpt id=\"p1\">**</bpt>MediaStreamer::Initialize<ept id=\"p1\">**</ept> method then obtains the complete output media format from Media Foundation and calls the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>MFCreateWaveFormatExFromMFMediaType<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ms702177)</ept> function to convert the Media Foundation audio media type to a <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>WAVEFORMATEX<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/hardware/ff538799)</ept> structure.","pos":[22751,23131],"source":"The **MediaStreamer::Initialize** method then obtains the complete output media format from Media Foundation and calls the [**MFCreateWaveFormatExFromMFMediaType**](https://msdn.microsoft.com/library/windows/desktop/ms702177) function to convert the Media Foundation audio media type to a [**WAVEFORMATEX**](https://msdn.microsoft.com/library/windows/hardware/ff538799) structure."},{"content":"The <bpt id=\"p1\">**</bpt>WAVEFORMATEX<ept id=\"p1\">**</ept> structure defines the format of waveform-audio data.","pos":[23132,23205],"source":" The **WAVEFORMATEX** structure defines the format of waveform-audio data."},{"content":"Marble Maze uses this structure to create the source voices and to apply the low-pass filter to the marble rolling sound.","pos":[23206,23327]},{"content":"<bpt id=\"p1\">**</bpt>Important<ept id=\"p1\">**</ept>   The <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>MFCreateWaveFormatExFromMFMediaType<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ms702177)</ept> function uses <bpt id=\"p4\">**</bpt>CoTaskMemAlloc<ept id=\"p4\">**</ept> to allocate the <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>WAVEFORMATEX<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/hardware/ff538799)</ept> object.","pos":[23763,24023],"source":"**Important**   The [**MFCreateWaveFormatExFromMFMediaType**](https://msdn.microsoft.com/library/windows/desktop/ms702177) function uses **CoTaskMemAlloc** to allocate the [**WAVEFORMATEX**](https://msdn.microsoft.com/library/windows/hardware/ff538799) object."},{"content":"Therefore, make sure that you call <bpt id=\"p1\">**</bpt>CoTaskMemFree<ept id=\"p1\">**</ept> when you are finished using this object.","pos":[24024,24117],"source":" Therefore, make sure that you call **CoTaskMemFree** when you are finished using this object."},{"content":"The <bpt id=\"p1\">**</bpt>MediaStreamer::Initialize<ept id=\"p1\">**</ept> method finishes by computing the length of the stream, m\\_<bpt id=\"p2\">*</bpt>maxStreamLengthInBytes<ept id=\"p2\">*</ept>, in bytes.","pos":[24122,24249],"source":"The **MediaStreamer::Initialize** method finishes by computing the length of the stream, m\\_*maxStreamLengthInBytes*, in bytes."},{"content":"To do so, it calls the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IMFSourceReader::IMFSourceReader::GetPresentationAttribute<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/dd374662)</ept> method to get the duration of the audio stream in 100-nanosecond units, converts the duration to sections, and then multiplies by the average data transfer rate in bytes per second.","pos":[24250,24580],"source":" To do so, it calls the [**IMFSourceReader::IMFSourceReader::GetPresentationAttribute**](https://msdn.microsoft.com/library/windows/desktop/dd374662) method to get the duration of the audio stream in 100-nanosecond units, converts the duration to sections, and then multiplies by the average data transfer rate in bytes per second."},{"content":"Marble Maze later uses this value to allocate the buffer that holds each game play sound.","pos":[24581,24670]},{"content":"Creating the source voices","pos":[25281,25307]},{"content":"Marble Maze creates XAudio2 source voices to play each of its game sounds and music in source voices.","pos":[25309,25410]},{"content":"The <bpt id=\"p1\">**</bpt>Audio<ept id=\"p1\">**</ept> class defines an <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IXAudio2SourceVoice<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ee415914)</ept> object for the background music and an array of <bpt id=\"p4\">**</bpt>SoundEffectData<ept id=\"p4\">**</ept> objects to hold the game play sounds.","pos":[25411,25634],"source":" The **Audio** class defines an [**IXAudio2SourceVoice**](https://msdn.microsoft.com/library/windows/desktop/ee415914) object for the background music and an array of **SoundEffectData** objects to hold the game play sounds."},{"content":"The <bpt id=\"p1\">**</bpt>SoundEffectData<ept id=\"p1\">**</ept> structure holds the <bpt id=\"p2\">**</bpt>IXAudio2SourceVoice<ept id=\"p2\">**</ept> object for an effect and also defines other effect-related data, such as the audio buffer.","pos":[25635,25793],"source":" The **SoundEffectData** structure holds the **IXAudio2SourceVoice** object for an effect and also defines other effect-related data, such as the audio buffer."},{"content":"Audio.h defines the <bpt id=\"p1\">**</bpt>SoundEvent<ept id=\"p1\">**</ept> enumeration.","pos":[25794,25841],"source":" Audio.h defines the **SoundEvent** enumeration."},{"content":"Marble Maze uses this enumeration to identify each game play sound.","pos":[25842,25909]},{"content":"The Audio class also uses this enumeration to index the array of <bpt id=\"p1\">**</bpt>SoundEffectData<ept id=\"p1\">**</ept> objects.","pos":[25910,26003],"source":" The Audio class also uses this enumeration to index the array of **SoundEffectData** objects."},{"content":"The following table shows the relationship between each of these values, the file that contains the associated sound data, and a brief description of what each sound represents.","pos":[26232,26409]},{"content":"The audio files are located in the \\\\Media\\\\Audio folder.","pos":[26410,26467]},{"content":"SoundEvent value","pos":[26471,26487]},{"content":"File name","pos":[26491,26500]},{"content":"Description","pos":[26508,26519]},{"content":"RollingEvent","pos":[26667,26679]},{"content":"MarbleRoll.wav","pos":[26687,26701]},{"content":"Played as the marble rolls.","pos":[26704,26731]},{"content":"FallingEvent","pos":[26765,26777]},{"content":"MarbleFall.wav","pos":[26785,26799]},{"content":"Played when the marble falls off the maze.","pos":[26802,26844]},{"content":"CollisionEvent","pos":[26863,26877]},{"content":"MarbleHit.wav","pos":[26883,26896]},{"content":"Played when the marble collides with the maze.","pos":[26900,26946]},{"content":"CheckpointEvent","pos":[26961,26976]},{"content":"Checkpoint.wav","pos":[26981,26995]},{"content":"Played when the marble passes over a checkpoint.","pos":[26998,27046]},{"content":"MenuChangeEvent","pos":[27059,27074]},{"content":"MenuChange.wav","pos":[27079,27093]},{"content":"Played when the game user changes the current menu item.","pos":[27096,27152]},{"content":"MenuSelectedEvent","pos":[27157,27174]},{"content":"MenuSelect.wav","pos":[27177,27191]},{"content":"Played when the game user selects a menu item.","pos":[27194,27240]},{"content":"The following example shows how the <bpt id=\"p1\">**</bpt>Audio::CreateResources<ept id=\"p1\">**</ept> method creates the source voice for the background music.","pos":[27257,27377],"source":"The following example shows how the **Audio::CreateResources** method creates the source voice for the background music."},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2::CreateSourceVoice<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee418607)</ept> method creates and configures a source voice.","pos":[27378,27522],"source":" The [**IXAudio2::CreateSourceVoice**](https://msdn.microsoft.com/library/windows/desktop/ee418607) method creates and configures a source voice."},{"content":"It takes a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>WAVEFORMATEX<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/hardware/ff538799)</ept> structure that defines the format of the audio buffers that are sent to the voice.","pos":[27523,27697],"source":" It takes a [**WAVEFORMATEX**](https://msdn.microsoft.com/library/windows/hardware/ff538799) structure that defines the format of the audio buffers that are sent to the voice."},{"content":"As mentioned previously, Marble Maze uses the PCM format.","pos":[27698,27755]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2\\_SEND\\_DESCRIPTOR<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419244)</ept> structure defines the target destination voice from another voice and specifies whether a filter should be used.","pos":[27756,27965],"source":" The [**XAUDIO2\\_SEND\\_DESCRIPTOR**](https://msdn.microsoft.com/library/windows/desktop/ee419244) structure defines the target destination voice from another voice and specifies whether a filter should be used."},{"content":"Marble Maze calls the <bpt id=\"p1\">**</bpt>Audio::SetSoundEffectFilter<ept id=\"p1\">**</ept> function to use the filters to change the sound of the ball as it rolls.","pos":[27966,28092],"source":" Marble Maze calls the **Audio::SetSoundEffectFilter** function to use the filters to change the sound of the ball as it rolls."},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>XAUDIO2\\_VOICE\\_SENDS<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee419246)</ept> structure defines the set of voices to receive data from a single output voice.","pos":[28093,28265],"source":" The [**XAUDIO2\\_VOICE\\_SENDS**](https://msdn.microsoft.com/library/windows/desktop/ee419246) structure defines the set of voices to receive data from a single output voice."},{"content":"Marble Maze sends data from the source voice to the mastering voice (for the dry, or unaltered, portion of a playing sound) and to the two submix voices that implement the wet, or reverberant, portion of a playing sound.","pos":[28266,28486]},{"content":"Playing background music","pos":[29590,29614]},{"content":"A source voice is created in the stopped state.","pos":[29617,29664]},{"content":"Marble Maze starts the background music in the game loop.","pos":[29665,29722]},{"content":"The first call to <bpt id=\"p1\">**</bpt>MarbleMaze::Update<ept id=\"p1\">**</ept> calls <bpt id=\"p2\">**</bpt>Audio::Start<ept id=\"p2\">**</ept> to start the background music.","pos":[29723,29817],"source":" The first call to **MarbleMaze::Update** calls **Audio::Start** to start the background music."},{"pos":[29887,30077],"content":"The <bpt id=\"p1\">**</bpt>Audio::Start<ept id=\"p1\">**</ept> method calls <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IXAudio2SourceVoice::Start<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ee418471)</ept> to start to process the source voice for the background music.","source":"The **Audio::Start** method calls [**IXAudio2SourceVoice::Start**](https://msdn.microsoft.com/library/windows/desktop/ee418471) to start to process the source voice for the background music."},{"content":"The source voice passes that audio data to the next stage of the audio graph.","pos":[30371,30448]},{"content":"In the case of Marble Maze, the next stage contains two submix voices that apply the two reverb effects to the audio.","pos":[30449,30566]},{"content":"One submix voice applies a close late-field reverb; the second applies a far late-field reverb.","pos":[30567,30662]},{"content":"The amount that each submix voice contributes to the final mix is determined by the size and shape of the room.","pos":[30663,30774]},{"content":"The near-field reverb contributes more when the ball is near a wall or in a small room, and the late-field reverb contributes more when the ball is in a large space.","pos":[30775,30940]},{"content":"This technique produces a more realistic echo effect as the marble moves through the maze.","pos":[30941,31031]},{"content":"To learn more about how Marble Maze implements this effect, see <bpt id=\"p1\">**</bpt>Audio::SetRoomSize<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>Physics::CalculateCurrentRoomSize<ept id=\"p2\">**</ept> in the Marble Maze source code.","pos":[31032,31192],"source":" To learn more about how Marble Maze implements this effect, see **Audio::SetRoomSize** and **Physics::CalculateCurrentRoomSize** in the Marble Maze source code."},{"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>  In a game in which most room sizes are relatively the same, you can use a more basic reverb model.","pos":[31196,31304],"source":"**Note**  In a game in which most room sizes are relatively the same, you can use a more basic reverb model."},{"content":"For example, you can use one reverb setting for all rooms or you can create a predefined reverb setting for each room.","pos":[31305,31423]},{"content":"The <bpt id=\"p1\">**</bpt>Audio::CreateResources<ept id=\"p1\">**</ept> method uses Media Foundation to load the background music.","pos":[31428,31517],"source":"The **Audio::CreateResources** method uses Media Foundation to load the background music."},{"content":"At this point, however, the source voice does not have audio data to work with.","pos":[31518,31597]},{"content":"In addition, because the background music loops, the source voice must be regularly updated with data so that the music continues to play.","pos":[31598,31736]},{"content":"To keep the source voice filled with data, the game loop updates the audio buffers every frame.","pos":[31737,31832]},{"content":"The <bpt id=\"p1\">**</bpt>MarbleMaze::Render<ept id=\"p1\">**</ept> method calls <bpt id=\"p2\">**</bpt>Audio::Render<ept id=\"p2\">**</ept> to process the background music audio buffer.","pos":[31833,31936],"source":" The **MarbleMaze::Render** method calls **Audio::Render** to process the background music audio buffer."},{"content":"The <bpt id=\"p1\">**</bpt>Audio::Render<ept id=\"p1\">**</ept> defines an array of three audio buffers, <bpt id=\"p2\">**</bpt>m\\_audioBuffers<ept id=\"p2\">**</ept>.","pos":[31937,32020],"source":" The **Audio::Render** defines an array of three audio buffers, **m\\_audioBuffers**."},{"content":"Each buffer holds 64 KB (65536 bytes) of data.","pos":[32021,32067]},{"content":"The loop reads data from the Media Foundation object and writes that data to the source voice until the source voice has three queued buffers.","pos":[32068,32210]},{"content":"<bpt id=\"p1\">**</bpt>Caution<ept id=\"p1\">**</ept>  Although Marble Maze uses a 64 KB buffer to hold music data, you may need to use a larger or smaller buffer.","pos":[32214,32335],"source":"**Caution**  Although Marble Maze uses a 64 KB buffer to hold music data, you may need to use a larger or smaller buffer."},{"content":"This amount depends on the requirements of your game.","pos":[32336,32389]},{"content":"The loop also handles when the Media Foundation object reaches the end of the stream.","pos":[34027,34112]},{"content":"In this case, it calls the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>MediaStreamer::OnClockRestart<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ms697215)</ept> method to reset the position of the audio source.","pos":[34113,34286],"source":" In this case, it calls the [**MediaStreamer::OnClockRestart**](https://msdn.microsoft.com/library/windows/desktop/ms697215) method to reset the position of the audio source."},{"content":"To implement audio looping for a single buffer (or for an entire sound that is fully loaded into memory), you can set the <bpt id=\"p1\">**</bpt>LoopCount<ept id=\"p1\">**</ept> field to <bpt id=\"p2\">**</bpt>XAUDIO2\\_LOOP\\_INFINITE<ept id=\"p2\">**</ept> when you initialize the sound.","pos":[34527,34730],"source":"To implement audio looping for a single buffer (or for an entire sound that is fully loaded into memory), you can set the **LoopCount** field to **XAUDIO2\\_LOOP\\_INFINITE** when you initialize the sound."},{"content":"Marble Maze uses this technique to play the rolling sound for the marble.","pos":[34731,34804]},{"content":"However, for the background music, Marble Maze manages the buffers directly so that it can better control the amount of memory that is used.","pos":[34923,35063]},{"content":"When your music files are large, you can stream the music data into smaller buffers.","pos":[35064,35148]},{"content":"Doing so can help balance memory size with the frequency of the gameâ€™s ability to process and stream audio data.","pos":[35149,35261]},{"content":"<bpt id=\"p1\">**</bpt>Tip<ept id=\"p1\">**</ept>  If your game has a low or varying frame rate, processing audio on the main thread can produce unexpected pauses or pops in the audio because the audio engine has insufficient buffered audio data to work with.","pos":[35265,35482],"source":"**Tip**  If your game has a low or varying frame rate, processing audio on the main thread can produce unexpected pauses or pops in the audio because the audio engine has insufficient buffered audio data to work with."},{"content":"If your game is sensitive to this issue, consider processing audio on a separate thread that does not perform rendering.","pos":[35483,35603]},{"content":"This approach is especially useful on computers that have multiple processors because your game can use idle processors.","pos":[35604,35724]},{"content":"Reacting to game events","pos":[35733,35756]},{"content":"The <bpt id=\"p1\">**</bpt>MarbleMaze<ept id=\"p1\">**</ept> class provides methods such as <bpt id=\"p2\">**</bpt>PlaySoundEffect<ept id=\"p2\">**</ept>, <bpt id=\"p3\">**</bpt>IsSoundEffectStarted<ept id=\"p3\">**</ept>, <bpt id=\"p4\">**</bpt>StopSoundEffect<ept id=\"p4\">**</ept>, <bpt id=\"p5\">**</bpt>SetSoundEffectVolume<ept id=\"p5\">**</ept>, <bpt id=\"p6\">**</bpt>SetSoundEffectPitch<ept id=\"p6\">**</ept>, and <bpt id=\"p7\">**</bpt>SetSoundEffectFilter<ept id=\"p7\">**</ept> to enable the game to control when sounds play and stop, and to control sound properties such as volume and pitch.","pos":[35759,36071],"source":"The **MarbleMaze** class provides methods such as **PlaySoundEffect**, **IsSoundEffectStarted**, **StopSoundEffect**, **SetSoundEffectVolume**, **SetSoundEffectPitch**, and **SetSoundEffectFilter** to enable the game to control when sounds play and stop, and to control sound properties such as volume and pitch."},{"content":"For example, if the marble falls off the maze, <bpt id=\"p1\">**</bpt>MarbleMaze::Update<ept id=\"p1\">**</ept> method calls the <bpt id=\"p2\">**</bpt>Audio::PlaySoundEffect<ept id=\"p2\">**</ept> method to play the <bpt id=\"p3\">**</bpt>FallingEvent<ept id=\"p3\">**</ept> sound.","pos":[36072,36228],"source":" For example, if the marble falls off the maze, **MarbleMaze::Update** method calls the **Audio::PlaySoundEffect** method to play the **FallingEvent** sound."},{"content":"The <bpt id=\"p1\">**</bpt>Audio::PlaySoundEffect<ept id=\"p1\">**</ept> method calls the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IXAudio2SourceVoice::Start<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/ee418471)</ept> method to begin playback of the sound.","pos":[36281,36461],"source":"The **Audio::PlaySoundEffect** method calls the [**IXAudio2SourceVoice::Start**](https://msdn.microsoft.com/library/windows/desktop/ee418471) method to begin playback of the sound."},{"content":"If the <bpt id=\"p1\">**</bpt>IXAudio2SourceVoice::Start<ept id=\"p1\">**</ept> method has already been called, it is not started again.","pos":[36462,36556],"source":" If the **IXAudio2SourceVoice::Start** method has already been called, it is not started again."},{"content":"<bpt id=\"p1\">**</bpt>Audio::PlaySoundEffect<ept id=\"p1\">**</ept> then performs custom logic for certain sounds.","pos":[36557,36630],"source":"**Audio::PlaySoundEffect** then performs custom logic for certain sounds."},{"content":"For sounds other than rolling, the <bpt id=\"p1\">**</bpt>Audio::PlaySoundEffect<ept id=\"p1\">**</ept> method calls <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IXAudio2SourceVoice::GetState<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/desktop/hh405047)</ept> to determine the number of buffers that the source voice is playing.","pos":[38550,38790],"source":"For sounds other than rolling, the **Audio::PlaySoundEffect** method calls [**IXAudio2SourceVoice::GetState**](https://msdn.microsoft.com/library/windows/desktop/hh405047) to determine the number of buffers that the source voice is playing."},{"content":"It calls <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2SourceVoice::SubmitSourceBuffer<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee418473)</ept> to add the audio data for the sound to the voiceâ€™s input queue if no buffers are active.","pos":[38791,38995],"source":" It calls [**IXAudio2SourceVoice::SubmitSourceBuffer**](https://msdn.microsoft.com/library/windows/desktop/ee418473) to add the audio data for the sound to the voiceâ€™s input queue if no buffers are active."},{"content":"The <bpt id=\"p1\">**</bpt>Audio::PlaySoundEffect<ept id=\"p1\">**</ept> method also enables the collision sound to be played two times in sequence.","pos":[38996,39102],"source":" The **Audio::PlaySoundEffect** method also enables the collision sound to be played two times in sequence."},{"content":"This occurs, for example, when the marble collides with a corner of the maze.","pos":[39103,39180]},{"content":"As already described, the Audio class uses the <bpt id=\"p1\">**</bpt>XAUDIO2\\_LOOP\\_INFINITE<ept id=\"p1\">**</ept> flag when it initializes the sound for the rolling event.","pos":[39182,39314],"source":"As already described, the Audio class uses the **XAUDIO2\\_LOOP\\_INFINITE** flag when it initializes the sound for the rolling event."},{"content":"The sound starts looped playback the first time that <bpt id=\"p1\">**</bpt>Audio::PlaySoundEffect<ept id=\"p1\">**</ept> is called for this event.","pos":[39315,39420],"source":" The sound starts looped playback the first time that **Audio::PlaySoundEffect** is called for this event."},{"content":"To simplify the playback logic for the rolling sound, Marble Maze mutes the sound instead of stopping it.","pos":[39421,39526]},{"content":"As the marble changes velocity, Marble Maze changes the pitch and volume of the sound to give it a more realistic effect.","pos":[39527,39648]},{"content":"The following shows how the <bpt id=\"p1\">**</bpt>MarbleMaze::Update<ept id=\"p1\">**</ept> method updates the pitch and volume of the marble as its velocity changes and how it mutes the sound by setting its volume to zero when the marble stops.","pos":[39649,39853],"source":" The following shows how the **MarbleMaze::Update** method updates the pitch and volume of the marble as its velocity changes and how it mutes the sound by setting its volume to zero when the marble stops."},{"content":"Reacting to suspend and resume events","pos":[40720,40757]},{"content":"The document Marble Maze application structure describes how Marble Maze supports suspend and resume.","pos":[40760,40861]},{"content":"When the game is suspended, the game pauses the audio.","pos":[40862,40916]},{"content":"When the game resumes, the game resumes the audio where it left off.","pos":[40917,40985]},{"content":"We do so to follow the best practice of not using resources when you know theyâ€™re not needed.","pos":[40986,41079]},{"content":"The <bpt id=\"p1\">**</bpt>Audio::SuspendAudio<ept id=\"p1\">**</ept> method is called when the game is suspended.","pos":[41081,41153],"source":"The **Audio::SuspendAudio** method is called when the game is suspended."},{"content":"This method calls the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2::StopEngine<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee418628)</ept> method to stop all audio.","pos":[41154,41289],"source":" This method calls the [**IXAudio2::StopEngine**](https://msdn.microsoft.com/library/windows/desktop/ee418628) method to stop all audio."},{"content":"Although <bpt id=\"p1\">**</bpt>IXAudio2::StopEngine<ept id=\"p1\">**</ept> stops all audio output immediately, it preserves the audio graph and its effect parameters (for example, the reverb effect thatâ€™s applied when the marble bounces).","pos":[41290,41487],"source":" Although **IXAudio2::StopEngine** stops all audio output immediately, it preserves the audio graph and its effect parameters (for example, the reverb effect thatâ€™s applied when the marble bounces)."},{"content":"The <bpt id=\"p1\">**</bpt>Audio::ResumeAudio<ept id=\"p1\">**</ept> method is called when the game is resumed.","pos":[42154,42223],"source":"The **Audio::ResumeAudio** method is called when the game is resumed."},{"content":"This method uses the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2::StartEngine<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee418626)</ept> method to restart the audio.","pos":[42224,42362],"source":" This method uses the [**IXAudio2::StartEngine**](https://msdn.microsoft.com/library/windows/desktop/ee418626) method to restart the audio."},{"content":"Because the call to <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2::StopEngine<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee418628)</ept> preserves the audio graph and its effect parameters, the audio output resumes where it left off.","pos":[42363,42567],"source":" Because the call to [**IXAudio2::StopEngine**](https://msdn.microsoft.com/library/windows/desktop/ee418628) preserves the audio graph and its effect parameters, the audio output resumes where it left off."},{"content":"Handling headphones and device changes","pos":[43232,43270]},{"content":"Marble maze uses engine callbacks to handle XAudio2 engine failures, such as when the audio device changes.","pos":[43273,43380]},{"content":"A likely cause of a device change is when the game user connects or disconnects the headphones.","pos":[43381,43476]},{"content":"We recommend that you implement the engine callback that handles device changes.","pos":[43477,43557]},{"content":"Otherwise, your game will stop playing sound when the user plugs in or removes headphones, until the game is restarted.","pos":[43558,43677]},{"content":"Audio.h defines the <bpt id=\"p1\">**</bpt>AudioEngineCallbacks<ept id=\"p1\">**</ept> class.","pos":[43679,43730],"source":"Audio.h defines the **AudioEngineCallbacks** class."},{"content":"This class implements the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2EngineCallback<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415910)</ept> interface.","pos":[43731,43857],"source":" This class implements the [**IXAudio2EngineCallback**](https://msdn.microsoft.com/library/windows/desktop/ee415910) interface."},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2EngineCallback<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415910)</ept> interface enables your code to be notified when audio processing events occur and when the engine encounters a critical error.","pos":[44435,44655],"source":"The [**IXAudio2EngineCallback**](https://msdn.microsoft.com/library/windows/desktop/ee415910) interface enables your code to be notified when audio processing events occur and when the engine encounters a critical error."},{"content":"To register for callbacks, Marble Maze calls the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2::RegisterForCallbacks<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee418620)</ept> method after it creates the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IXAudio2<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</ept> object for the music engine.","pos":[44656,44935],"source":" To register for callbacks, Marble Maze calls the [**IXAudio2::RegisterForCallbacks**](https://msdn.microsoft.com/library/windows/desktop/ee418620) method after it creates the [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) object for the music engine."},{"content":"Marble Maze does not require notification when audio processing starts or ends.","pos":[45050,45129]},{"content":"Therefore, it implements the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2EngineCallback::OnProcessingPassStart<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee418463)</ept> and <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IXAudio2EngineCallback::OnProcessingPassEnd<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/desktop/ee418462)</ept> methods to do nothing.","pos":[45130,45409],"source":" Therefore, it implements the [**IXAudio2EngineCallback::OnProcessingPassStart**](https://msdn.microsoft.com/library/windows/desktop/ee418463) and [**IXAudio2EngineCallback::OnProcessingPassEnd**](https://msdn.microsoft.com/library/windows/desktop/ee418462) methods to do nothing."},{"content":"For the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IXAudio2EngineCallback::OnCriticalError<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee418461)</ept> method, Marble Maze calls the <bpt id=\"p3\">**</bpt>SetEngineExperiencedCriticalError<ept id=\"p3\">**</ept> method, which sets the <bpt id=\"p4\">**</bpt>m\\_engineExperiencedCriticalError<ept id=\"p4\">**</ept> flag.","pos":[45410,45659],"source":" For the [**IXAudio2EngineCallback::OnCriticalError**](https://msdn.microsoft.com/library/windows/desktop/ee418461) method, Marble Maze calls the **SetEngineExperiencedCriticalError** method, which sets the **m\\_engineExperiencedCriticalError** flag."},{"content":"When a critical error occurs, audio processing stops and all additional calls to XAudio2 fail.","pos":[46229,46323]},{"content":"To recover from this situation, you must release the XAudio2 instance and create a new one.","pos":[46324,46415]},{"content":"The <bpt id=\"p1\">**</bpt>Audio::Render<ept id=\"p1\">**</ept> method, which is called from the game loop every frame, first checks the <bpt id=\"p2\">**</bpt>m\\_engineExperiencedCriticalError<ept id=\"p2\">**</ept> flag.","pos":[46416,46554],"source":" The **Audio::Render** method, which is called from the game loop every frame, first checks the **m\\_engineExperiencedCriticalError** flag."},{"content":"If this flag is set, it clears the flag, releases the current XAudio2 instance, initializes resources, and then starts the background music.","pos":[46555,46695]},{"content":"Marble Maze also uses the <bpt id=\"p1\">**</bpt>m\\_engineExperiencedCriticalError<ept id=\"p1\">**</ept> flag to guard against calling into XAudio2 when no audio device is available.","pos":[46945,47086],"source":"Marble Maze also uses the **m\\_engineExperiencedCriticalError** flag to guard against calling into XAudio2 when no audio device is available."},{"content":"For example, the <bpt id=\"p1\">**</bpt>MarbleMaze::Update<ept id=\"p1\">**</ept> method does not process audio for rolling or collision events when this flag is set.","pos":[47087,47211],"source":" For example, the **MarbleMaze::Update** method does not process audio for rolling or collision events when this flag is set."},{"content":"The app attempts to repair the audio engine every frame if it is required; however, the <bpt id=\"p1\">**</bpt>m\\_engineExperiencedCriticalError<ept id=\"p1\">**</ept> flag might always be set if the computer does not have an audio device or the headphones are unplugged and there is no other available audio device.","pos":[47212,47486],"source":" The app attempts to repair the audio engine every frame if it is required; however, the **m\\_engineExperiencedCriticalError** flag might always be set if the computer does not have an audio device or the headphones are unplugged and there is no other available audio device."},{"content":"<bpt id=\"p1\">**</bpt>Caution<ept id=\"p1\">**</ept>   As a rule, do not perform blocking operations in the body of an engine callback.","pos":[47490,47584],"source":"**Caution**   As a rule, do not perform blocking operations in the body of an engine callback."},{"content":"Doing so can cause performance issues.","pos":[47585,47623]},{"content":"Marble Maze sets a flag in the <bpt id=\"p1\">**</bpt>OnCriticalError<ept id=\"p1\">**</ept> callback and later handles the error during the regular audio processing phase.","pos":[47624,47754],"source":" Marble Maze sets a flag in the **OnCriticalError** callback and later handles the error during the regular audio processing phase."},{"content":"For more information about XAudio2 callbacks, see <bpt id=\"p1\">[</bpt>XAudio2 Callbacks<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415745)</ept>.","pos":[47755,47886],"source":" For more information about XAudio2 callbacks, see [XAudio2 Callbacks](https://msdn.microsoft.com/library/windows/desktop/ee415745)."},{"content":"Related topics","pos":[47894,47908]},{"content":"Adding input and interactivity to the Marble Maze sample","pos":[47914,47970]},{"content":"Developing Marble Maze, a UWP game in C++ and DirectX","pos":[48036,48089]}],"content":"---\ntitle: Adding audio to the Marble Maze sample\ndescription: This document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices.\nms.assetid: 77c23d0a-af6d-17b5-d69e-51d9885b0d44\n---\n\n# Adding audio to the Marble Maze sample\n\n\n\\[ Updated for UWP apps on Windows 10. For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]\n\n\nThis document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices. Marble Maze uses Microsoft Media Foundation to load audio resources from file, and XAudio2 to mix and play audio and to apply effects to audio.\n\nMarble Maze plays music in the background, and also uses game-play sounds to indicate game events, such as when the marble hits a wall. An important part of the implementation is that Marble Maze uses a reverb, or echo, effect to simulate the sound of a marble when it bounces. The reverb effect implementation causes echoes to reach you more quickly and loudly in small rooms; echoes are quieter and reach you more slowly in larger rooms.\n\n> **Note**   The sample code that corresponds to this document is found in the [DirectX Marble Maze game sample](http://go.microsoft.com/fwlink/?LinkId=624011).\n\nHere are some of the key points that this document discusses for when you work with audio in your game:\n\n-   Consider using Media Foundation to decode audio assets and XAudio2 to play audio. However, if you have an existing audio asset-loading mechanism that works in a Universal Windows Platform (UWP) app, you can use it.\n-   An audio graph contains one source voice for each active sound, zero or more submix voices, and one mastering voice. Source voices can feed into submix voices and/or the mastering voice. Submix voices feed into other submix voices or the mastering voice.\n-   If your background music files are large, consider streaming your music into smaller buffers so that less memory is used.\n-   If it makes sense to do so, pause audio playback when the app loses focus or visibility, or is suspended. Resume playback when your app regains focus, becomes visible, or is resumed.\n-   Set audio categories to reflect the role of each sound. For example, you typically use **AudioCategory\\_GameMedia** for game background audio and **AudioCategory\\_GameEffects** for sound effects.\n-   Handle device changes, including headphones, by releasing and recreating all audio resources and interfaces.\n-   Consider whether to compress audio files when minimizing disk space and streaming costs is a requirement. Otherwise, you can leave audio uncompressed so that it loads faster.\n\n## Introducing XAudio2 and Microsoft Media Foundation\n\n\nXAudio2 is a low-level audio library for Windows that specifically supports game audio. It provides a digital signal processing (DSP) and audio-graph engine for games. XAudio2 expands on its predecessors, DirectSound and XAudio, by supporting computing trends such as SIMD floating-point architectures and HD audio. It also supports the more complex sound processing demands of todayâ€™s games.\n\nThe document [XAudio2 Key Concepts](https://msdn.microsoft.com/library/windows/desktop/ee415764) explains the key concepts for using XAudio2. In brief, the concepts are:\n\n-   The [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) interface is the core of the XAudio2 engine. Marble Maze uses this interface to create voices and to receive notification when the output device changes or fails.\n-   A voice processes, adjusts, and plays audio data.\n-   A source voice is a collection of audio channels (mono, 5.1, and so on) and represents one stream of audio data. In XAudio2, a source voice is where audio processing begins. Typically, sound data is loaded from an external source, such as a file or a network, and is sent to a source voice. Marble Maze uses [Media Foundation](https://msdn.microsoft.com/library/windows/desktop/ms694197) to load sound data from files. Media Foundation is introduced later in this document.\n-   A submix voice processes audio data. This processing can include changing the audio stream or combining multiple streams into one. Marble Maze uses submixes to create the reverb effect.\n-   A mastering voice combines data from source and submix voices and sends that data to the audio hardware.\n-   An audio graph contains one source voice for each active sound, zero or more submix voices, and only one mastering voice.\n-   A callback informs client code that some event has occurred in a voice or in an engine object. By using callbacks, you can reuse memory when XAudio2 is finished with a buffer, react when the audio device changes (for example, when you connect or disconnect headphones), and more. The [Handling headphones and device changes section](#phones) later in this document explains how Marble Maze uses this mechanism to handle device changes.\n\nMarble Maze uses two audio engines (in other words, two [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) objects) to process audio. One engine processes the background music, and the other engine processes game-play sounds.\n\nMarble Maze must also create one mastering voice for each engine. Recall that a mastering engine combines audio streams into one stream and sends that stream to the audio hardware. The background music stream, a source voice, outputs data to a mastering voice and to two submix voices. The submix voices perform the reverb effect.\n\nMedia Foundation is a multimedia library that supports many audio and video formats. XAudio2 and Media Foundation complement each other. Marble Maze uses Media Foundation to load audio assets from file and uses XAudio2 to play audio. You don't have to use Media Foundation to load audio assets. If you have an existing audio asset loading mechanism that works in Universal Windows Platform (UWP) apps, use it.\n\nFor more information about XAudio2, see [Programming Guide](https://msdn.microsoft.com/library/windows/desktop/ee415737). For more information about Media Foundation, see [Microsoft Media Foundation](https://msdn.microsoft.com/library/windows/desktop/ms694197).\n\n## Initializing audio resources\n\n\nMarble Mazes uses a Windows Media Audio (.wma) file for the background music, and WAV (.wav) files for game play sounds. These formats are supported by Media Foundation. Although the .wav file format is natively supported by XAudio2, a game has to parse the file format manually to fill out the appropriate XAudio2 data structures. Marble Maze uses Media Foundation to more easily work with .wav files. For the complete list of the media formats that are supported by Media Foundation, see [Supported Media Formats in Media Foundation](https://msdn.microsoft.com/library/windows/desktop/dd757927). Marble Maze does not use separate design-time and run-time audio formats, and does not use XAudio2 ADPCM compression support. For more information about ADPCM compression in XAudio2, see [ADPCM Overview](https://msdn.microsoft.com/library/windows/desktop/ee415711).\n\nThe **Audio::CreateResources** method, which is called from **MarbleMaze::CreateDeviceIndependentResources**, loads the audio streams from file, initializes the XAudio2 engine objects, and creates the source, submix, and mastering voices.\n\n###  Creating the XAudio2 engines\n\nRecall that Marble Maze creates one [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) object to represent each audio engine that it uses. To create an audio engine, call the [**XAudio2Create**](https://msdn.microsoft.com/library/windows/desktop/ee419212) function. The following example shows how Marble Maze creates the audio engine that processes background music.\n\n```cpp\nDX::ThrowIfFailed(\n    XAudio2Create(&m_musicEngine)\n    );\n```\n\nMarble Maze performs a similar step to create the audio engine that plays game-play sounds.\n\nHow to work with the [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) interface in a UWP app differs from a desktop app in two ways. First, you don't have to call **CoInitializeEx** before you call [**XAudio2Create**](https://msdn.microsoft.com/library/windows/desktop/ee419212). In addition, **IXAudio2** no longer supports device enumeration. For information about how to enumerate audio devices, see [Enumerating devices](https://msdn.microsoft.com/library/windows/apps/hh464977).\n\n###  Creating the mastering voices\n\nThe following example shows how the **Audio::CreateResources** method creates the mastering voice for the background music. The call to [**IXAudio2::CreateMasteringVoice**](https://msdn.microsoft.com/library/windows/desktop/hh405048) specifies two input channels. This simplifies the logic for the reverb effect. The **XAUDIO2\\_DEFAULT\\_SAMPLERATE** specification tells the audio engine to use the sample rate that is specified in the Sound Control Panel. In this example, **m\\_musicMasteringVoice** is an [**IXAudio2MasteringVoice**](https://msdn.microsoft.com/library/windows/desktop/ee415912) object.\n\n```cpp\n// This sample plays the equivalent of background music, which we tag on the  \n// mastering voice as AudioCategory_GameMedia. In ordinary usage, if we were  \n// playing the music track with no effects, we could route it entirely through \n// Media Foundation. Here, we are using XAudio2 to apply a reverb effect to the \n// music, so we use Media Foundation to decode the data then we feed it through \n// the XAudio2 pipeline as a separate Mastering Voice, so that we can tag it \n// as Game Media. We default the mastering voice to 2 channels to simplify  \n// the reverb logic.\nDX::ThrowIfFailed(\n    m_musicEngine->CreateMasteringVoice(\n        &m_musicMasteringVoice, \n        2, \n        48000, \n        0, \n        nullptr, \n        nullptr, \n        AudioCategory_GameMedia\n        )\n);\n```\n\nThe **Audio::CreateResources** method performs a similar step to create the mastering voice for the game play sounds, except that it specifies **AudioCategory\\_GameEffects** for the *StreamCategory* parameter, which is the default. Marble Maze specifies **AudioCategory\\_GameMedia** for background music so that users can listen to music from a different application as they play the game. When a music app is playing, Windows mutes any voices that are created by the **AudioCategory\\_GameMedia** option. The user still hears game-play sounds because they are created by the **AudioCategory\\_GameEffects** option. For more info about audio categories, see [**AUDIO\\_STREAM\\_CATEGORY**](https://msdn.microsoft.com/library/windows/desktop/hh404178) enumeration.\n\n###  Creating the reverb effect\n\nFor each voice, you can use XAudio2 to create sequences of effects that process audio. Such a sequence is known as an effect chain. Use effect chains when you want to apply one or more effects to a voice. Effect chains can be destructive; that is, each effect in the chain can overwrite the audio buffer. This property is important because XAudio2 makes no guarantee that output buffers are initialized with silence. Effect objects are represented in XAudio2 by cross-platform audio processing objects (XAPO). For more information about XAPO, see [XAPO Overviews](o:microsoft.directx_sdk.xapo.audio_overview_xapo).\n\nWhen you create an effect chain, follow these steps:\n\n1.  Create the effect object.\n2.  Populate an [**XAUDIO2\\_EFFECT\\_DESCRIPTOR**](https://msdn.microsoft.com/library/windows/desktop/ee419236) structure with effect data.\n3.  Populate an [**XAUDIO2\\_EFFECT\\_CHAIN**](https://msdn.microsoft.com/library/windows/desktop/ee419235) structure with data.\n4.  Apply the effect chain to a voice.\n5.  Populate an effect parameter structure and apply it to the effect.\n6.  Disable or enable the effect whenever appropriate.\n\nThe **Audio** class defines the **CreateReverb** method to create the effect chain that implements reverb. This method calls the [**XAudio2CreateReverb**](https://msdn.microsoft.com/library/windows/desktop/ee419213) function to create a [**IXAudio2SubmixVoice**](https://msdn.microsoft.com/library/windows/desktop/ee415915) object, which acts as the submix voice for the reverb effect.\n\n```cpp\nDX::ThrowIfFailed(\n    XAudio2CreateReverb(&soundEffectXAPO)\n    );\n```\n\nThe [**XAUDIO2\\_EFFECT\\_DESCRIPTOR**](https://msdn.microsoft.com/library/windows/desktop/ee419236) structure contains information about an XAPO for use in an effect chain, for example, the target number of output channels. The **Audio::CreateReverb** method creates an **XAUDIO2\\_EFFECT\\_DESCRIPTOR** object that is set to the disabled state, uses two output channels, and references the [**IXAudio2SubmixVoice**](https://msdn.microsoft.com/library/windows/desktop/ee415915) object for the reverb effect. The **XAUDIO2\\_EFFECT\\_DESCRIPTOR** object starts in the disabled state because the game must set parameters before the effect starts modifying game sounds. Marble Maze uses two output channels to simplify the logic for the reverb effect.\n\n```cpp\nsoundEffectdescriptor.InitialState = false;\nsoundEffectdescriptor.OutputChannels = 2;\nsoundEffectdescriptor.pEffect = soundEffectXAPO.Get();\n```\n\nIf your effect chain has multiple effects, each effect requires an object. The [**XAUDIO2\\_EFFECT\\_CHAIN**](https://msdn.microsoft.com/library/windows/desktop/ee419235) structure holds the array of [**XAUDIO2\\_EFFECT\\_DESCRIPTOR**](https://msdn.microsoft.com/library/windows/desktop/ee419236) objects that participate in the effect. The following example shows how the **Audio::CreateReverb** method specifies the one effect to implement reverb.\n\n```cpp\nsoundEffectChain.EffectCount = 1;\nsoundEffectChain.pEffectDescriptors = &soundEffectdescriptor;\n```\n\nThe **Audio::CreateReverb** method calls the [**IXAudio2::CreateSubmixVoice**](https://msdn.microsoft.com/library/windows/desktop/ee418608) method to create the submix voice for the effect. It specifies the [**XAUDIO2\\_EFFECT\\_CHAIN**](https://msdn.microsoft.com/library/windows/desktop/ee419235) object for the *pEffectChain* parameter to associate the effect chain with the voice. Marble Maze also specifies two output channels and a sample rate of 48 kilohertz. We chose this sample rate because it represented a balance between audio quality and the amount of required CPU processing. A greater sample rate would have required more CPU processing without having a noticeable quality benefit.\n\n```cpp\nDX::ThrowIfFailed(\n    engine->CreateSubmixVoice(newSubmix, 2, 48000, 0, 0, nullptr, &soundEffectChain)\n    );\n```\n\n> **Tip**   If you want to attach an existing effect chain to an existing submix voice, or you want to replace the current effect chain, use the [**IXAudio2Voice::SetEffectChain**](https://msdn.microsoft.com/library/windows/desktop/ee418594) method.\n\n \n\nThe [**Audio::XAudio2CreateReverb**](https://msdn.microsoft.com/library/windows/desktop/ee419213) method calls [**IXAudio2Voice::SetEffectParameters**](https://msdn.microsoft.com/library/windows/desktop/ee418595) to set additional parameters that are associated with the effect. This method takes a parameter structure that is specific to the effect. An [**XAUDIO2FX\\_REVERB\\_PARAMETERS**](https://msdn.microsoft.com/library/windows/desktop/ee419224) object, which contains the effect parameters for reverb, is initialized in the **Audio::Initialize** method because every reverb effect shares the same parameters. The following example shows how the **Audio::Initialize** method initializes the reverb parameters for near-field reverb.\n\n```cpp\nm_reverbParametersSmall.ReflectionsDelay = XAUDIO2FX_REVERB_DEFAULT_REFLECTIONS_DELAY;\nm_reverbParametersSmall.ReverbDelay = XAUDIO2FX_REVERB_DEFAULT_REVERB_DELAY;\nm_reverbParametersSmall.RearDelay = XAUDIO2FX_REVERB_DEFAULT_REAR_DELAY;\nm_reverbParametersSmall.PositionLeft = XAUDIO2FX_REVERB_DEFAULT_POSITION;\nm_reverbParametersSmall.PositionRight = XAUDIO2FX_REVERB_DEFAULT_POSITION;\nm_reverbParametersSmall.PositionMatrixLeft = XAUDIO2FX_REVERB_DEFAULT_POSITION_MATRIX;\nm_reverbParametersSmall.PositionMatrixRight = XAUDIO2FX_REVERB_DEFAULT_POSITION_MATRIX;\nm_reverbParametersSmall.EarlyDiffusion = 4;\nm_reverbParametersSmall.LateDiffusion = 15;\nm_reverbParametersSmall.LowEQGain = XAUDIO2FX_REVERB_DEFAULT_LOW_EQ_GAIN;\nm_reverbParametersSmall.LowEQCutoff = XAUDIO2FX_REVERB_DEFAULT_LOW_EQ_CUTOFF;\nm_reverbParametersSmall.HighEQGain = XAUDIO2FX_REVERB_DEFAULT_HIGH_EQ_GAIN;\nm_reverbParametersSmall.HighEQCutoff = XAUDIO2FX_REVERB_DEFAULT_HIGH_EQ_CUTOFF;\nm_reverbParametersSmall.RoomFilterFreq = XAUDIO2FX_REVERB_DEFAULT_ROOM_FILTER_FREQ;\nm_reverbParametersSmall.RoomFilterMain = XAUDIO2FX_REVERB_DEFAULT_ROOM_FILTER_MAIN;\nm_reverbParametersSmall.RoomFilterHF = XAUDIO2FX_REVERB_DEFAULT_ROOM_FILTER_HF;\nm_reverbParametersSmall.ReflectionsGain = XAUDIO2FX_REVERB_DEFAULT_REFLECTIONS_GAIN;\nm_reverbParametersSmall.ReverbGain = XAUDIO2FX_REVERB_DEFAULT_REVERB_GAIN;\nm_reverbParametersSmall.DecayTime = XAUDIO2FX_REVERB_DEFAULT_DECAY_TIME;\nm_reverbParametersSmall.Density = XAUDIO2FX_REVERB_DEFAULT_DENSITY;\nm_reverbParametersSmall.RoomSize = XAUDIO2FX_REVERB_DEFAULT_ROOM_SIZE;\nm_reverbParametersSmall.WetDryMix = XAUDIO2FX_REVERB_DEFAULT_WET_DRY_MIX;\nm_reverbParametersSmall.DisableLateField = TRUE;\n```\n\nThis example uses the default values for most of the reverb parameters, but it sets **DisableLateField** to TRUE to specify near-field reverb, **EarlyDiffusion** to 4 to simulate flat near surfaces, and **LateDiffusion** to 15 to simulate very diffuse distant surfaces. Flat near surfaces cause echoes to reach you more quickly and loudly; diffuse distant surfaces cause echoes to be quieter and reach you more slowly. You can experiment with reverb values to get the desired effect in your game or use the **ReverbConvertI3DL2ToNative** function to use industry-standard I3DL2 (Interactive 3D Audio Rendering Guidelines Level 2.0) parameters.\n\nThe following example shows how **Audio::CreateReverb** sets the reverb parameters. The parameters parameter is an [**XAUDIO2FX\\_REVERB\\_PARAMETERS**](https://msdn.microsoft.com/library/windows/desktop/ee419224) object.\n\n```cpp\nDX::ThrowIfFailed(\n    (*newSubmix)->SetEffectParameters(0, parameters, sizeof(m_reverbParametersSmall))\n    );\n```\n\nThe **Audio::CreateReverb** method finishes by enabling the effect if the **enableEffect** flag is set and by setting its volume and output matrix. This part sets the volume to full (1.0) and then specifies the volume matrix to be silence for both left and right inputs and left and right output speakers. We do this because other code later cross-fades between the two reverbs (simulating the transition from being near a wall to being in a large room), or mutes both reverbs if required. When the reverb path is later unmuted, the game sets a matrix of {1.0f, 0.0f, 0.0f, 1.0f} to route left reverb output to the left input of the mastering voice and right reverb output to the right input of the mastering voice.\n\n```cpp\nif (enableEffect)\n{\n    DX::ThrowIfFailed(\n        (*newSubmix)->EnableEffect(0)\n        );    \n}\n\nDX::ThrowIfFailed(\n    (*newSubmix)->SetVolume (1.0f)\n    );\n\nfloat outputMatrix[4] = {0, 0, 0, 0};\nDX::ThrowIfFailed(\n    (*newSubmix)->SetOutputMatrix(masteringVoice, 2, 2, outputMatrix)\n    );\n```\n\nMarble Maze calls the **CreateReverb** method four times; two times for the background music and two times for the game-play sounds. The following shows how Marble Maze calls the **CreateReverb** method for the background music.\n\n```cpp\nCreateReverb(\n    m_musicEngine, \n    m_musicMasteringVoice, \n    &m_reverbParametersSmall, \n    &m_musicReverbVoiceSmallRoom, \n    true\n    );\nCreateReverb(\n    m_musicEngine, \n    m_musicMasteringVoice, \n    &m_reverbParametersLarge, \n    &m_musicReverbVoiceLargeRoom, \n    true\n    );\n```\n\nFor a list of possible sources of effects for use with XAudio2, see [XAudio2 Audio Effects](https://msdn.microsoft.com/library/windows/desktop/ee415756).\n\n### Loading audio data from file\n\nMarble Maze defines the **MediaStreamer** class, which uses Media Foundation to load audio resources from file. Marble Maze uses one **MediaStreamer** object to load each audio file.\n\nMarble Maze calls the **MediaStreamer::Initialize** method to initialize each audio stream. Here's how the **Audio::CreateResources** method calls **MediaStreamer::Initialize** to initialize the audio stream for the background music:\n\n```cpp\n// Media Foundation is a convenient way to get both file I/O and format decode for \n// audio assets. You can replace the streamer in this sample with your own file I/O \n// and decode routines.\nm_musicStreamer.Initialize(L\"Media\\\\Audio\\\\background.wma\");\n```\n\nThe **MediaStreamer::Initialize** method starts by calling the [**MFStartup**](https://msdn.microsoft.com/library/windows/desktop/ms702238) function to initialize Media Foundation.\n\n```cpp\nDX::ThrowIfFailed(\n    MFStartup(MF_VERSION)\n    );\n```\n\n**MediaStreamer::Initialize** then calls [**MFCreateSourceReaderFromURL**](https://msdn.microsoft.com/library/windows/desktop/dd388110) to create an [**IMFSourceReader**](https://msdn.microsoft.com/library/windows/desktop/dd374655) object. An **IMFSourceReader** object reads media data from the file that is specified by url.\n\n```cpp\nDX::ThrowIfFailed(\n    MFCreateSourceReaderFromURL(url, nullptr, &m_reader)\n    );\n```\n\nThe **MediaStreamer::Initialize** method then creates an [**IMFMediaType**](https://msdn.microsoft.com/library/windows/desktop/ms704850) object to describe the format of the audio stream. An audio format has two types: a major type and a subtype. The major type defines the overall format of the media, such as video, audio, script, and so on. The subtype defines the format, such as PCM, ADPCM, or WMA. The **MediaStreamer::Initialize** method uses the [**IMFMediaType::SetGUID**](https://msdn.microsoft.com/library/windows/desktop/bb970530) method to specify the major type as audio (**MFMediaType\\_Audio**) and the minor type as uncompressed PCM audio (**MFAudioFormat\\_PCM**). The [**IMFSourceReader::SetCurrentMediaType**](https://msdn.microsoft.com/library/windows/desktop/bb970432) method associates the media type with the stream reader.\n\n```cpp\n// Set the decoded output format as PCM. \n// XAudio2 on Windows can process PCM and ADPCM-encoded buffers. \n// When this sample uses Media Foundation, it always decodes into PCM.\n\nDX::ThrowIfFailed(\n    MFCreateMediaType(&mediaType)\n    );\n\nDX::ThrowIfFailed(\n    mediaType->SetGUID(MF_MT_MAJOR_TYPE, MFMediaType_Audio)\n    );\n\nDX::ThrowIfFailed(\n    mediaType->SetGUID(MF_MT_SUBTYPE, MFAudioFormat_PCM)\n    );\n\nDX::ThrowIfFailed(\n    m_reader->SetCurrentMediaType(MF_SOURCE_READER_FIRST_AUDIO_STREAM, 0, mediaType.Get())\n    );\n```\n\nThe **MediaStreamer::Initialize** method then obtains the complete output media format from Media Foundation and calls the [**MFCreateWaveFormatExFromMFMediaType**](https://msdn.microsoft.com/library/windows/desktop/ms702177) function to convert the Media Foundation audio media type to a [**WAVEFORMATEX**](https://msdn.microsoft.com/library/windows/hardware/ff538799) structure. The **WAVEFORMATEX** structure defines the format of waveform-audio data. Marble Maze uses this structure to create the source voices and to apply the low-pass filter to the marble rolling sound.\n\n```cpp\n// Get the complete WAVEFORMAT from the Media Type.\nDX::ThrowIfFailed(\n    m_reader->GetCurrentMediaType(MF_SOURCE_READER_FIRST_AUDIO_STREAM, &outputMediaType)\n    );\n\nuint32 formatSize = 0;\nWAVEFORMATEX* waveFormat;\nDX::ThrowIfFailed(\n    MFCreateWaveFormatExFromMFMediaType(outputMediaType.Get(), &waveFormat, &formatSize)\n    );\nCopyMemory(&m_waveFormat, waveFormat, sizeof(m_waveFormat));\nCoTaskMemFree(waveFormat);\n```\n\n> **Important**   The [**MFCreateWaveFormatExFromMFMediaType**](https://msdn.microsoft.com/library/windows/desktop/ms702177) function uses **CoTaskMemAlloc** to allocate the [**WAVEFORMATEX**](https://msdn.microsoft.com/library/windows/hardware/ff538799) object. Therefore, make sure that you call **CoTaskMemFree** when you are finished using this object.\n\n \n\nThe **MediaStreamer::Initialize** method finishes by computing the length of the stream, m\\_*maxStreamLengthInBytes*, in bytes. To do so, it calls the [**IMFSourceReader::IMFSourceReader::GetPresentationAttribute**](https://msdn.microsoft.com/library/windows/desktop/dd374662) method to get the duration of the audio stream in 100-nanosecond units, converts the duration to sections, and then multiplies by the average data transfer rate in bytes per second. Marble Maze later uses this value to allocate the buffer that holds each game play sound.\n\n```cpp\n// Get the total length of the stream, in bytes.\nPROPVARIANT var;\nDX::ThrowIfFailed(\n    m_reader->GetPresentationAttribute(MF_SOURCE_READER_MEDIASOURCE, MF_PD_DURATION, &var)\n    );\nLONGLONG duration = var.uhVal.QuadPart;\n// The duration is in 100ns units; convert the value to seconds. \ndouble durationInSeconds = (duration / static_cast<double>(10000000)); \nm_maxStreamLengthInBytes = \n    static_cast<unsigned int>(durationInSeconds * m_waveFormat.nAvgBytesPerSec);\n\n// Round up the buffer size to the nearest four bytes.\nm_maxStreamLengthInBytes = (m_maxStreamLengthInBytes + 3) / 4 * 4;\n```\n\n### Creating the source voices\n\nMarble Maze creates XAudio2 source voices to play each of its game sounds and music in source voices. The **Audio** class defines an [**IXAudio2SourceVoice**](https://msdn.microsoft.com/library/windows/desktop/ee415914) object for the background music and an array of **SoundEffectData** objects to hold the game play sounds. The **SoundEffectData** structure holds the **IXAudio2SourceVoice** object for an effect and also defines other effect-related data, such as the audio buffer. Audio.h defines the **SoundEvent** enumeration. Marble Maze uses this enumeration to identify each game play sound. The Audio class also uses this enumeration to index the array of **SoundEffectData** objects.\n\n```cpp\nenum SoundEvent\n{\n    RollingEvent        = 0,\n    FallingEvent        = 1,\n    CollisionEvent      = 2,\n    CheckpointEvent     = 3,\n    MenuChangeEvent     = 4,\n    MenuSelectedEvent   = 5,\n    LastSoundEvent,\n};\n```\n\nThe following table shows the relationship between each of these values, the file that contains the associated sound data, and a brief description of what each sound represents. The audio files are located in the \\\\Media\\\\Audio folder.\n\n| SoundEvent value  | File name      | Description                                              |\n|-------------------|----------------|----------------------------------------------------------|\n| RollingEvent      | MarbleRoll.wav | Played as the marble rolls.                              |\n| FallingEvent      | MarbleFall.wav | Played when the marble falls off the maze.               |\n| CollisionEvent    | MarbleHit.wav  | Played when the marble collides with the maze.           |\n| CheckpointEvent   | Checkpoint.wav | Played when the marble passes over a checkpoint.         |\n| MenuChangeEvent   | MenuChange.wav | Played when the game user changes the current menu item. |\n| MenuSelectedEvent | MenuSelect.wav | Played when the game user selects a menu item.           |\n\n \n\nThe following example shows how the **Audio::CreateResources** method creates the source voice for the background music. The [**IXAudio2::CreateSourceVoice**](https://msdn.microsoft.com/library/windows/desktop/ee418607) method creates and configures a source voice. It takes a [**WAVEFORMATEX**](https://msdn.microsoft.com/library/windows/hardware/ff538799) structure that defines the format of the audio buffers that are sent to the voice. As mentioned previously, Marble Maze uses the PCM format. The [**XAUDIO2\\_SEND\\_DESCRIPTOR**](https://msdn.microsoft.com/library/windows/desktop/ee419244) structure defines the target destination voice from another voice and specifies whether a filter should be used. Marble Maze calls the **Audio::SetSoundEffectFilter** function to use the filters to change the sound of the ball as it rolls. The [**XAUDIO2\\_VOICE\\_SENDS**](https://msdn.microsoft.com/library/windows/desktop/ee419246) structure defines the set of voices to receive data from a single output voice. Marble Maze sends data from the source voice to the mastering voice (for the dry, or unaltered, portion of a playing sound) and to the two submix voices that implement the wet, or reverberant, portion of a playing sound.\n\n```cpp\nXAUDIO2_SEND_DESCRIPTOR descriptors[3];\ndescriptors[0].pOutputVoice = m_soundEffectMasteringVoice;\ndescriptors[0].Flags = 0;\ndescriptors[1].pOutputVoice = m_soundEffectReverbVoiceSmallRoom;\ndescriptors[1].Flags = 0;\ndescriptors[2].pOutputVoice = m_soundEffectReverbVoiceLargeRoom;\ndescriptors[2].Flags = 0;\nXAUDIO2_VOICE_SENDS sends = {0};\nsends.SendCount = 3;\nsends.pSends = descriptors;\n\n// The rolling sound can have pitch shifting and a low-pass filter. \nif (sound == RollingEvent)\n{\n    DX::ThrowIfFailed(\n        m_soundEffectEngine->CreateSourceVoice(\n            &m_soundEffects[sound].m_soundEffectSourceVoice,\n            &(soundEffectStream.GetOutputWaveFormatEx()),\n            XAUDIO2_VOICE_USEFILTER,\n            2.0f,\n            &m_voiceContext,\n            &sends)\n        );\n}\nelse\n{\n    DX::ThrowIfFailed(\n        m_soundEffectEngine->CreateSourceVoice(\n            &m_soundEffects[sound].m_soundEffectSourceVoice,\n            &(soundEffectStream.GetOutputWaveFormatEx()),\n            0,\n            1.0f,\n            &m_voiceContext,\n            &sends)\n        );\n}\n```\n\n## Playing background music\n\n\nA source voice is created in the stopped state. Marble Maze starts the background music in the game loop. The first call to **MarbleMaze::Update** calls **Audio::Start** to start the background music.\n\n```cpp\nif (!m_audio.m_isAudioStarted)\n{\n    m_audio.Start();\n}\n```\n\nThe **Audio::Start** method calls [**IXAudio2SourceVoice::Start**](https://msdn.microsoft.com/library/windows/desktop/ee418471) to start to process the source voice for the background music.\n\n```cpp\nvoid Audio::Start()\n{     \n    if (m_engineExperiencedCriticalError)\n    {\n        return;\n    }\n\n    HRESULT hr = m_musicSourceVoice->Start(0);\n\n    if SUCCEEDED(hr) {\n        m_isAudioStarted = true;\n    }\n    else\n    {\n        m_engineExperiencedCriticalError = true;\n    }\n}\n```\n\nThe source voice passes that audio data to the next stage of the audio graph. In the case of Marble Maze, the next stage contains two submix voices that apply the two reverb effects to the audio. One submix voice applies a close late-field reverb; the second applies a far late-field reverb. The amount that each submix voice contributes to the final mix is determined by the size and shape of the room. The near-field reverb contributes more when the ball is near a wall or in a small room, and the late-field reverb contributes more when the ball is in a large space. This technique produces a more realistic echo effect as the marble moves through the maze. To learn more about how Marble Maze implements this effect, see **Audio::SetRoomSize** and **Physics::CalculateCurrentRoomSize** in the Marble Maze source code.\n\n> **Note**  In a game in which most room sizes are relatively the same, you can use a more basic reverb model. For example, you can use one reverb setting for all rooms or you can create a predefined reverb setting for each room.\n\n \n\nThe **Audio::CreateResources** method uses Media Foundation to load the background music. At this point, however, the source voice does not have audio data to work with. In addition, because the background music loops, the source voice must be regularly updated with data so that the music continues to play. To keep the source voice filled with data, the game loop updates the audio buffers every frame. The **MarbleMaze::Render** method calls **Audio::Render** to process the background music audio buffer. The **Audio::Render** defines an array of three audio buffers, **m\\_audioBuffers**. Each buffer holds 64 KB (65536 bytes) of data. The loop reads data from the Media Foundation object and writes that data to the source voice until the source voice has three queued buffers.\n\n> **Caution**  Although Marble Maze uses a 64 KB buffer to hold music data, you may need to use a larger or smaller buffer. This amount depends on the requirements of your game.\n\n \n\n```cpp\nvoid Audio::Render()\n{\n    if (m_engineExperiencedCriticalError)\n    {\n        m_engineExperiencedCriticalError = false;\n        ReleaseResources();\n        Initialize();\n        CreateResources();\n        Start();\n        if (m_engineExperiencedCriticalError)\n        {\n            return;\n        }\n    }\n\n    try\n    {\n        bool streamComplete;\n        XAUDIO2_VOICE_STATE state;\n        uint32 bufferLength;\n        XAUDIO2_BUFFER buf = {0};\n\n        // Use MediaStreamer to stream the buffers.\n        m_musicSourceVoice->GetState(&state);\n        while (state.BuffersQueued <= MAX_BUFFER_COUNT - 1)\n        {\n            streamComplete = m_musicStreamer.GetNextBuffer(\n                m_audioBuffers[m_currentBuffer], \n                STREAMING_BUFFER_SIZE, \n                &bufferLength\n                );\n\n            if (bufferLength > 0)\n            {\n                buf.AudioBytes = bufferLength;\n                buf.pAudioData = m_audioBuffers[m_currentBuffer];\n                buf.Flags = (streamComplete) ? XAUDIO2_END_OF_STREAM : 0;\n                buf.pContext = 0;\n                DX::ThrowIfFailed(\n                    m_musicSourceVoice->SubmitSourceBuffer(&buf)\n                    );\n\n                m_currentBuffer++;\n                m_currentBuffer %= MAX_BUFFER_COUNT;\n            }\n\n            if (streamComplete)\n            {\n                // Loop the stream.\n                m_musicStreamer.Restart();\n                break;\n            }\n\n            m_musicSourceVoice->GetState(&state);\n        }\n    }\n    catch(...)\n    {\n        m_engineExperiencedCriticalError = true;\n    }\n}\n```\n\nThe loop also handles when the Media Foundation object reaches the end of the stream. In this case, it calls the [**MediaStreamer::OnClockRestart**](https://msdn.microsoft.com/library/windows/desktop/ms697215) method to reset the position of the audio source.\n\n```cpp\nvoid MediaStreamer::Restart()\n{\n    if (m_reader == nullptr)\n    {\n        return;\n    }\n\n    PROPVARIANT var = {0};\n    var.vt = VT_I8;\n\n    DX::ThrowIfFailed(\n        m_reader->SetCurrentPosition(GUID_NULL, var)\n        );\n}\n```\n\nTo implement audio looping for a single buffer (or for an entire sound that is fully loaded into memory), you can set the **LoopCount** field to **XAUDIO2\\_LOOP\\_INFINITE** when you initialize the sound. Marble Maze uses this technique to play the rolling sound for the marble.\n\n```cpp\nif(sound == RollingEvent)\n{\n    m_soundEffects[sound].m_audioBuffer.LoopCount = XAUDIO2_LOOP_INFINITE;\n}\n```\n\nHowever, for the background music, Marble Maze manages the buffers directly so that it can better control the amount of memory that is used. When your music files are large, you can stream the music data into smaller buffers. Doing so can help balance memory size with the frequency of the gameâ€™s ability to process and stream audio data.\n\n> **Tip**  If your game has a low or varying frame rate, processing audio on the main thread can produce unexpected pauses or pops in the audio because the audio engine has insufficient buffered audio data to work with. If your game is sensitive to this issue, consider processing audio on a separate thread that does not perform rendering. This approach is especially useful on computers that have multiple processors because your game can use idle processors.\n\n \n\n##  Reacting to game events\n\n\nThe **MarbleMaze** class provides methods such as **PlaySoundEffect**, **IsSoundEffectStarted**, **StopSoundEffect**, **SetSoundEffectVolume**, **SetSoundEffectPitch**, and **SetSoundEffectFilter** to enable the game to control when sounds play and stop, and to control sound properties such as volume and pitch. For example, if the marble falls off the maze, **MarbleMaze::Update** method calls the **Audio::PlaySoundEffect** method to play the **FallingEvent** sound.\n\n```cpp\nm_audio.PlaySoundEffect(FallingEvent);\n```\n\nThe **Audio::PlaySoundEffect** method calls the [**IXAudio2SourceVoice::Start**](https://msdn.microsoft.com/library/windows/desktop/ee418471) method to begin playback of the sound. If the **IXAudio2SourceVoice::Start** method has already been called, it is not started again. **Audio::PlaySoundEffect** then performs custom logic for certain sounds.\n\n```cpp\nvoid Audio::PlaySoundEffect(SoundEvent sound)\n{\n    XAUDIO2_BUFFER buf = {0};\n    XAUDIO2_VOICE_STATE state = {0};\n\n    if (m_engineExperiencedCriticalError) {\n        // If there's an error, then we'll recreate the engine on the next  \n        // render pass. \n        return;\n    }\n\n    SoundEffectData* soundEffect = &m_soundEffects[sound];\n    HRESULT hr = soundEffect->m_soundEffectSourceVoice->Start();\n    if FAILED(hr)\n    {\n        m_engineExperiencedCriticalError = true;\n        return;\n    }\n\n    // For one-off voices, submit a new buffer if there's none queued up, \n    // and allow up to two collisions to be queued up. \n    if(sound != RollingEvent)\n    {\n        XAUDIO2_VOICE_STATE state = {0};\n        soundEffect->m_soundEffectSourceVoice->GetState(&state, XAUDIO2_VOICE_NOSAMPLESPLAYED);\n        if (state.BuffersQueued == 0)\n        {\n            soundEffect->m_soundEffectSourceVoice->SubmitSourceBuffer(&soundEffect->m_audioBuffer);\n        }\n        else if (state.BuffersQueued < 2 && sound == CollisionEvent)\n        {\n            soundEffect->m_soundEffectSourceVoice->SubmitSourceBuffer(&soundEffect->m_audioBuffer);\n        }\n\n        // For the menu clicks, we want to stop the voice and replay the click right away. \n        // Note that stopping and then flushing could cause a glitch due to the \n        // waveform not being at a zero-crossing, but due to the nature of the sound  \n        // (fast and 'clicky'), we don't mind. \n        if (state.BuffersQueued > 0 && sound == MenuChangeEvent)\n        {\n            soundEffect->m_soundEffectSourceVoice->Stop();\n            soundEffect->m_soundEffectSourceVoice->FlushSourceBuffers();\n            soundEffect->m_soundEffectSourceVoice->SubmitSourceBuffer(&soundEffect->m_audioBuffer);\n            soundEffect->m_soundEffectSourceVoice->Start();\n        }\n    }\n\n    m_soundEffects[sound].m_soundEffectStarted = true;\n}\n```\n\nFor sounds other than rolling, the **Audio::PlaySoundEffect** method calls [**IXAudio2SourceVoice::GetState**](https://msdn.microsoft.com/library/windows/desktop/hh405047) to determine the number of buffers that the source voice is playing. It calls [**IXAudio2SourceVoice::SubmitSourceBuffer**](https://msdn.microsoft.com/library/windows/desktop/ee418473) to add the audio data for the sound to the voiceâ€™s input queue if no buffers are active. The **Audio::PlaySoundEffect** method also enables the collision sound to be played two times in sequence. This occurs, for example, when the marble collides with a corner of the maze.\n\nAs already described, the Audio class uses the **XAUDIO2\\_LOOP\\_INFINITE** flag when it initializes the sound for the rolling event. The sound starts looped playback the first time that **Audio::PlaySoundEffect** is called for this event. To simplify the playback logic for the rolling sound, Marble Maze mutes the sound instead of stopping it. As the marble changes velocity, Marble Maze changes the pitch and volume of the sound to give it a more realistic effect. The following shows how the **MarbleMaze::Update** method updates the pitch and volume of the marble as its velocity changes and how it mutes the sound by setting its volume to zero when the marble stops.\n\n```cpp\n// Play the roll sound only if the marble is actually rolling. \nif (ci.isRollingOnFloor && volume > 0)\n{\n    if (!m_audio.IsSoundEffectStarted(RollingEvent))\n    {\n        m_audio.PlaySoundEffect(RollingEvent);\n    }\n\n    // Update the volume and pitch by the velocity.\n    m_audio.SetSoundEffectVolume(RollingEvent, volume);\n    m_audio.SetSoundEffectPitch(RollingEvent, pitch);\n\n    // The rolling sound has at most 8000Hz sounds, so we linearly  \n    // ramp up the low-pass filter the faster we go. \n    // We also reduce the Q-value of the filter, starting with a  \n    // relatively broad cutoff and get progressively tighter.\n    m_audio.SetSoundEffectFilter(\n        RollingEvent, \n        600.0f + 8000.0f * volume,\n        XAUDIO2_MAX_FILTER_ONEOVERQ - volume*volume\n        );\n}\nelse\n{\n    m_audio.SetSoundEffectVolume(RollingEvent, 0);\n}\n```\n\n## Reacting to suspend and resume events\n\n\nThe document Marble Maze application structure describes how Marble Maze supports suspend and resume. When the game is suspended, the game pauses the audio. When the game resumes, the game resumes the audio where it left off. We do so to follow the best practice of not using resources when you know theyâ€™re not needed.\n\nThe **Audio::SuspendAudio** method is called when the game is suspended. This method calls the [**IXAudio2::StopEngine**](https://msdn.microsoft.com/library/windows/desktop/ee418628) method to stop all audio. Although **IXAudio2::StopEngine** stops all audio output immediately, it preserves the audio graph and its effect parameters (for example, the reverb effect thatâ€™s applied when the marble bounces).\n\n```cpp\n// Uses the IXAudio2::StopEngine method to stop all audio immediately.  \n// It leaves the audio graph untouched, which preserves all effect parameters   \n// and effect histories (like reverb effects) voice states, pending buffers,  \n// cursor positions and so on. \n// When the engines are restarted, the resulting audio will sound as if it had  \n// never been stopped except for the period of silence. \nvoid Audio::SuspendAudio()\n{\n    if (m_engineExperiencedCriticalError)\n    {\n        return;\n    }\n\n    if (m_isAudioStarted)\n    {\n        m_musicEngine->StopEngine();\n        m_soundEffectEngine->StopEngine();\n    }\n    m_isAudioStarted = false;\n}\n```\n\nThe **Audio::ResumeAudio** method is called when the game is resumed. This method uses the [**IXAudio2::StartEngine**](https://msdn.microsoft.com/library/windows/desktop/ee418626) method to restart the audio. Because the call to [**IXAudio2::StopEngine**](https://msdn.microsoft.com/library/windows/desktop/ee418628) preserves the audio graph and its effect parameters, the audio output resumes where it left off.\n\n```cpp\n// Restarts the audio streams. A call to this method must match a previous call  \n// to SuspendAudio. This method causes audio to continue where it left off. \n// If there is a problem with the restart, the m_engineExperiencedCriticalError  \n// flag is set. The next call to Render will recreate all the resources and  \n// reset the audio pipeline. \nvoid Audio::ResumeAudio()\n{\n    if (m_engineExperiencedCriticalError)\n    {\n        return;\n    }\n\n    HRESULT hr = m_musicEngine->StartEngine();\n    HRESULT hr2 = m_soundEffectEngine->StartEngine();\n\n    if (FAILED(hr) || FAILED(hr2))\n    {\n        m_engineExperiencedCriticalError = true;\n    }\n}\n```\n\n## Handling headphones and device changes\n\n\nMarble maze uses engine callbacks to handle XAudio2 engine failures, such as when the audio device changes. A likely cause of a device change is when the game user connects or disconnects the headphones. We recommend that you implement the engine callback that handles device changes. Otherwise, your game will stop playing sound when the user plugs in or removes headphones, until the game is restarted.\n\nAudio.h defines the **AudioEngineCallbacks** class. This class implements the [**IXAudio2EngineCallback**](https://msdn.microsoft.com/library/windows/desktop/ee415910) interface.\n\n```cpp\nclass AudioEngineCallbacks: public IXAudio2EngineCallback\n{\nprivate: \n    Audio* m_audio;\n\npublic :\n    AudioEngineCallbacks(){};\n    void Initialize(Audio* audio);\n\n    // Called by XAudio2 just before an audio processing pass begins.\n    void _stdcall OnProcessingPassStart(){};\n\n    // Called just after an audio processing pass ends.\n    void  _stdcall OnProcessingPassEnd(){};\n\n    // Called when a critical system error causes XAudio2\n    // to be closed and restarted. The error code is given in Error.\n    void  _stdcall OnCriticalError(HRESULT Error);\n};\n```\n\nThe [**IXAudio2EngineCallback**](https://msdn.microsoft.com/library/windows/desktop/ee415910) interface enables your code to be notified when audio processing events occur and when the engine encounters a critical error. To register for callbacks, Marble Maze calls the [**IXAudio2::RegisterForCallbacks**](https://msdn.microsoft.com/library/windows/desktop/ee418620) method after it creates the [**IXAudio2**](https://msdn.microsoft.com/library/windows/desktop/ee415908) object for the music engine.\n\n```cpp\nm_musicEngineCallback.Initialize(this);\nm_musicEngine->RegisterForCallbacks(&m_musicEngineCallback);\n```\n\nMarble Maze does not require notification when audio processing starts or ends. Therefore, it implements the [**IXAudio2EngineCallback::OnProcessingPassStart**](https://msdn.microsoft.com/library/windows/desktop/ee418463) and [**IXAudio2EngineCallback::OnProcessingPassEnd**](https://msdn.microsoft.com/library/windows/desktop/ee418462) methods to do nothing. For the [**IXAudio2EngineCallback::OnCriticalError**](https://msdn.microsoft.com/library/windows/desktop/ee418461) method, Marble Maze calls the **SetEngineExperiencedCriticalError** method, which sets the **m\\_engineExperiencedCriticalError** flag.\n\n```cpp\n// Called when a critical system error causes XAudio2 \n// to be closed and restarted. The error code is given in Error. \nvoid  _stdcall AudioEngineCallbacks::OnCriticalError(HRESULT Error)\n{\n    m_audio->SetEngineExperiencedCriticalError();\n}\n```\n\n```cpp\n// This flag can be used to tell when the audio system \n// is experiencing critial errors.\n// XAudio2 gives a critical error when the user unplugs\n// the headphones and a new speaker configuration is generated.\nvoid SetEngineExperiencedCriticalError()\n{\n    m_engineExperiencedCriticalError = true;\n}\n```\n\nWhen a critical error occurs, audio processing stops and all additional calls to XAudio2 fail. To recover from this situation, you must release the XAudio2 instance and create a new one. The **Audio::Render** method, which is called from the game loop every frame, first checks the **m\\_engineExperiencedCriticalError** flag. If this flag is set, it clears the flag, releases the current XAudio2 instance, initializes resources, and then starts the background music.\n\n```cpp\nif (m_engineExperiencedCriticalError)\n{\n    m_engineExperiencedCriticalError = false;\n    ReleaseResources();\n    Initialize();\n    CreateResources();\n    Start();\n    if (m_engineExperiencedCriticalError)\n    {\n        return;\n    }\n}\n```\n\nMarble Maze also uses the **m\\_engineExperiencedCriticalError** flag to guard against calling into XAudio2 when no audio device is available. For example, the **MarbleMaze::Update** method does not process audio for rolling or collision events when this flag is set. The app attempts to repair the audio engine every frame if it is required; however, the **m\\_engineExperiencedCriticalError** flag might always be set if the computer does not have an audio device or the headphones are unplugged and there is no other available audio device.\n\n> **Caution**   As a rule, do not perform blocking operations in the body of an engine callback. Doing so can cause performance issues. Marble Maze sets a flag in the **OnCriticalError** callback and later handles the error during the regular audio processing phase. For more information about XAudio2 callbacks, see [XAudio2 Callbacks](https://msdn.microsoft.com/library/windows/desktop/ee415745).\n\n \n\n## Related topics\n\n\n* [Adding input and interactivity to the Marble Maze sample](adding-input-and-interactivity-to-the-marble-maze-sample.md)\n* [Developing Marble Maze, a UWP game in C++ and DirectX](developing-marble-maze-a-windows-store-game-in-cpp-and-directx.md)\n\n \n\n \n\n\n\n\n"}
{"nodes":[{"pos":[17,229],"content":"In addition to using voice commands within Cortana to access system features, you can also use voice commands through Cortana to launch a foreground app and specify an action or command to execute within the app.","needQuote":true,"needEscape":true,"nodes":[{"content":"In addition to using voice commands within Cortana to access system features, you can also use voice commands through Cortana to launch a foreground app and specify an action or command to execute within the app.","pos":[0,212]}]},{"pos":[237,291],"content":"Launch a foreground app with voice commands in Cortana","needQuote":true,"needEscape":true,"nodes":[{"content":"Launch a foreground app with voice commands in Cortana","pos":[0,54]}]},{"content":"Launch a foreground app with voice commands in Cortana","pos":[408,462]},{"content":"\\[ Updated for UWP apps on Windows 10.","pos":[465,503]},{"content":"For Windows 8.x articles, see the <bpt id=\"p1\">[</bpt>archive<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept> \\]","pos":[504,599],"source":" For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]"},{"content":"Important APIs","pos":[604,618]},{"content":"Windows.ApplicationModel.VoiceCommands","pos":[629,667]},{"content":"VCD elements and attributes v1.2","pos":[736,768]},{"pos":[831,1051],"content":"In addition to using voice commands within <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> to access system features, you can also use voice commands through <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> to launch a foreground app and specify an action or command to execute within the app.","source":"In addition to using voice commands within **Cortana** to access system features, you can also use voice commands through **Cortana** to launch a foreground app and specify an action or command to execute within the app."},{"content":"Note","pos":[1055,1059]},{"content":"A voice command is a single utterance with a specific intent, defined in a Voice Command Definition (VCD) file, directed at an installed app through <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept>.","pos":[1064,1225],"source":"A voice command is a single utterance with a specific intent, defined in a Voice Command Definition (VCD) file, directed at an installed app through **Cortana**."},{"content":"A voice command definition can vary in complexity.","pos":[1227,1277]},{"content":"It can support anything from a single, constrained utterance to a collection of more flexible, natural language utterances, all denoting the same intent.","pos":[1278,1431]},{"content":"A VCD file defines one or more voice commands, each with a unique intent.","pos":[1433,1506]},{"content":"The target app can be launched in the foreground (the app takes focus) or activated in the background (<bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> retains focus but provides results from the app), depending on the complexity of the interaction.","pos":[1508,1720],"source":"The target app can be launched in the foreground (the app takes focus) or activated in the background (**Cortana** retains focus but provides results from the app), depending on the complexity of the interaction."},{"content":"For example, voice commands that require additional context or user input (such as sending a message to a specific contact) are best handled in a foreground app, while basic commands can be handled in <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> through a background app.","pos":[1721,1959],"source":" For example, voice commands that require additional context or user input (such as sending a message to a specific contact) are best handled in a foreground app, while basic commands can be handled in **Cortana** through a background app."},{"pos":[1964,2065],"content":"We demonstrate these features here with a trip planning and management app named <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept>.","source":"We demonstrate these features here with a trip planning and management app named **Adventure Works**."},{"content":"To create a new <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept> trip without <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept>, a user would launch the app and navigate to the <bpt id=\"p3\">**</bpt>New trip<ept id=\"p3\">**</ept> page.","pos":[2067,2195],"source":"To create a new **Adventure Works** trip without **Cortana**, a user would launch the app and navigate to the **New trip** page."},{"content":"To view an existing trip, a user would launch the app, navigate to the <bpt id=\"p1\">**</bpt>Upcoming trips<ept id=\"p1\">**</ept> page, and select the trip.","pos":[2196,2312],"source":" To view an existing trip, a user would launch the app, navigate to the **Upcoming trips** page, and select the trip."},{"content":"Using voice commands through <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept>, the user can instead just say, \"Adventure Works add a trip\" or \"Add a trip on Adventure Works\" to launch the app and navigate to the <bpt id=\"p2\">**</bpt>New trip<ept id=\"p2\">**</ept> page.","pos":[2314,2507],"source":"Using voice commands through **Cortana**, the user can instead just say, \"Adventure Works add a trip\" or \"Add a trip on Adventure Works\" to launch the app and navigate to the **New trip** page."},{"content":"In turn, saying \"Adventure Works, show my trip to London\" will launch the app and navigate to the <bpt id=\"p1\">**</bpt>Trip<ept id=\"p1\">**</ept> detail page, shown here.","pos":[2508,2639],"source":" In turn, saying \"Adventure Works, show my trip to London\" will launch the app and navigate to the **Trip** detail page, shown here."},{"content":"cortana launching foreground app","pos":[2643,2675]},{"content":"These are the basic steps to add voice-command functionality and integrate Cortana with your app using speech or keyboard input:","pos":[2729,2857]},{"content":"Create a VCD file.","pos":[2863,2881]},{"content":"This is an XML document that defines all the spoken commands that the user can say to initiate actions or invoke commands when activating your app.","pos":[2882,3029]},{"content":"See <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VCD elements and attributes v1.2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept>.","pos":[3030,3131],"source":" See [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593)."},{"content":"Register the command sets in the VCD file when the app is launched.","pos":[3136,3203]},{"content":"Handle the activation-by-voice-command, navigation within the app, and execution of the command.","pos":[3208,3304]},{"content":"**Prerequisites:  **","pos":[3306,3326]},{"content":"If you're new to developing Universal Windows Platform (UWP) apps, have a look through these topics to get familiar with the technologies discussed here.","pos":[3328,3481]},{"content":"Create your first app","pos":[3488,3509]},{"pos":[3573,3690],"content":"Learn about events with <bpt id=\"p1\">[</bpt>Events and routed events overview<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/mt185584)</ept>","source":"Learn about events with [Events and routed events overview](https://msdn.microsoft.com/library/windows/apps/mt185584)"},{"content":"**User experience guidelines:  **","pos":[3692,3725]},{"pos":[3727,4035],"content":"See <bpt id=\"p1\">[</bpt>Cortana design guidelines<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974233)</ept> for info about how to integrate your app with <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> and <bpt id=\"p3\">[</bpt>Speech design guidelines<ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn596121)</ept> for helpful tips on designing a useful and engaging speech-enabled app.","source":"See [Cortana design guidelines](https://msdn.microsoft.com/library/windows/apps/dn974233) for info about how to integrate your app with **Cortana** and [Speech design guidelines](https://msdn.microsoft.com/library/windows/apps/dn596121) for helpful tips on designing a useful and engaging speech-enabled app."},{"pos":[4148,4165],"content":"Create a VCD file"},{"pos":[4172,4284],"content":"In Microsoft Visual Studio, right-click the project name, select Add-<ph id=\"ph1\">&amp;gt;</ph>New Item, and then select <bpt id=\"p1\">**</bpt>XML File<ept id=\"p1\">**</ept>.","source":"In Microsoft Visual Studio, right-click the project name, select Add-&gt;New Item, and then select **XML File**."},{"content":"Type a name for the VCD file.","pos":[4289,4318]},{"content":"For example, \"AdventureWorksCommands.xml\".","pos":[4319,4361]},{"content":"Select <bpt id=\"p1\">**</bpt>Add<ept id=\"p1\">**</ept>.","pos":[4362,4377],"source":" Select **Add**."},{"pos":[4382,4428],"content":"In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, select the VCD file.","source":"In **Solution Explorer**, select the VCD file."},{"pos":[4433,4563],"content":"In the <bpt id=\"p1\">**</bpt>Properties<ept id=\"p1\">**</ept> window, set <bpt id=\"p2\">**</bpt>Build action<ept id=\"p2\">**</ept> to <bpt id=\"p3\">**</bpt>Content<ept id=\"p3\">**</ept>, and then set <bpt id=\"p4\">**</bpt>Copy to output directory<ept id=\"p4\">**</ept> to <bpt id=\"p5\">**</bpt>Copy if newer<ept id=\"p5\">**</ept>.","source":"In the **Properties** window, set **Build action** to **Content**, and then set **Copy to output directory** to **Copy if newer**."},{"pos":[4676,4693],"content":"Edit the VCD file"},{"pos":[4696,4804],"content":"For each language supported by your app, create a <bpt id=\"p1\">**</bpt>CommandSet<ept id=\"p1\">**</ept> of voice commands that your app can handle.","source":"For each language supported by your app, create a **CommandSet** of voice commands that your app can handle."},{"pos":[4806,4876],"content":"Each <bpt id=\"p1\">**</bpt>Command<ept id=\"p1\">**</ept> declared in a VCD file must include this information:","source":"Each **Command** declared in a VCD file must include this information:"},{"content":"A command Name used by the application to identify the voice command at runtime.","pos":[4882,4962]},{"content":"An <bpt id=\"p1\">**</bpt>Example<ept id=\"p1\">**</ept> element that contains a phrase describing how a user can invoke the command.","pos":[4967,5058],"source":"An **Example** element that contains a phrase describing how a user can invoke the command."},{"content":"<bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> shows this example when the user says \"What can I say?\", \"Help\", or they tap <bpt id=\"p2\">**</bpt>See more<ept id=\"p2\">**</ept>.","pos":[5059,5161],"source":"**Cortana** shows this example when the user says \"What can I say?\", \"Help\", or they tap **See more**."},{"content":"A <bpt id=\"p1\">**</bpt>ListenFor<ept id=\"p1\">**</ept> element that contains the words or phrases that your app recognizes to initiate a command.","pos":[5167,5273],"source":"A **ListenFor** element that contains the words or phrases that your app recognizes to initiate a command."},{"content":"Each command needs to have at least one <bpt id=\"p1\">**</bpt>ListenFor<ept id=\"p1\">**</ept> element.","pos":[5274,5336],"source":" Each command needs to have at least one **ListenFor** element."},{"pos":[5341,5455],"content":"A <bpt id=\"p1\">**</bpt>Feedback<ept id=\"p1\">**</ept> element that contains the text for <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> to display and speak as the application is launched.","source":"A **Feedback** element that contains the text for **Cortana** to display and speak as the application is launched."},{"content":"A <bpt id=\"p1\">**</bpt>Navigate<ept id=\"p1\">**</ept> element to indicate that the voice command is to launch the app in the foreground.","pos":[5460,5557],"source":"A **Navigate** element to indicate that the voice command is to launch the app in the foreground."},{"content":"Specify a <bpt id=\"p1\">**</bpt>VoiceCommandService<ept id=\"p1\">**</ept> element if the voice command launches the app in the background instead.","pos":[5558,5664],"source":" Specify a **VoiceCommandService** element if the voice command launches the app in the background instead."},{"content":"For more details, see <bpt id=\"p1\">[</bpt>Launch a background app with voice commands in Cortana<ept id=\"p1\">](launch-a-background-app-with-voice-commands-in-cortana.md)</ept>.","pos":[5665,5803],"source":" For more details, see [Launch a background app with voice commands in Cortana](launch-a-background-app-with-voice-commands-in-cortana.md)."},{"pos":[5805,5937],"content":"For more detail, see the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VCD elements and attributes v1.2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept> reference.","source":"For more detail, see the [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593) reference."},{"content":"You can specify multiple language versions for the commands used to activate your app and execute a command.","pos":[5939,6047]},{"content":"You can create multiple <bpt id=\"p1\">**</bpt>CommandSet<ept id=\"p1\">**</ept> elements, each with a different <bpt id=\"p2\">**</bpt>xml:lang<ept id=\"p2\">**</ept> attribute to allow your app to be used in different markets.","pos":[6048,6192],"source":" You can create multiple **CommandSet** elements, each with a different **xml:lang** attribute to allow your app to be used in different markets."},{"content":"For example, an app for the United States might have a <bpt id=\"p1\">**</bpt>CommandSet<ept id=\"p1\">**</ept> for English and a <bpt id=\"p2\">**</bpt>CommandSet<ept id=\"p2\">**</ept> for Spanish.","pos":[6193,6308],"source":" For example, an app for the United States might have a **CommandSet** for English and a **CommandSet** for Spanish."},{"content":"Caution","pos":[6312,6319]},{"content":"To activate an app and initiate an action using a voice command, the app must register a VCD file that contains a <bpt id=\"p1\">**</bpt>CommandSet<ept id=\"p1\">**</ept> with a language that matches the speech language that the user selected on their device.","pos":[6324,6541],"source":"To activate an app and initiate an action using a voice command, the app must register a VCD file that contains a **CommandSet** with a language that matches the speech language that the user selected on their device."},{"content":"This language is set by the user on the device Settings <ph id=\"ph1\">&amp;gt;</ph> System <ph id=\"ph2\">&amp;gt;</ph> Speech <ph id=\"ph3\">&amp;gt;</ph> Speech Language screen.","pos":[6542,6650],"source":" This language is set by the user on the device Settings &gt; System &gt; Speech &gt; Speech Language screen."},{"pos":[6655,6734],"content":"Here's a VCD file that defines a voice command for the <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept> app.","source":"Here's a VCD file that defines a voice command for the **Adventure Works** app."},{"pos":[6736,7270],"content":"For this example, <bpt id=\"p1\">**</bpt>CommandPrefix<ept id=\"p1\">**</ept> is set to \"Adventure Works\", <bpt id=\"p2\">**</bpt>Command<ept id=\"p2\">**</ept>, identified by Name (\" showTripToDestination\"), specifies both what the user can say and what feedback is provided by Cortana, <bpt id=\"p3\">**</bpt>ListenFor<ept id=\"p3\">**</ept> specifies the text that can be recognized (with a reference to a <bpt id=\"p4\">**</bpt>PhraseList<ept id=\"p4\">**</ept> element that constrains the recognized destinations), <bpt id=\"p5\">**</bpt>Navigate<ept id=\"p5\">**</ept> indicates that the voice command is handled by launching the app in the foreground, and <bpt id=\"p6\">**</bpt>Feedback<ept id=\"p6\">**</ept> specifies what the user will hear when <bpt id=\"p7\">**</bpt>Cortana<ept id=\"p7\">**</ept> launches the app.","source":"For this example, **CommandPrefix** is set to \"Adventure Works\", **Command**, identified by Name (\" showTripToDestination\"), specifies both what the user can say and what feedback is provided by Cortana, **ListenFor** specifies the text that can be recognized (with a reference to a **PhraseList** element that constrains the recognized destinations), **Navigate** indicates that the voice command is handled by launching the app in the foreground, and **Feedback** specifies what the user will hear when **Cortana** launches the app."},{"content":"<bpt id=\"p1\">**</bpt>ListenFor<ept id=\"p1\">**</ept> elements cannot be programmatically modified.","pos":[7272,7331],"source":"**ListenFor** elements cannot be programmatically modified."},{"content":"However, <bpt id=\"p1\">**</bpt>PhraseList<ept id=\"p1\">**</ept> elements associated with <bpt id=\"p2\">**</bpt>ListenFor<ept id=\"p2\">**</ept> elements can be programmatically modified.","pos":[7332,7437],"source":" However, **PhraseList** elements associated with **ListenFor** elements can be programmatically modified."},{"content":"Applications should modify the content of the <bpt id=\"p1\">**</bpt>PhraseList<ept id=\"p1\">**</ept> at runtime based on the data set generated as the user uses the app.","pos":[7438,7567],"source":" Applications should modify the content of the **PhraseList** at runtime based on the data set generated as the user uses the app."},{"content":"See <bpt id=\"p1\">[</bpt>How to dynamically modify VCD phrase lists<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn747872)</ept>.","pos":[7568,7675],"source":" See [How to dynamically modify VCD phrase lists](https://msdn.microsoft.com/library/windows/apps/dn747872)."},{"pos":[8828,8852],"content":"Install the VCD commands"},{"content":"Your app must run once to install the command sets in the VCD.","pos":[8855,8917]},{"pos":[8919,9211],"content":"When your app is activated, call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>InstallCommandDefinitionsFromStorageFileAsync<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn708205)</ept> in the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>OnLaunched<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br242335)</ept> handler to register the commands that the system should listen for.","source":"When your app is activated, call [**InstallCommandDefinitionsFromStorageFileAsync**](https://msdn.microsoft.com/library/windows/apps/dn708205) in the [**OnLaunched**](https://msdn.microsoft.com/library/windows/apps/br242335) handler to register the commands that the system should listen for."},{"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>  If a device backup occurs and your app reinstalls automatically, voice command data is not preserved.","pos":[9213,9324],"source":"**Note**  If a device backup occurs and your app reinstalls automatically, voice command data is not preserved."},{"content":"To ensure the voice command data for your app stays intact, consider initializing your VCD file each time your app launches or activates, or store a setting that indicates if the VCD is currently installed and check the setting each time your app launches or activates.","pos":[9325,9594]},{"content":"Here's an example that shows how to install the commands specified by a VCD file (vcd.xml).","pos":[9599,9690]},{"pos":[10184,10228],"content":"Handle activation and execute voice commands"},{"content":"Once your app has been launched and the voice command sets installed, specify how your app responds to subsequent voice command activations.","pos":[10231,10371]},{"content":"For example, your app might navigate to a specific page of content, display a map or other navigation utility, or speak a confirmation or status.","pos":[10372,10517]},{"content":"You need to:","pos":[10519,10531]},{"content":"Confirm that your app was activated by a voice command.","pos":[10537,10592]},{"pos":[10598,10956],"content":"Override the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Application.OnActivated<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br242330)</ept> event and check whether <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IActivatedEventArgs<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br224727)</ept>.<bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>Kind<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br224728)</ept> is <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>VoiceCommand<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/br224693)</ept>.","source":"Override the [**Application.OnActivated**](https://msdn.microsoft.com/library/windows/apps/br242330) event and check whether [**IActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/br224727).[**Kind**](https://msdn.microsoft.com/library/windows/apps/br224728) is [**VoiceCommand**](https://msdn.microsoft.com/library/windows/apps/br224693)."},{"content":"Determine the name of the command and what was spoken.","pos":[10962,11016]},{"pos":[11022,11433],"content":"Get a reference to a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VoiceCommandActivatedEventArgs<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn609755)</ept> object from the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IActivatedEventArgs<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br224727)</ept> and query the <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>Result<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/dn609758)</ept> property for a <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>SpeechRecognitionResult<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/dn631432)</ept> object.","source":"Get a reference to a [**VoiceCommandActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/dn609755) object from the [**IActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/br224727) and query the [**Result**](https://msdn.microsoft.com/library/windows/apps/dn609758) property for a [**SpeechRecognitionResult**](https://msdn.microsoft.com/library/windows/apps/dn631432) object."},{"pos":[11439,11734],"content":"To determine what the user said, check the value of <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Text<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631441)</ept> or the semantic properties of the recognized phrase in the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>SpeechRecognitionSemanticInterpretation<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn631443)</ept> dictionary.","source":"To determine what the user said, check the value of [**Text**](https://msdn.microsoft.com/library/windows/apps/dn631441) or the semantic properties of the recognized phrase in the [**SpeechRecognitionSemanticInterpretation**](https://msdn.microsoft.com/library/windows/apps/dn631443) dictionary."},{"content":"Take the appropriate action in your app, typically navigating to the relevant page.","pos":[11740,11823]},{"content":"For this example, we refer back to the VCD in Step 3: Edit the VCD file.","pos":[11825,11897]},{"content":"Once we get the speech-recognition result for the voice command, we get the command name from the first value in the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>RulePath<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631438)</ept> array.","pos":[11899,12095],"source":"Once we get the speech-recognition result for the voice command, we get the command name from the first value in the [**RulePath**](https://msdn.microsoft.com/library/windows/apps/dn631438) array."},{"content":"As the VCD file defined more than one possible voice command, we need to compare the value against the command names in the VCD and take the appropriate action.","pos":[12096,12256]},{"content":"The most common action an application can take is to navigate to a page with content relevant to the context of the voice command.","pos":[12258,12388]},{"content":"For this example, we navigate to a <bpt id=\"p1\">**</bpt>TripPage<ept id=\"p1\">**</ept> page and pass in the value of the voice command, how the command was input, and the recognized \"destination\" phrase (if applicable).","pos":[12389,12569],"source":" For this example, we navigate to a **TripPage** page and pass in the value of the voice command, how the command was input, and the recognized \"destination\" phrase (if applicable)."},{"content":"Alternatively, the app could send a navigation parameter to the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SpeechRecognitionResult<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631432)</ept> when navigating to the page.","pos":[12570,12750],"source":" Alternatively, the app could send a navigation parameter to the [**SpeechRecognitionResult**](https://msdn.microsoft.com/library/windows/apps/dn631432) when navigating to the page."},{"content":"You can find out whether the voice command that launched your app was actually spoken, or whether it was typed in as text, from the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SpeechRecognitionSemanticInterpretation.Properties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631445)</ept> dictionary using the <bpt id=\"p3\">**</bpt>commandMode<ept id=\"p3\">**</ept> key.","pos":[12752,13040],"source":"You can find out whether the voice command that launched your app was actually spoken, or whether it was typed in as text, from the [**SpeechRecognitionSemanticInterpretation.Properties**](https://msdn.microsoft.com/library/windows/apps/dn631445) dictionary using the **commandMode** key."},{"content":"The value of that key will be either \"voice\" or \"text\".","pos":[13041,13096]},{"content":"If the value of the key is \"voice\", consider using speech synthesis (<bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Windows.Media.SpeechSynthesis<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn278951)</ept>) to provide the user with spoken feedback.","pos":[13097,13302],"source":" If the value of the key is \"voice\", consider using speech synthesis ([**Windows.Media.SpeechSynthesis**](https://msdn.microsoft.com/library/windows/apps/dn278951)) to provide the user with spoken feedback."},{"content":"Use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SpeechRecognitionSemanticInterpretation.Properties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631445)</ept> to find out the content spoken in the <bpt id=\"p3\">**</bpt>PhraseList<ept id=\"p3\">**</ept> or <bpt id=\"p4\">**</bpt>PhraseTopic<ept id=\"p4\">**</ept> constraints of a <bpt id=\"p5\">**</bpt>ListenFor<ept id=\"p5\">**</ept> element.","pos":[13304,13538],"source":"Use the [**SpeechRecognitionSemanticInterpretation.Properties**](https://msdn.microsoft.com/library/windows/apps/dn631445) to find out the content spoken in the **PhraseList** or **PhraseTopic** constraints of a **ListenFor** element."},{"content":"The dictionary key is the value of the <bpt id=\"p1\">**</bpt>Label<ept id=\"p1\">**</ept> attribute of the <bpt id=\"p2\">**</bpt>PhraseList<ept id=\"p2\">**</ept> or <bpt id=\"p3\">**</bpt>PhraseTopic<ept id=\"p3\">**</ept> element.","pos":[13539,13647],"source":" The dictionary key is the value of the **Label** attribute of the **PhraseList** or **PhraseTopic** element."},{"content":"Here, we show how to access the value of <bpt id=\"p1\">**</bpt>{destination}<ept id=\"p1\">**</ept> phrase.","pos":[13648,13714],"source":" Here, we show how to access the value of **{destination}** phrase."},{"pos":[15624,15640],"content":"Related articles"},{"content":"Developers","pos":[15645,15655]},{"content":"Cortana interactions","pos":[15661,15681]},{"content":"Define custom recognition constraints","pos":[15711,15748]},{"pos":[15794,15904],"content":"<bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VCD elements and attributes v1.2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept><ph id=\"ph1\">\n</ph><bpt id=\"p3\">**</bpt>Designers<ept id=\"p3\">**</ept>","source":"[**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593)\n**Designers**"},{"content":"Cortana design guidelines","pos":[15908,15933]},{"pos":[15995,16091],"content":"<bpt id=\"p1\">[</bpt>Speech design guidelines<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn596121)</ept><ph id=\"ph1\">\n</ph><bpt id=\"p2\">**</bpt>Samples<ept id=\"p2\">**</ept>","source":"[Speech design guidelines](https://msdn.microsoft.com/library/windows/apps/dn596121)\n**Samples**"},{"content":"Cortana voice command sample","pos":[16095,16123]}],"content":"---\nDescription: In addition to using voice commands within Cortana to access system features, you can also use voice commands through Cortana to launch a foreground app and specify an action or command to execute within the app.\ntitle: Launch a foreground app with voice commands in Cortana\nms.assetid: 8D3D1F66-7D17-4DD1-B426-DCCBD534EF00\nlabel: Cortana-Launch a foreground app\ntemplate: detail.hbs\n---\n\n# Launch a foreground app with voice commands in Cortana\n\n\n\\[ Updated for UWP apps on Windows 10. For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]\n\n\n**Important APIs**\n\n-   [**Windows.ApplicationModel.VoiceCommands**](https://msdn.microsoft.com/library/windows/apps/dn706594)\n-   [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593)\n\nIn addition to using voice commands within **Cortana** to access system features, you can also use voice commands through **Cortana** to launch a foreground app and specify an action or command to execute within the app.\n\n**Note**  \nA voice command is a single utterance with a specific intent, defined in a Voice Command Definition (VCD) file, directed at an installed app through **Cortana**.\n\nA voice command definition can vary in complexity. It can support anything from a single, constrained utterance to a collection of more flexible, natural language utterances, all denoting the same intent.\n\nA VCD file defines one or more voice commands, each with a unique intent.\n\nThe target app can be launched in the foreground (the app takes focus) or activated in the background (**Cortana** retains focus but provides results from the app), depending on the complexity of the interaction. For example, voice commands that require additional context or user input (such as sending a message to a specific contact) are best handled in a foreground app, while basic commands can be handled in **Cortana** through a background app.\n\n \n\nWe demonstrate these features here with a trip planning and management app named **Adventure Works**.\n\nTo create a new **Adventure Works** trip without **Cortana**, a user would launch the app and navigate to the **New trip** page. To view an existing trip, a user would launch the app, navigate to the **Upcoming trips** page, and select the trip.\n\nUsing voice commands through **Cortana**, the user can instead just say, \"Adventure Works add a trip\" or \"Add a trip on Adventure Works\" to launch the app and navigate to the **New trip** page. In turn, saying \"Adventure Works, show my trip to London\" will launch the app and navigate to the **Trip** detail page, shown here.\n\n![cortana launching foreground app](images/cortana-foreground-with-adventureworks.png)\n\nThese are the basic steps to add voice-command functionality and integrate Cortana with your app using speech or keyboard input:\n\n1.  Create a VCD file. This is an XML document that defines all the spoken commands that the user can say to initiate actions or invoke commands when activating your app. See [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593).\n2.  Register the command sets in the VCD file when the app is launched.\n3.  Handle the activation-by-voice-command, navigation within the app, and execution of the command.\n\n**Prerequisites:  **\n\nIf you're new to developing Universal Windows Platform (UWP) apps, have a look through these topics to get familiar with the technologies discussed here.\n\n-   [Create your first app](https://msdn.microsoft.com/library/windows/apps/bg124288)\n-   Learn about events with [Events and routed events overview](https://msdn.microsoft.com/library/windows/apps/mt185584)\n\n**User experience guidelines:  **\n\nSee [Cortana design guidelines](https://msdn.microsoft.com/library/windows/apps/dn974233) for info about how to integrate your app with **Cortana** and [Speech design guidelines](https://msdn.microsoft.com/library/windows/apps/dn596121) for helpful tips on designing a useful and engaging speech-enabled app.\n\n## <span id=\"Create_a_VCD_file\"></span><span id=\"create_a_vcd_file\"></span><span id=\"CREATE_A_VCD_FILE\"></span>Create a VCD file\n\n\n1.  In Microsoft Visual Studio, right-click the project name, select Add-&gt;New Item, and then select **XML File**.\n2.  Type a name for the VCD file. For example, \"AdventureWorksCommands.xml\". Select **Add**.\n3.  In **Solution Explorer**, select the VCD file.\n4.  In the **Properties** window, set **Build action** to **Content**, and then set **Copy to output directory** to **Copy if newer**.\n\n## <span id=\"Edit_the_VCD_file\"></span><span id=\"edit_the_vcd_file\"></span><span id=\"EDIT_THE_VCD_FILE\"></span>Edit the VCD file\n\n\nFor each language supported by your app, create a **CommandSet** of voice commands that your app can handle.\n\nEach **Command** declared in a VCD file must include this information:\n\n-   A command Name used by the application to identify the voice command at runtime.\n-   An **Example** element that contains a phrase describing how a user can invoke the command. **Cortana** shows this example when the user says \"What can I say?\", \"Help\", or they tap **See more**.\n\n-   A **ListenFor** element that contains the words or phrases that your app recognizes to initiate a command. Each command needs to have at least one **ListenFor** element.\n-   A **Feedback** element that contains the text for **Cortana** to display and speak as the application is launched.\n-   A **Navigate** element to indicate that the voice command is to launch the app in the foreground. Specify a **VoiceCommandService** element if the voice command launches the app in the background instead. For more details, see [Launch a background app with voice commands in Cortana](launch-a-background-app-with-voice-commands-in-cortana.md).\n\nFor more detail, see the [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593) reference.\n\nYou can specify multiple language versions for the commands used to activate your app and execute a command. You can create multiple **CommandSet** elements, each with a different **xml:lang** attribute to allow your app to be used in different markets. For example, an app for the United States might have a **CommandSet** for English and a **CommandSet** for Spanish.\n\n**Caution**  \nTo activate an app and initiate an action using a voice command, the app must register a VCD file that contains a **CommandSet** with a language that matches the speech language that the user selected on their device. This language is set by the user on the device Settings &gt; System &gt; Speech &gt; Speech Language screen.\n\n \n\nHere's a VCD file that defines a voice command for the **Adventure Works** app.\n\nFor this example, **CommandPrefix** is set to \"Adventure Works\", **Command**, identified by Name (\" showTripToDestination\"), specifies both what the user can say and what feedback is provided by Cortana, **ListenFor** specifies the text that can be recognized (with a reference to a **PhraseList** element that constrains the recognized destinations), **Navigate** indicates that the voice command is handled by launching the app in the foreground, and **Feedback** specifies what the user will hear when **Cortana** launches the app.\n\n**ListenFor** elements cannot be programmatically modified. However, **PhraseList** elements associated with **ListenFor** elements can be programmatically modified. Applications should modify the content of the **PhraseList** at runtime based on the data set generated as the user uses the app. See [How to dynamically modify VCD phrase lists](https://msdn.microsoft.com/library/windows/apps/dn747872).\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<VoiceCommands xmlns=\"http://schemas.microsoft.com/voicecommands/1.1\">\n  <CommandSet xml:lang=\"en-us\" Name=\"AdventureWorksCommandSet_en-us\">\n    <AppName> Adventure Works </AppName>\n    <Example> Show trip to London </Example>\n\n    <Command Name=\"showTripToDestination\">\n      <Example> Show trip to London </Example>\n      <ListenFor RequireAppName=\"BeforeOrAfterPhrase\"> show [my] trip to {destination} </ListenFor>\n      <ListenFor RequireAppName=\"ExplicitlySpecified\"> show [my] {builtin:AppName} trip to {destination} </ListenFor>\n      <Feedback> Showing trip to {destination} </Feedback>\n      <Navigate />\n    </Command>\n\n    <PhraseList Label=\"destination\">\n      <Item> London </Item>\n      <Item> Dallas </Item>\n      <Item> New York </Item>\n    </PhraseList>\n\n    <PhraseTopic Label=\"newDestination\" Scenario=\"Search\">\n      <Subject>City/State</Subject>\n    </PhraseTopic>\n  </CommandSet>\n\n<!-- Other CommandSets for other languages -->\n\n</VoiceCommands>\n```\n\n## <span id=\"Install_the_VCD_commands\"></span><span id=\"install_the_vcd_commands\"></span><span id=\"INSTALL_THE_VCD_COMMANDS\"></span>Install the VCD commands\n\n\nYour app must run once to install the command sets in the VCD.\n\nWhen your app is activated, call [**InstallCommandDefinitionsFromStorageFileAsync**](https://msdn.microsoft.com/library/windows/apps/dn708205) in the [**OnLaunched**](https://msdn.microsoft.com/library/windows/apps/br242335) handler to register the commands that the system should listen for.\n\n**Note**  If a device backup occurs and your app reinstalls automatically, voice command data is not preserved. To ensure the voice command data for your app stays intact, consider initializing your VCD file each time your app launches or activates, or store a setting that indicates if the VCD is currently installed and check the setting each time your app launches or activates.\n\n \n\nHere's an example that shows how to install the commands specified by a VCD file (vcd.xml).\n\n```CSharp\nvar storageFile = \n  await Windows.Storage.StorageFile.GetFileFromApplicationUriAsync(\n    new Uri(\"ms-appx:///AdventureWorksCommands.xml\"));\nawait \n  Windows.ApplicationModel.VoiceCommands.VoiceCommandDefinitionManager.\n    InstallCommandDefinitionsFromStorageFileAsync(storageFile);\n```\n\n## <span id=\"Handle_activation_and_execute_voice_commands\"></span><span id=\"handle_activation_and_execute_voice_commands\"></span><span id=\"HANDLE_ACTIVATION_AND_EXECUTE_VOICE_COMMANDS\"></span>Handle activation and execute voice commands\n\n\nOnce your app has been launched and the voice command sets installed, specify how your app responds to subsequent voice command activations. For example, your app might navigate to a specific page of content, display a map or other navigation utility, or speak a confirmation or status.\n\nYou need to:\n\n1.  Confirm that your app was activated by a voice command.\n\n    Override the [**Application.OnActivated**](https://msdn.microsoft.com/library/windows/apps/br242330) event and check whether [**IActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/br224727).[**Kind**](https://msdn.microsoft.com/library/windows/apps/br224728) is [**VoiceCommand**](https://msdn.microsoft.com/library/windows/apps/br224693).\n\n2.  Determine the name of the command and what was spoken.\n\n    Get a reference to a [**VoiceCommandActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/dn609755) object from the [**IActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/br224727) and query the [**Result**](https://msdn.microsoft.com/library/windows/apps/dn609758) property for a [**SpeechRecognitionResult**](https://msdn.microsoft.com/library/windows/apps/dn631432) object.\n\n    To determine what the user said, check the value of [**Text**](https://msdn.microsoft.com/library/windows/apps/dn631441) or the semantic properties of the recognized phrase in the [**SpeechRecognitionSemanticInterpretation**](https://msdn.microsoft.com/library/windows/apps/dn631443) dictionary.\n\n3.  Take the appropriate action in your app, typically navigating to the relevant page.\n\nFor this example, we refer back to the VCD in Step 3: Edit the VCD file.\n\nOnce we get the speech-recognition result for the voice command, we get the command name from the first value in the [**RulePath**](https://msdn.microsoft.com/library/windows/apps/dn631438) array. As the VCD file defined more than one possible voice command, we need to compare the value against the command names in the VCD and take the appropriate action.\n\nThe most common action an application can take is to navigate to a page with content relevant to the context of the voice command. For this example, we navigate to a **TripPage** page and pass in the value of the voice command, how the command was input, and the recognized \"destination\" phrase (if applicable). Alternatively, the app could send a navigation parameter to the [**SpeechRecognitionResult**](https://msdn.microsoft.com/library/windows/apps/dn631432) when navigating to the page.\n\nYou can find out whether the voice command that launched your app was actually spoken, or whether it was typed in as text, from the [**SpeechRecognitionSemanticInterpretation.Properties**](https://msdn.microsoft.com/library/windows/apps/dn631445) dictionary using the **commandMode** key. The value of that key will be either \"voice\" or \"text\". If the value of the key is \"voice\", consider using speech synthesis ([**Windows.Media.SpeechSynthesis**](https://msdn.microsoft.com/library/windows/apps/dn278951)) to provide the user with spoken feedback.\n\nUse the [**SpeechRecognitionSemanticInterpretation.Properties**](https://msdn.microsoft.com/library/windows/apps/dn631445) to find out the content spoken in the **PhraseList** or **PhraseTopic** constraints of a **ListenFor** element. The dictionary key is the value of the **Label** attribute of the **PhraseList** or **PhraseTopic** element. Here, we show how to access the value of **{destination}** phrase.\n\n```CSS\nprotected override void OnActivated(IActivatedEventArgs e)\n{\n  // Was the app activated by a voice command?\n  if (e.Kind != Windows.ApplicationModel.Activation.ActivationKind.VoiceCommand)\n  {\n    return;\n  }\n\n  var commandArgs = e as Windows.ApplicationModel.Activation.VoiceCommandActivatedEventArgs;\n\n  Windows.ApplicationModel.VoiceCommands.VoiceCommand.SpeechRecognitionResult speechRecognitionResult = \n    commandArgs.Result;\n\n  // Get the name of the voice command and the text spoken.\n  string voiceCommandName = speechRecognitionResult.RulePath[0];\n  string textSpoken = speechRecognitionResult.Text;\n  // The commandMode is either \"voice\" or \"text\", and it indicates how the voice command was entered by the user.\n  // Apps should respect \"text\" mode by providing feedback in a silent form.\n  string commandMode = this.SemanticInterpretation(\"commandMode\", speechRecognitionResult);\n\n  switch (voiceCommandName)\n  {\n    case \"showTripToDestination\":\n    // Access the value of the {destination} phrase in the voice command.\n    string destination = speechRecognitionResult.SemanticInterpretation.Properties[\"destination\"][0];\n    // Create a navigation parameter string to pass to the page.\n    navigationParameterString = string.Format(\"{0}|{1}|{2}|{3}\", \n                    voiceCommandName, commandMode, textSpoken, destination);\n    // Set the page where to navigate for this voice command.\n    navigateToPageType = typeof(TripPage);\n    break;\n\n    default:\n      // There is no match for the voice command name. Navigate to MainPage.\n      navigateToPageType = typeof(MainPage);\n      break;\n  }\n  if (this.rootFrame == null)\n  {\n    // App needs to create a new Frame, not shown\n  }\n\n  if (!this.rootFrame.Navigate(navigateToPageType, navigationParameterString))\n    {\n    throw new Exception(\"Failed to create voice command page\");\n    }\n}\n```\n\n## <span id=\"related_topics\"></span>Related articles\n\n\n**Developers**\n* [Cortana interactions](cortana-interactions.md)\n* [Define custom recognition constraints](define-custom-recognition-constraints.md)\n* [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593)\n**Designers**\n* [Cortana design guidelines](https://msdn.microsoft.com/library/windows/apps/dn974233)\n* [Speech design guidelines](https://msdn.microsoft.com/library/windows/apps/dn596121)\n**Samples**\n* [Cortana voice command sample](http://go.microsoft.com/fwlink/p/?LinkID=619899)\n \n\n \n\n\n\n\n"}
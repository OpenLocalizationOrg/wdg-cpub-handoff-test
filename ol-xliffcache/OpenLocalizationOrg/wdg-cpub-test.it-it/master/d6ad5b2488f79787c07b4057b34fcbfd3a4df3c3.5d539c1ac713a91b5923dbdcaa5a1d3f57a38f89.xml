{"nodes":[{"content":"This article describes how to create a Windows Runtime Compontent that implements the IBasicVideoEffect interface to allows you to create custom effects for video streams.","pos":[37,208]},{"pos":[358,378],"content":"Custom video effects","needQuote":true,"needEscape":true,"nodes":[{"content":"Custom video effects","pos":[0,20]}]},{"content":"Custom video effects","pos":[386,406]},{"content":"\\[ Updated for UWP apps on Windows 10.","pos":[409,447]},{"content":"For Windows 8.x articles, see the <bpt id=\"p1\">[</bpt>archive<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept> \\]","pos":[448,543],"source":" For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]"},{"content":"\\[Some information relates to pre-released product which may be substantially modified before it's commercially released.","pos":[546,667]},{"content":"Microsoft makes no warranties, express or implied, with respect to the information provided here.\\]","pos":[668,767]},{"content":"This article describes how to create a Windows Runtime Compontent that implements the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBasicVideoEffect<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764788)</ept> interface to allows you to create custom effects for video streams.","pos":[769,1004],"source":"This article describes how to create a Windows Runtime Compontent that implements the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788) interface to allows you to create custom effects for video streams."},{"content":"Custom effects can be used with several different Windows Runtime APIs including <bpt id=\"p1\">[</bpt>MediaCapture<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br241124)</ept>, which provides access to a device's camera, and <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>MediaComposition<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn652646)</ept>, which allows you to create complex compositions out of media clips.","pos":[1005,1357],"source":" Custom effects can be used with several different Windows Runtime APIs including [MediaCapture](https://msdn.microsoft.com/library/windows/apps/br241124), which provides access to a device's camera, and [**MediaComposition**](https://msdn.microsoft.com/library/windows/apps/dn652646), which allows you to create complex compositions out of media clips."},{"content":"Add a custom effect to your app","pos":[1362,1393]},{"content":"A custom video effect is defined in a class that implements the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBasicVideoEffect<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764788)</ept> interface.","pos":[1396,1552],"source":"A custom video effect is defined in a class that implements the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788) interface."},{"content":"This class can't be included directly in your app's project.","pos":[1553,1613]},{"content":"Instead, you must use a Windows Runtime Component to host your video effect class.","pos":[1614,1696]},{"content":"Add a Windows Runtime Component for your video effect","pos":[1700,1753]},{"pos":[1761,1876],"content":"In Microsoft Visual Studio, with your solution open, go to the <bpt id=\"p1\">**</bpt>File<ept id=\"p1\">**</ept> menu and select <bpt id=\"p2\">**</bpt>Add-<ph id=\"ph1\">&amp;gt;</ph>New Project....<ept id=\"p2\">**</ept>","source":"In Microsoft Visual Studio, with your solution open, go to the **File** menu and select **Add-&gt;New Project....**"},{"pos":[1881,1955],"content":"Select the <bpt id=\"p1\">**</bpt>Windows Runtime Component (Universal Windows)<ept id=\"p1\">**</ept> project type.","source":"Select the **Windows Runtime Component (Universal Windows)** project type."},{"content":"For this example, name the project \"VideoEffectComponent\".","pos":[1960,2018]},{"content":"This name will be referenced in code later.","pos":[2019,2062]},{"pos":[2067,2080],"content":"Click <bpt id=\"p1\">**</bpt>OK<ept id=\"p1\">**</ept>.","source":"Click **OK**."},{"content":"The project template creates a class called Class1.cs.","pos":[2085,2139]},{"content":"In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right-click the icon for Class1.cs and select <bpt id=\"p2\">**</bpt>Rename<ept id=\"p2\">**</ept>.","pos":[2140,2223],"source":" In **Solution Explorer**, right-click the icon for Class1.cs and select **Rename**."},{"content":"Rename the file to \"ExampleVideoEffect.cs\".","pos":[2228,2271]},{"content":"Visual Studio will show a prompt asking if you want to update all references to the new name.","pos":[2272,2365]},{"content":"Click <bpt id=\"p1\">**</bpt>Yes<ept id=\"p1\">**</ept>.","pos":[2366,2380],"source":" Click **Yes**."},{"pos":[2385,2555],"content":"Open \"ExampleVideoEffect.cs\" and update the class definition to implement the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBasicVideoEffect<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764788)</ept> interface.","source":"Open \"ExampleVideoEffect.cs\" and update the class definition to implement the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788) interface."},{"pos":[2567,2593],"content":"ImplementIBasicVideoEffect"},{"content":"You need to include the following namespaces in your effect class file in order to access all of the types used in the examples in this article.","pos":[2704,2848]},{"pos":[2860,2871],"content":"EffectUsing"},{"content":"Implement the IBasicVideoEffect interface using software processing","pos":[2970,3037]},{"content":"Your video effect must implement all of the methods and properties of the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBasicVideoEffect<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764788)</ept> interface.","pos":[3040,3206],"source":"Your video effect must implement all of the methods and properties of the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788) interface."},{"content":"This section walks you through a simple implementation of this interface that uses software processing.","pos":[3207,3310]},{"content":"Close method","pos":[3316,3328]},{"content":"The system will call the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Close<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764789)</ept> method on your class when the effect should shut down.","pos":[3330,3479],"source":"The system will call the [**Close**](https://msdn.microsoft.com/library/windows/apps/dn764789) method on your class when the effect should shut down."},{"content":"You should use this method to dispose of any resources you have created.","pos":[3480,3552]},{"content":"The argument to the method is a MediaEffectClosedReason that lets you know whether the effect was closed normally, if an error occurred, or if the effect does not support the required encoding format.","pos":[3553,3753]},{"pos":[3765,3770],"content":"Close"},{"content":"DiscardQueuedFrames method","pos":[3864,3890]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>DiscardQueuedFrames<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764790)</ept> method is called when your effect should reset.","pos":[3892,4027],"source":"The [**DiscardQueuedFrames**](https://msdn.microsoft.com/library/windows/apps/dn764790) method is called when your effect should reset."},{"content":"A typical scenario for this is if your effect stores previously processed frames to use in processing the current frame.","pos":[4028,4148]},{"content":"When this method is called, you should dispose of the set of previous frames you have saved.","pos":[4149,4241]},{"content":"Although this method can be used to reset any state related to previous frames, not only accumulated video frames.","pos":[4242,4356]},{"pos":[4369,4388],"content":"DiscardQueuedFrames"},{"content":"IsReadOnly property","pos":[4497,4516]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IsReadOnly<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764792)</ept> property lets the system know if your effect will write to the output of the effect.","pos":[4518,4681],"source":"The [**IsReadOnly**](https://msdn.microsoft.com/library/windows/apps/dn764792) property lets the system know if your effect will write to the output of the effect."},{"content":"If your app does not modify the video frames - for example, an effect that only performs analysis of the video frames - then you should set this property to true, which will cause the system to efficiently copy the frame input to the frame output for you.","pos":[4682,4937]},{"content":"<bpt id=\"p1\">**</bpt>Tip<ept id=\"p1\">**</ept>  When the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IsReadOnly<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn764792)</ept> property is set to true, the system copies the input frame to the output frame before <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>ProcessFrame<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/dn764794)</ept> is called.","pos":[4939,5205],"source":"**Tip**  When the [**IsReadOnly**](https://msdn.microsoft.com/library/windows/apps/dn764792) property is set to true, the system copies the input frame to the output frame before [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764794) is called."},{"content":"Setting the <bpt id=\"p1\">**</bpt>IsReadOnly<ept id=\"p1\">**</ept> property to true does not restrict you from writing to the effect's output frames in <bpt id=\"p2\">**</bpt>ProcessFrame<ept id=\"p2\">**</ept>.","pos":[5206,5335],"source":" Setting the **IsReadOnly** property to true does not restrict you from writing to the effect's output frames in **ProcessFrame**."},{"pos":[5347,5357],"content":"IsReadOnly"},{"content":"SetEncodingProperties method","pos":[5457,5485]},{"content":"The system calls <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SetEncodingProperties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn919884)</ept> on your effect to let you know the encoding properties for the video stream upon which the effect is operating.","pos":[5487,5701],"source":"The system calls [**SetEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn919884) on your effect to let you know the encoding properties for the video stream upon which the effect is operating."},{"content":"This method also provides a reference to the Direct3D device used for hardware rendering.","pos":[5702,5791]},{"content":"The usage of this device is shown in the hardware processing example later in this article.","pos":[5792,5883]},{"pos":[5895,5916],"content":"SetEncodingProperties"},{"content":"SupportedEncodingProperties property","pos":[6026,6062]},{"content":"The system checks the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SupportedEncodingProperties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764799)</ept> property to determine which encoding properties are supported by your effect.","pos":[6064,6255],"source":"The system checks the [**SupportedEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn764799) property to determine which encoding properties are supported by your effect."},{"content":"Note that if the consumer of your effect can't encode video using the properties you specify, it will call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Close<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764789)</ept> on your effect and will remove your effect from the video pipeline.","pos":[6256,6500],"source":" Note that if the consumer of your effect can't encode video using the properties you specify, it will call [**Close**](https://msdn.microsoft.com/library/windows/apps/dn764789) on your effect and will remove your effect from the video pipeline."},{"pos":[6513,6540],"content":"SupportedEncodingProperties"},{"pos":[6652,6870],"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>  If you return an empty list of <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>VideoEncodingProperties<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/hh701217)</ept> objects from <bpt id=\"p4\">**</bpt>SupportedEncodingProperties<ept id=\"p4\">**</ept>, the system will default to ARGB32 encoding.","source":"**Note**  If you return an empty list of [**VideoEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/hh701217) objects from **SupportedEncodingProperties**, the system will default to ARGB32 encoding."},{"content":"SupportedMemoryTypes property","pos":[6879,6908]},{"content":"The system checks the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SupportedMemoryTypes<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764801)</ept> property to determine whether your effect will access video frames in software memory or in hardware (GPU) memory.","pos":[6910,7131],"source":"The system checks the [**SupportedMemoryTypes**](https://msdn.microsoft.com/library/windows/apps/dn764801) property to determine whether your effect will access video frames in software memory or in hardware (GPU) memory."},{"content":"If you return <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>MediaMemoryTypes.Cpu<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764822)</ept>, your effect will be passed input and output frames that contain image data in <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>SoftwareBitmap<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn887358)</ept> objects.","pos":[7132,7397],"source":" If you return [**MediaMemoryTypes.Cpu**](https://msdn.microsoft.com/library/windows/apps/dn764822), your effect will be passed input and output frames that contain image data in [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn887358) objects."},{"content":"If you return <bpt id=\"p1\">**</bpt>MediaMemoryTypes.Gpu<ept id=\"p1\">**</ept>, your effect will be passed input and output frames that contain image data in <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IDirect3DSurface<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn965505)</ept> objects.","pos":[7398,7605],"source":" If you return **MediaMemoryTypes.Gpu**, your effect will be passed input and output frames that contain image data in [**IDirect3DSurface**](https://msdn.microsoft.com/library/windows/apps/dn965505) objects."},{"pos":[7617,7637],"content":"SupportedMemoryTypes"},{"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>  If you specify <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>MediaMemoryTypes.GpuAndCpu<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn764822)</ept>, the system will use either GPU or system memory, whichever is more efficient for the pipeline.","pos":[7742,7953],"source":"**Note**  If you specify [**MediaMemoryTypes.GpuAndCpu**](https://msdn.microsoft.com/library/windows/apps/dn764822), the system will use either GPU or system memory, whichever is more efficient for the pipeline."},{"content":"When using this value, you must check in the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ProcessFrame<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764794)</ept> method to see whether the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>SoftwareBitmap<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn887358)</ept> or <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>IDirect3DSurface<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/dn965505)</ept> passed into the method contains data and then process the frame accordingly.","pos":[7954,8341],"source":" When using this value, you must check in the [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764794) method to see whether the [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn887358) or [**IDirect3DSurface**](https://msdn.microsoft.com/library/windows/apps/dn965505) passed into the method contains data and then process the frame accordingly."},{"content":"TimeIndependent property","pos":[8350,8374]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>TimeIndependent<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764803)</ept> property lets the system know whether your effect requires uniform timing.","pos":[8376,8534],"source":"The [**TimeIndependent**](https://msdn.microsoft.com/library/windows/apps/dn764803) property lets the system know whether your effect requires uniform timing."},{"content":"When set to true, the system can use optimizations that enhance effect performance.","pos":[8535,8618]},{"pos":[8630,8645],"content":"TimeIndependent"},{"content":"SetProperties method","pos":[8748,8768]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SetProperties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br240986)</ept> method allows the app that is using your effect to adjust effect parameters.","pos":[8770,8928],"source":"The [**SetProperties**](https://msdn.microsoft.com/library/windows/apps/br240986) method allows the app that is using your effect to adjust effect parameters."},{"content":"Properties are passed as an <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IPropertySet<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br226054)</ept> map of property names and values.","pos":[8929,9067],"source":" Properties are passed as an [**IPropertySet**](https://msdn.microsoft.com/library/windows/apps/br226054) map of property names and values."},{"pos":[9080,9093],"content":"SetProperties"},{"content":"This simple example will dim the pixels in each video frame according to a specified value.","pos":[9191,9282]},{"content":"A property is declared and TryGetValue is used to get the value set by the calling app.","pos":[9283,9370]},{"content":"If no value was set, a default value of .5 is used.","pos":[9371,9422]},{"pos":[9434,9443],"content":"FadeValue"},{"content":"ProcessFrame method","pos":[9541,9560]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ProcessFrame<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764794)</ept> method is where your effect modifies the image data of the video.","pos":[9562,9708],"source":"The [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764794) method is where your effect modifies the image data of the video."},{"content":"The method is called once per frame and is passed a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ProcessVideoFrameContext<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764826)</ept> object.","pos":[9709,9857],"source":" The method is called once per frame and is passed a [**ProcessVideoFrameContext**](https://msdn.microsoft.com/library/windows/apps/dn764826) object."},{"content":"This object contains an input <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VideoFrame<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn930917)</ept> object that contains the incoming frame to be processed and an output <bpt id=\"p3\">**</bpt>VideoFrame<ept id=\"p3\">**</ept> object to which you write image data that will be passed on to rest of the video pipeline.","pos":[9858,10138],"source":" This object contains an input [**VideoFrame**](https://msdn.microsoft.com/library/windows/apps/dn930917) object that contains the incoming frame to be processed and an output **VideoFrame** object to which you write image data that will be passed on to rest of the video pipeline."},{"content":"Each of these <bpt id=\"p1\">**</bpt>VideoFrame<ept id=\"p1\">**</ept> objects has a <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>SoftwareBitmap<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn930926)</ept> property and a <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>Direct3DSurface<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/dn930920)</ept> property, but which of these can be used is determined by the value you returned from the <bpt id=\"p6\">[</bpt><bpt id=\"p7\">**</bpt>SupportedMemoryTypes<ept id=\"p7\">**</ept><ept id=\"p6\">](https://msdn.microsoft.com/library/windows/apps/dn764801)</ept> property.","pos":[10139,10540],"source":" Each of these **VideoFrame** objects has a [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn930926) property and a [**Direct3DSurface**](https://msdn.microsoft.com/library/windows/apps/dn930920) property, but which of these can be used is determined by the value you returned from the [**SupportedMemoryTypes**](https://msdn.microsoft.com/library/windows/apps/dn764801) property."},{"content":"This example shows a simple implementation of the <bpt id=\"p1\">**</bpt>ProcessFrame<ept id=\"p1\">**</ept> method using software processing.","pos":[10542,10642],"source":"This example shows a simple implementation of the **ProcessFrame** method using software processing."},{"content":"For more information on working with <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SoftwareBitmap<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn887358)</ept> objects, see <bpt id=\"p3\">[</bpt>Imaging<ept id=\"p3\">](imaging.md)</ept>.","pos":[10643,10794],"source":" For more information on working with [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn887358) objects, see [Imaging](imaging.md)."},{"content":"An example <bpt id=\"p1\">**</bpt>ProcessFrame<ept id=\"p1\">**</ept> implementation using hardware processing is shown later in this article.","pos":[10795,10895],"source":" An example **ProcessFrame** implementation using hardware processing is shown later in this article."},{"pos":[10897,11066],"content":"Accessing the data buffer of a <bpt id=\"p1\">**</bpt>SoftwareBitmap<ept id=\"p1\">**</ept> requires COM interop, so you should include the <bpt id=\"p2\">**</bpt>System.Runtime.InteropServices<ept id=\"p2\">**</ept> namespace in your effect class file.","source":"Accessing the data buffer of a **SoftwareBitmap** requires COM interop, so you should include the **System.Runtime.InteropServices** namespace in your effect class file."},{"pos":[11078,11086],"content":"COMUsing"},{"content":"Add the following code inside the namespace for your effect to import the interface for accessing the image buffer.","pos":[11179,11294]},{"pos":[11306,11315],"content":"COMImport"},{"pos":[11409,11546],"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>  Because this technique accesses a native, unmanaged image buffer, you will need to configure your project to allow unsafe code.","source":"**Note**  Because this technique accesses a native, unmanaged image buffer, you will need to configure your project to allow unsafe code."},{"content":"In Solution Explorer, right-click the VideoEffectComponent project and select Properties....","pos":[11551,11643]},{"content":"Select the Build tab.","pos":[11648,11669]},{"content":"Check the checkbox for \"Allow unsafe code\"","pos":[11674,11716]},{"content":"Now you can add the <bpt id=\"p1\">**</bpt>ProcessFrame<ept id=\"p1\">**</ept> method implementation.","pos":[11721,11780],"source":"Now you can add the **ProcessFrame** method implementation."},{"content":"First, this method obtains a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>BitmapBuffer<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn887325)</ept> object from both the input and output software bitmaps.","pos":[11781,11942],"source":" First, this method obtains a [**BitmapBuffer**](https://msdn.microsoft.com/library/windows/apps/dn887325) object from both the input and output software bitmaps."},{"content":"Note that the output frame is opened for writing and the input for reading.","pos":[11943,12018]},{"content":"Next, an <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IMemoryBufferReference<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn921671)</ept> is obtained for each buffer by calling <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>CreateReference<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn949046)</ept>.","pos":[12019,12234],"source":" Next, an [**IMemoryBufferReference**](https://msdn.microsoft.com/library/windows/apps/dn921671) is obtained for each buffer by calling [**CreateReference**](https://msdn.microsoft.com/library/windows/apps/dn949046)."},{"content":"Then, the actual data buffer is obtained by casting the <bpt id=\"p1\">**</bpt>IMemoryBufferReference<ept id=\"p1\">**</ept> objects as the COM interop interface defined above, <bpt id=\"p2\">**</bpt>IMemoryByteAccess<ept id=\"p2\">**</ept>, and then calling <bpt id=\"p3\">**</bpt>GetBuffer<ept id=\"p3\">**</ept>.","pos":[12235,12424],"source":" Then, the actual data buffer is obtained by casting the **IMemoryBufferReference** objects as the COM interop interface defined above, **IMemoryByteAccess**, and then calling **GetBuffer**."},{"content":"Now that the data buffers have been obtained, you can read from the input buffer and write to the output buffer.","pos":[12426,12538]},{"content":"The layout of the buffer is obtained by calling <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>GetPlaneDescription<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn887330)</ept>, which provides information on the width, stride, and initial offset of the buffer.","pos":[12539,12754],"source":" The layout of the buffer is obtained by calling [**GetPlaneDescription**](https://msdn.microsoft.com/library/windows/apps/dn887330), which provides information on the width, stride, and initial offset of the buffer."},{"content":"The bits per pixel is determined by the encoding properties set previously with the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SetEncodingProperties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn919884)</ept> method.","pos":[12755,12932],"source":" The bits per pixel is determined by the encoding properties set previously with the [**SetEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn919884) method."},{"content":"The buffer format information is used to find the index into the buffer for each pixel.","pos":[12933,13020]},{"content":"The pixel value from the source buffer is copied into the target buffer, with the color values being multiplied by the FadeValue property defined for this effect to dim them by the specified amount.","pos":[13021,13219]},{"pos":[13231,13257],"content":"ProcessFrameSoftwareBitmap"},{"content":"Implement the IBasicVideoEffect interface using hardware processing","pos":[13371,13438]},{"content":"Creating a custom video effect using hardware (GPU) processing is almost identical to using software processing as described above.","pos":[13441,13572]},{"content":"This section will show the few differences in an effect that uses hardware processing.","pos":[13573,13659]},{"content":"This example uses the Win2D Windows Runtime API.","pos":[13660,13708]},{"content":"For more information on using Win2D, see the <bpt id=\"p1\">[</bpt>Win2D documentation<ept id=\"p1\">](http://go.microsoft.com/fwlink/?LinkId=519078)</ept>.","pos":[13709,13823],"source":" For more information on using Win2D, see the [Win2D documentation](http://go.microsoft.com/fwlink/?LinkId=519078)."},{"pos":[13825,14021],"content":"Use the following steps to add the Win2D NuGet package to the project you created as described in the <bpt id=\"p1\">[</bpt>Add a custom effect to your app<ept id=\"p1\">](#addacustomeffect)</ept> section at the beginning of this article.","source":"Use the following steps to add the Win2D NuGet package to the project you created as described in the [Add a custom effect to your app](#addacustomeffect) section at the beginning of this article."},{"content":"Add the Win2D NuGet package to your effect project","pos":[14025,14075]},{"pos":[14083,14197],"content":"In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right-click the <bpt id=\"p2\">**</bpt>VideoEffectComponent<ept id=\"p2\">**</ept> project and select <bpt id=\"p3\">**</bpt>Manage NuGet Packages...<ept id=\"p3\">**</ept>","source":"In **Solution Explorer**, right-click the **VideoEffectComponent** project and select **Manage NuGet Packages...**"},{"pos":[14202,14254],"content":"At the top of the window, select the <bpt id=\"p1\">**</bpt>Browse<ept id=\"p1\">**</ept> tab.","source":"At the top of the window, select the **Browse** tab."},{"content":"In the search box, type \"Win2D\".","pos":[14259,14291]},{"pos":[14296,14359],"content":"Click on <bpt id=\"p1\">**</bpt>Win2D.uwp<ept id=\"p1\">**</ept> and the click Install in the right pane.","source":"Click on **Win2D.uwp** and the click Install in the right pane."},{"content":"The <bpt id=\"p1\">**</bpt>Review Changes<ept id=\"p1\">**</ept> dialog shows you the package to be installed.","pos":[14364,14432],"source":"The **Review Changes** dialog shows you the package to be installed."},{"content":"Click <bpt id=\"p1\">**</bpt>OK<ept id=\"p1\">**</ept>.","pos":[14433,14446],"source":" Click **OK**."},{"content":"Accept the package license.","pos":[14451,14478]},{"content":"In addition to the namespaces included in the basic project setup, you will need to include the following namespaces provided by Win2D.","pos":[14480,14615]},{"pos":[14627,14637],"content":"UsingWin2D"},{"pos":[14737,15016],"content":"Because this effect will use GPU memory for operating on the image data, you should return <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>MediaMemoryTypes.Gpu<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764822)</ept> from the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>SupportedMemoryTypes<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn764801)</ept> property.","source":"Because this effect will use GPU memory for operating on the image data, you should return [**MediaMemoryTypes.Gpu**](https://msdn.microsoft.com/library/windows/apps/dn764822) from the [**SupportedMemoryTypes**](https://msdn.microsoft.com/library/windows/apps/dn764801) property."},{"pos":[15028,15053],"content":"SupportedMemoryTypesWin2D"},{"content":"Set the encoding properties your effect will support with the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SupportedEncodingProperties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764799)</ept> property.","pos":[15168,15331],"source":"Set the encoding properties your effect will support with the [**SupportedEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn764799) property."},{"content":"When working with Win2D, you must use ARGB32 encoding.","pos":[15332,15386]},{"pos":[15398,15430],"content":"SupportedEncodingPropertiesWin2D"},{"pos":[15552,15811],"content":"Use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SetEncodingProperties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn919884)</ept> method to create a new Win2D <bpt id=\"p3\">**</bpt>CanvasDevice<ept id=\"p3\">**</ept> object from the <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>IDirect3DDevice<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/dn895092)</ept> passed into the method.","source":"Use the [**SetEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn919884) method to create a new Win2D **CanvasDevice** object from the [**IDirect3DDevice**](https://msdn.microsoft.com/library/windows/apps/dn895092) passed into the method."},{"pos":[15823,15849],"content":"SetEncodingPropertiesWin2D"},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SetProperties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br240986)</ept> implementation is identical to the software processing example above.","pos":[15965,16116],"source":"The [**SetProperties**](https://msdn.microsoft.com/library/windows/apps/br240986) implementation is identical to the software processing example above."},{"content":"This example uses a <bpt id=\"p1\">**</bpt>BlurAmount<ept id=\"p1\">**</ept> property to configure a Win2D blur effect.","pos":[16117,16194],"source":" This example uses a **BlurAmount** property to configure a Win2D blur effect."},{"pos":[16206,16224],"content":"SetPropertiesWin2D"},{"pos":[16341,16356],"content":"BlurAmountWin2D"},{"pos":[16461,16618],"content":"The last step is to implement the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ProcessFrame<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn764794)</ept> method that actually processes the image data.","source":"The last step is to implement the [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764794) method that actually processes the image data."},{"content":"Using Win2D APIs, a <bpt id=\"p1\">**</bpt>CanvasBitmap<ept id=\"p1\">**</ept> is created from the input frame's <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>Direct3DSurface<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn930920)</ept> property.","pos":[16620,16780],"source":"Using Win2D APIs, a **CanvasBitmap** is created from the input frame's [**Direct3DSurface**](https://msdn.microsoft.com/library/windows/apps/dn930920) property."},{"content":"A <bpt id=\"p1\">**</bpt>CanvasRenderTarget<ept id=\"p1\">**</ept> is created from the output frame's <bpt id=\"p2\">**</bpt>Direct3DSurface<ept id=\"p2\">**</ept> and a <bpt id=\"p3\">**</bpt>CanvasDrawingSession<ept id=\"p3\">**</ept> is created from this render target.","pos":[16781,16927],"source":" A **CanvasRenderTarget** is created from the output frame's **Direct3DSurface** and a **CanvasDrawingSession** is created from this render target."},{"content":"A new Win2D <bpt id=\"p1\">**</bpt>GaussianBlurEffect<ept id=\"p1\">**</ept> is initialized, using the <bpt id=\"p2\">**</bpt>BlurAmount<ept id=\"p2\">**</ept> property our effect exposes via <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>SetProperties<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br240986)</ept>.","pos":[16928,17114],"source":" A new Win2D **GaussianBlurEffect** is initialized, using the **BlurAmount** property our effect exposes via [**SetProperties**](https://msdn.microsoft.com/library/windows/apps/br240986)."},{"content":"Finally, the <bpt id=\"p1\">**</bpt>CanvasDrawingSession.DrawImage<ept id=\"p1\">**</ept> method is called to draw the input bitmap to the render target using the blur effect.","pos":[17115,17248],"source":" Finally, the **CanvasDrawingSession.DrawImage** method is called to draw the input bitmap to the render target using the blur effect."},{"pos":[17260,17277],"content":"ProcessFrameWin2D"},{"content":"Adding your custom effect to your app","pos":[17387,17424]},{"content":"In order to use your video effect from your app, you must add a reference to the effect project to your app.","pos":[17427,17535]},{"content":"In Solution Explorer, under your app project, right-click References and select Add reference...","pos":[17541,17637]},{"content":"Expand the Projects tab, click Solution, and select the checkbox for your effect project name.","pos":[17642,17736]},{"content":"For this example, the name is VideoEffectComponent.","pos":[17737,17788]},{"content":"Click OK.","pos":[17793,17802]},{"content":"Add your custom effect to a camera video stream","pos":[17808,17855]},{"content":"You can set up a simple preview stream from the camera by following the steps in the article <bpt id=\"p1\">[</bpt>Simple camera preview access<ept id=\"p1\">](simple-camera-preview-access.md)</ept>.","pos":[17857,18014],"source":"You can set up a simple preview stream from the camera by following the steps in the article [Simple camera preview access](simple-camera-preview-access.md)."},{"content":"Following those steps will provide you with an initialized <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>MediaCapture<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br241124)</ept> object that is used to access the camera's video stream.","pos":[18015,18207],"source":" Following those steps will provide you with an initialized [**MediaCapture**](https://msdn.microsoft.com/library/windows/apps/br241124) object that is used to access the camera's video stream."},{"content":"To add your custom video effect to a camera stream, first create a new <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VideoEffectDefinition<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn608055)</ept> object, passing in the namespace and class name for your effect.","pos":[18209,18430],"source":"To add your custom video effect to a camera stream, first create a new [**VideoEffectDefinition**](https://msdn.microsoft.com/library/windows/apps/dn608055) object, passing in the namespace and class name for your effect."},{"content":"Next call the <bpt id=\"p1\">**</bpt>MediaCapture<ept id=\"p1\">**</ept> object's <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>AddVideoEffect<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn878035)</ept> method to add your effect to the specified stream.","pos":[18431,18600],"source":" Next call the **MediaCapture** object's [**AddVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn878035) method to add your effect to the specified stream."},{"content":"This example uses the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>MediaStreamType.VideoPreview<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br226640)</ept> value to specify that the effect should be added to the preview stream.","pos":[18601,18787],"source":" This example uses the [**MediaStreamType.VideoPreview**](https://msdn.microsoft.com/library/windows/apps/br226640) value to specify that the effect should be added to the preview stream."},{"content":"If your app supports video capture, you could also use <bpt id=\"p1\">**</bpt>MediaStreamType.VideoRecord<ept id=\"p1\">**</ept> to add the effect to the capture stream.","pos":[18788,18915],"source":" If your app supports video capture, you could also use **MediaStreamType.VideoRecord** to add the effect to the capture stream."},{"content":"<bpt id=\"p1\">**</bpt>AddVideoEffect<ept id=\"p1\">**</ept> returns an <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>IMediaExtension<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/br240985)</ept> object representing your custom effect.","pos":[18916,19065],"source":"**AddVideoEffect** returns an [**IMediaExtension**](https://msdn.microsoft.com/library/windows/apps/br240985) object representing your custom effect."},{"content":"You can use the SetProperties method to set the configuration for your effect.","pos":[19066,19144]},{"pos":[19146,19298],"content":"Once the effect has been added, <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>StartPreviewAsync<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br226613)</ept> is called to start the preview stream.","source":"Once the effect has been added, [**StartPreviewAsync**](https://msdn.microsoft.com/library/windows/apps/br226613) is called to start the preview stream."},{"pos":[19310,19329],"content":"AddVideoEffectAsync"},{"content":"Add your custom effect to a clip in a MediaComposition","pos":[19430,19484]},{"content":"For general guidance oncreating media compositions from video clips, see <bpt id=\"p1\">[</bpt>Media compositions and editing<ept id=\"p1\">](media-compositions-and-editing.md)</ept>.","pos":[19486,19627],"source":"For general guidance oncreating media compositions from video clips, see [Media compositions and editing](media-compositions-and-editing.md)."},{"content":"The following code snippet shows the creation of a simple media composition with using a custom video effect.","pos":[19628,19737]},{"content":"A <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>MediaClip<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn652596)</ept> object is created by calling <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>CreateFromFileAsync<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn652607)</ept>, passing in a video file that was selected by the user with a <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>FileOpenPicker<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br207847)</ept> and the clip is added to a new <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>MediaComposition<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/dn652646)</ept>.","pos":[19738,20180],"source":" A [**MediaClip**](https://msdn.microsoft.com/library/windows/apps/dn652596) object is created by calling [**CreateFromFileAsync**](https://msdn.microsoft.com/library/windows/apps/dn652607), passing in a video file that was selected by the user with a [**FileOpenPicker**](https://msdn.microsoft.com/library/windows/apps/br207847) and the clip is added to a new [**MediaComposition**](https://msdn.microsoft.com/library/windows/apps/dn652646)."},{"content":"Next a new <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VideoEffectDefinition<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn608055)</ept> object is created, passing in the namespace and class name for your effect to the constructor.","pos":[20181,20372],"source":" Next a new [**VideoEffectDefinition**](https://msdn.microsoft.com/library/windows/apps/dn608055) object is created, passing in the namespace and class name for your effect to the constructor."},{"content":"Finally, the effect definition is added to the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VideoEffectDefinitions<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn652643)</ept> collection of the <bpt id=\"p3\">**</bpt>MediaClip<ept id=\"p3\">**</ept> object.","pos":[20373,20546],"source":" Finally, the effect definition is added to the [**VideoEffectDefinitions**](https://msdn.microsoft.com/library/windows/apps/dn652643) collection of the **MediaClip** object."},{"pos":[20559,20581],"content":"AddEffectToComposition"},{"content":"Related topics","pos":[20683,20697]},{"pos":[20700,20900],"content":"<bpt id=\"p1\">[</bpt>Simple camera preview access<ept id=\"p1\">](simple-camera-preview-access.md)</ept><ph id=\"ph1\">\n</ph><bpt id=\"p2\">[</bpt>Media compositions and editing<ept id=\"p2\">](media-compositions-and-editing.md)</ept><ph id=\"ph2\">\n</ph><bpt id=\"p3\">[</bpt>Win2D documentation<ept id=\"p3\">](http://go.microsoft.com/fwlink/?LinkId=519078)</ept>","source":"[Simple camera preview access](simple-camera-preview-access.md)\n[Media compositions and editing](media-compositions-and-editing.md)\n[Win2D documentation](http://go.microsoft.com/fwlink/?LinkId=519078)"}],"content":"---\nauthor: drewbatgit\nDescription: 'This article describes how to create a Windows Runtime Compontent that implements the IBasicVideoEffect interface to allows you to create custom effects for video streams.'\nMS-HAID: 'dev\\_audio\\_vid\\_camera.custom\\_video\\_effects'\nMSHAttr: 'PreferredLib:/library/windows/apps'\nSearch.Product: eADQiWindows 10XVcnh\ntitle: Custom video effects\n---\n\n# Custom video effects\n\n\n\\[ Updated for UWP apps on Windows 10. For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]\n\n\n\\[Some information relates to pre-released product which may be substantially modified before it's commercially released. Microsoft makes no warranties, express or implied, with respect to the information provided here.\\]\n\nThis article describes how to create a Windows Runtime Compontent that implements the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788) interface to allows you to create custom effects for video streams. Custom effects can be used with several different Windows Runtime APIs including [MediaCapture](https://msdn.microsoft.com/library/windows/apps/br241124), which provides access to a device's camera, and [**MediaComposition**](https://msdn.microsoft.com/library/windows/apps/dn652646), which allows you to create complex compositions out of media clips.\n\n## Add a custom effect to your app\n\n\nA custom video effect is defined in a class that implements the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788) interface. This class can't be included directly in your app's project. Instead, you must use a Windows Runtime Component to host your video effect class.\n\n**Add a Windows Runtime Component for your video effect**\n\n1.  In Microsoft Visual Studio, with your solution open, go to the **File** menu and select **Add-&gt;New Project....**\n2.  Select the **Windows Runtime Component (Universal Windows)** project type.\n3.  For this example, name the project \"VideoEffectComponent\". This name will be referenced in code later.\n4.  Click **OK**.\n5.  The project template creates a class called Class1.cs. In **Solution Explorer**, right-click the icon for Class1.cs and select **Rename**.\n6.  Rename the file to \"ExampleVideoEffect.cs\". Visual Studio will show a prompt asking if you want to update all references to the new name. Click **Yes**.\n7.  Open \"ExampleVideoEffect.cs\" and update the class definition to implement the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788) interface.\n\n[!code-cs[ImplementIBasicVideoEffect](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetImplementIBasicVideoEffect)]\n\n\nYou need to include the following namespaces in your effect class file in order to access all of the types used in the examples in this article.\n\n[!code-cs[EffectUsing](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetEffectUsing)]\n\n\n## Implement the IBasicVideoEffect interface using software processing\n\n\nYour video effect must implement all of the methods and properties of the [**IBasicVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn764788) interface. This section walks you through a simple implementation of this interface that uses software processing.\n\n### Close method\n\nThe system will call the [**Close**](https://msdn.microsoft.com/library/windows/apps/dn764789) method on your class when the effect should shut down. You should use this method to dispose of any resources you have created. The argument to the method is a MediaEffectClosedReason that lets you know whether the effect was closed normally, if an error occurred, or if the effect does not support the required encoding format.\n\n[!code-cs[Close](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetClose)]\n\n\n### DiscardQueuedFrames method\n\nThe [**DiscardQueuedFrames**](https://msdn.microsoft.com/library/windows/apps/dn764790) method is called when your effect should reset. A typical scenario for this is if your effect stores previously processed frames to use in processing the current frame. When this method is called, you should dispose of the set of previous frames you have saved. Although this method can be used to reset any state related to previous frames, not only accumulated video frames.\n\n\n[!code-cs[DiscardQueuedFrames](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetDiscardQueuedFrames)]\n\n\n\n### IsReadOnly property\n\nThe [**IsReadOnly**](https://msdn.microsoft.com/library/windows/apps/dn764792) property lets the system know if your effect will write to the output of the effect. If your app does not modify the video frames - for example, an effect that only performs analysis of the video frames - then you should set this property to true, which will cause the system to efficiently copy the frame input to the frame output for you.\n\n**Tip**  When the [**IsReadOnly**](https://msdn.microsoft.com/library/windows/apps/dn764792) property is set to true, the system copies the input frame to the output frame before [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764794) is called. Setting the **IsReadOnly** property to true does not restrict you from writing to the effect's output frames in **ProcessFrame**.\n\n[!code-cs[IsReadOnly](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetIsReadOnly)] \n\n\n### SetEncodingProperties method\n\nThe system calls [**SetEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn919884) on your effect to let you know the encoding properties for the video stream upon which the effect is operating. This method also provides a reference to the Direct3D device used for hardware rendering. The usage of this device is shown in the hardware processing example later in this article.\n\n[!code-cs[SetEncodingProperties](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetSetEncodingProperties)]\n\n\n### SupportedEncodingProperties property\n\nThe system checks the [**SupportedEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn764799) property to determine which encoding properties are supported by your effect. Note that if the consumer of your effect can't encode video using the properties you specify, it will call [**Close**](https://msdn.microsoft.com/library/windows/apps/dn764789) on your effect and will remove your effect from the video pipeline.\n\n\n[!code-cs[SupportedEncodingProperties](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetSupportedEncodingProperties)]\n\n\n**Note**  If you return an empty list of [**VideoEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/hh701217) objects from **SupportedEncodingProperties**, the system will default to ARGB32 encoding.\n\n \n\n### SupportedMemoryTypes property\n\nThe system checks the [**SupportedMemoryTypes**](https://msdn.microsoft.com/library/windows/apps/dn764801) property to determine whether your effect will access video frames in software memory or in hardware (GPU) memory. If you return [**MediaMemoryTypes.Cpu**](https://msdn.microsoft.com/library/windows/apps/dn764822), your effect will be passed input and output frames that contain image data in [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn887358) objects. If you return **MediaMemoryTypes.Gpu**, your effect will be passed input and output frames that contain image data in [**IDirect3DSurface**](https://msdn.microsoft.com/library/windows/apps/dn965505) objects.\n\n[!code-cs[SupportedMemoryTypes](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetSupportedMemoryTypes)]\n\n\n**Note**  If you specify [**MediaMemoryTypes.GpuAndCpu**](https://msdn.microsoft.com/library/windows/apps/dn764822), the system will use either GPU or system memory, whichever is more efficient for the pipeline. When using this value, you must check in the [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764794) method to see whether the [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn887358) or [**IDirect3DSurface**](https://msdn.microsoft.com/library/windows/apps/dn965505) passed into the method contains data and then process the frame accordingly.\n\n \n\n### TimeIndependent property\n\nThe [**TimeIndependent**](https://msdn.microsoft.com/library/windows/apps/dn764803) property lets the system know whether your effect requires uniform timing. When set to true, the system can use optimizations that enhance effect performance.\n\n[!code-cs[TimeIndependent](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetTimeIndependent)]\n\n### SetProperties method\n\nThe [**SetProperties**](https://msdn.microsoft.com/library/windows/apps/br240986) method allows the app that is using your effect to adjust effect parameters. Properties are passed as an [**IPropertySet**](https://msdn.microsoft.com/library/windows/apps/br226054) map of property names and values.\n\n\n[!code-cs[SetProperties](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetSetProperties)]\n\n\nThis simple example will dim the pixels in each video frame according to a specified value. A property is declared and TryGetValue is used to get the value set by the calling app. If no value was set, a default value of .5 is used.\n\n[!code-cs[FadeValue](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetFadeValue)]\n\n\n### ProcessFrame method\n\nThe [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764794) method is where your effect modifies the image data of the video. The method is called once per frame and is passed a [**ProcessVideoFrameContext**](https://msdn.microsoft.com/library/windows/apps/dn764826) object. This object contains an input [**VideoFrame**](https://msdn.microsoft.com/library/windows/apps/dn930917) object that contains the incoming frame to be processed and an output **VideoFrame** object to which you write image data that will be passed on to rest of the video pipeline. Each of these **VideoFrame** objects has a [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn930926) property and a [**Direct3DSurface**](https://msdn.microsoft.com/library/windows/apps/dn930920) property, but which of these can be used is determined by the value you returned from the [**SupportedMemoryTypes**](https://msdn.microsoft.com/library/windows/apps/dn764801) property.\n\nThis example shows a simple implementation of the **ProcessFrame** method using software processing. For more information on working with [**SoftwareBitmap**](https://msdn.microsoft.com/library/windows/apps/dn887358) objects, see [Imaging](imaging.md). An example **ProcessFrame** implementation using hardware processing is shown later in this article.\n\nAccessing the data buffer of a **SoftwareBitmap** requires COM interop, so you should include the **System.Runtime.InteropServices** namespace in your effect class file.\n\n[!code-cs[COMUsing](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetCOMUsing)]\n\n\nAdd the following code inside the namespace for your effect to import the interface for accessing the image buffer.\n\n[!code-cs[COMImport](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetCOMImport)]\n\n\n**Note**  Because this technique accesses a native, unmanaged image buffer, you will need to configure your project to allow unsafe code.\n1.  In Solution Explorer, right-click the VideoEffectComponent project and select Properties....\n2.  Select the Build tab.\n3.  Check the checkbox for \"Allow unsafe code\"\n\n \n\nNow you can add the **ProcessFrame** method implementation. First, this method obtains a [**BitmapBuffer**](https://msdn.microsoft.com/library/windows/apps/dn887325) object from both the input and output software bitmaps. Note that the output frame is opened for writing and the input for reading. Next, an [**IMemoryBufferReference**](https://msdn.microsoft.com/library/windows/apps/dn921671) is obtained for each buffer by calling [**CreateReference**](https://msdn.microsoft.com/library/windows/apps/dn949046). Then, the actual data buffer is obtained by casting the **IMemoryBufferReference** objects as the COM interop interface defined above, **IMemoryByteAccess**, and then calling **GetBuffer**.\n\nNow that the data buffers have been obtained, you can read from the input buffer and write to the output buffer. The layout of the buffer is obtained by calling [**GetPlaneDescription**](https://msdn.microsoft.com/library/windows/apps/dn887330), which provides information on the width, stride, and initial offset of the buffer. The bits per pixel is determined by the encoding properties set previously with the [**SetEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn919884) method. The buffer format information is used to find the index into the buffer for each pixel. The pixel value from the source buffer is copied into the target buffer, with the color values being multiplied by the FadeValue property defined for this effect to dim them by the specified amount.\n\n[!code-cs[ProcessFrameSoftwareBitmap](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffect.cs#SnippetProcessFrameSoftwareBitmap)]\n\n\n## Implement the IBasicVideoEffect interface using hardware processing\n\n\nCreating a custom video effect using hardware (GPU) processing is almost identical to using software processing as described above. This section will show the few differences in an effect that uses hardware processing. This example uses the Win2D Windows Runtime API. For more information on using Win2D, see the [Win2D documentation](http://go.microsoft.com/fwlink/?LinkId=519078).\n\nUse the following steps to add the Win2D NuGet package to the project you created as described in the [Add a custom effect to your app](#addacustomeffect) section at the beginning of this article.\n\n**Add the Win2D NuGet package to your effect project**\n\n1.  In **Solution Explorer**, right-click the **VideoEffectComponent** project and select **Manage NuGet Packages...**\n2.  At the top of the window, select the **Browse** tab.\n3.  In the search box, type \"Win2D\".\n4.  Click on **Win2D.uwp** and the click Install in the right pane.\n5.  The **Review Changes** dialog shows you the package to be installed. Click **OK**.\n6.  Accept the package license.\n\nIn addition to the namespaces included in the basic project setup, you will need to include the following namespaces provided by Win2D.\n\n[!code-cs[UsingWin2D](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffectWin2D.cs#SnippetUsingWin2D)]\n\n\nBecause this effect will use GPU memory for operating on the image data, you should return [**MediaMemoryTypes.Gpu**](https://msdn.microsoft.com/library/windows/apps/dn764822) from the [**SupportedMemoryTypes**](https://msdn.microsoft.com/library/windows/apps/dn764801) property.\n\n[!code-cs[SupportedMemoryTypesWin2D](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffectWin2D.cs#SnippetSupportedMemoryTypesWin2D)]\n\n\nSet the encoding properties your effect will support with the [**SupportedEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn764799) property. When working with Win2D, you must use ARGB32 encoding.\n\n[!code-cs[SupportedEncodingPropertiesWin2D](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffectWin2D.cs#SnippetSupportedEncodingPropertiesWin2D)]\n\n\nUse the [**SetEncodingProperties**](https://msdn.microsoft.com/library/windows/apps/dn919884) method to create a new Win2D **CanvasDevice** object from the [**IDirect3DDevice**](https://msdn.microsoft.com/library/windows/apps/dn895092) passed into the method.\n\n[!code-cs[SetEncodingPropertiesWin2D](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffectWin2D.cs#SnippetSetEncodingPropertiesWin2D)]\n\n\nThe [**SetProperties**](https://msdn.microsoft.com/library/windows/apps/br240986) implementation is identical to the software processing example above. This example uses a **BlurAmount** property to configure a Win2D blur effect.\n\n[!code-cs[SetPropertiesWin2D](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffectWin2D.cs#SnippetSetPropertiesWin2D)]\n\n[!code-cs[BlurAmountWin2D](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffectWin2D.cs#SnippetBlurAmountWin2D)]\n\n\nThe last step is to implement the [**ProcessFrame**](https://msdn.microsoft.com/library/windows/apps/dn764794) method that actually processes the image data.\n\nUsing Win2D APIs, a **CanvasBitmap** is created from the input frame's [**Direct3DSurface**](https://msdn.microsoft.com/library/windows/apps/dn930920) property. A **CanvasRenderTarget** is created from the output frame's **Direct3DSurface** and a **CanvasDrawingSession** is created from this render target. A new Win2D **GaussianBlurEffect** is initialized, using the **BlurAmount** property our effect exposes via [**SetProperties**](https://msdn.microsoft.com/library/windows/apps/br240986). Finally, the **CanvasDrawingSession.DrawImage** method is called to draw the input bitmap to the render target using the blur effect.\n\n[!code-cs[ProcessFrameWin2D](./code/VideoEffect_Win10/cs/VideoEffectComponent/ExampleVideoEffectWin2D.cs#SnippetProcessFrameWin2D)]\n\n\n## Adding your custom effect to your app\n\n\nIn order to use your video effect from your app, you must add a reference to the effect project to your app.\n\n1.  In Solution Explorer, under your app project, right-click References and select Add reference...\n2.  Expand the Projects tab, click Solution, and select the checkbox for your effect project name. For this example, the name is VideoEffectComponent.\n3.  Click OK.\n\n### Add your custom effect to a camera video stream\n\nYou can set up a simple preview stream from the camera by following the steps in the article [Simple camera preview access](simple-camera-preview-access.md). Following those steps will provide you with an initialized [**MediaCapture**](https://msdn.microsoft.com/library/windows/apps/br241124) object that is used to access the camera's video stream.\n\nTo add your custom video effect to a camera stream, first create a new [**VideoEffectDefinition**](https://msdn.microsoft.com/library/windows/apps/dn608055) object, passing in the namespace and class name for your effect. Next call the **MediaCapture** object's [**AddVideoEffect**](https://msdn.microsoft.com/library/windows/apps/dn878035) method to add your effect to the specified stream. This example uses the [**MediaStreamType.VideoPreview**](https://msdn.microsoft.com/library/windows/apps/br226640) value to specify that the effect should be added to the preview stream. If your app supports video capture, you could also use **MediaStreamType.VideoRecord** to add the effect to the capture stream. **AddVideoEffect** returns an [**IMediaExtension**](https://msdn.microsoft.com/library/windows/apps/br240985) object representing your custom effect. You can use the SetProperties method to set the configuration for your effect.\n\nOnce the effect has been added, [**StartPreviewAsync**](https://msdn.microsoft.com/library/windows/apps/br226613) is called to start the preview stream.\n\n[!code-cs[AddVideoEffectAsync](./code/VideoEffect_Win10/cs/VideoEffect_Win10/MainPage.xaml.cs#SnippetAddVideoEffectAsync)]\n\n\n\n### Add your custom effect to a clip in a MediaComposition\n\nFor general guidance oncreating media compositions from video clips, see [Media compositions and editing](media-compositions-and-editing.md). The following code snippet shows the creation of a simple media composition with using a custom video effect. A [**MediaClip**](https://msdn.microsoft.com/library/windows/apps/dn652596) object is created by calling [**CreateFromFileAsync**](https://msdn.microsoft.com/library/windows/apps/dn652607), passing in a video file that was selected by the user with a [**FileOpenPicker**](https://msdn.microsoft.com/library/windows/apps/br207847) and the clip is added to a new [**MediaComposition**](https://msdn.microsoft.com/library/windows/apps/dn652646). Next a new [**VideoEffectDefinition**](https://msdn.microsoft.com/library/windows/apps/dn608055) object is created, passing in the namespace and class name for your effect to the constructor. Finally, the effect definition is added to the [**VideoEffectDefinitions**](https://msdn.microsoft.com/library/windows/apps/dn652643) collection of the **MediaClip** object.\n\n\n[!code-cs[AddEffectToComposition](./code/VideoEffect_Win10/cs/VideoEffect_Win10/MainPage.xaml.cs#SnippetAddEffectToComposition)]\n\n\n## Related topics\n\n\n[Simple camera preview access](simple-camera-preview-access.md)\n[Media compositions and editing](media-compositions-and-editing.md)\n[Win2D documentation](http://go.microsoft.com/fwlink/?LinkId=519078)\n \n\n \n\n\n\n"}
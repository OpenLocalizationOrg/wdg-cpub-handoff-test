{"nodes":[{"pos":[11,26],"content":"Audio for games","needQuote":true,"needEscape":true,"nodes":[{"content":"Audio for games","pos":[0,15]}]},{"pos":[40,195],"content":"Learn how to develop and incorporate music and sounds into your DirectX game, and how to process the audio signals to create dynamic and positional sounds.","needQuote":true,"needEscape":true,"nodes":[{"content":"Learn how to develop and incorporate music and sounds into your DirectX game, and how to process the audio signals to create dynamic and positional sounds.","pos":[0,155]}]},{"content":"Audio for games","pos":[252,267]},{"content":"\\[ Updated for UWP apps on Windows 10.","pos":[270,308]},{"content":"For Windows 8.x articles, see the <bpt id=\"p1\">[</bpt>archive<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept> \\]","pos":[309,404],"source":" For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]"},{"content":"Learn how to develop and incorporate music and sounds into your DirectX game, and how to process the audio signals to create dynamic and positional sounds.","pos":[406,561]},{"content":"For audio programming, we recommend using the XAudio2 library in DirectX, and we use it here.","pos":[563,656]},{"content":"XAudio2 is a low-level audio library that provides a signal processing and mixing foundation for games, and it supports a variety of formats.","pos":[657,798]},{"content":"You can also implement simple sounds and music playback with <bpt id=\"p1\">[</bpt>Microsoft Media Foundation<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ms694197)</ept>.","pos":[800,951],"source":"You can also implement simple sounds and music playback with [Microsoft Media Foundation](https://msdn.microsoft.com/library/windows/desktop/ms694197)."},{"content":"Microsoft Media Foundation is designed for the playback of media files and streams, both audio and video, but can also be used in games, and is particularly useful for cinematic scenes or non-interactive components of your game.","pos":[952,1180]},{"content":"Concepts at a glance","pos":[1185,1205]},{"content":"Here are a few audio programming concepts we use in this section.","pos":[1208,1273]},{"content":"Signals are the basic unit of sound programming, analogous to pixels in graphics.","pos":[1279,1360]},{"content":"The digital signal processors (DSPs) that process them are like the pixel shaders of game audio.","pos":[1361,1457]},{"content":"They can transform signals, or combine them, or filter them.","pos":[1458,1518]},{"content":"By programming to the DSPs, you can alter your game's sound effects and music with as little or as much complexity as you need.","pos":[1519,1646]},{"content":"Voices are the submixed composites of two or more signals.","pos":[1651,1709]},{"content":"There are 3 types of XAudio2 voice objects: source, submix, and mastering voices.","pos":[1710,1791]},{"content":"Source voices operate on audio data provided by the client.","pos":[1792,1851]},{"content":"Source and submix voices send their output to one or more submix or mastering voices.","pos":[1852,1937]},{"content":"Submix and mastering voices mix the audio from all voices feeding them, and operate on the result.","pos":[1938,2036]},{"content":"Mastering voices write audio data to an audio device.","pos":[2037,2090]},{"content":"Mixing is the process of combining several discrete voices, such as the sound effects and the background audio that are played back in a scene, into a single stream.","pos":[2095,2260]},{"content":"Submixing is the process of combining several discrete signals, such as the component sounds of an engine noise, and creating a voice.","pos":[2261,2395]},{"content":"Audio formats.","pos":[2400,2414]},{"content":"Music and sound effects can be stored in a variety of digital formats for your game.","pos":[2415,2499]},{"content":"There are uncompressed formats, like WAV, and compressed formats like MP3 and OGG.","pos":[2500,2582]},{"content":"The more a sample is compressed -- typically designated by its bit rate, where the lower the bit rate is, the more lossy the compression -- the worse fidelity it has.","pos":[2583,2749]},{"content":"Fidelity can vary across compression schemes and bit rates, so experiment with them to find what works best for your game.","pos":[2750,2872]},{"content":"Sample rate and quality.","pos":[2877,2901]},{"content":"Sounds can be sampled at different rates, and sounds sampled at a lower rate have much poorer fidelity.","pos":[2902,3005]},{"content":"The sample rate for CD quality is 44.1 Khz (44100 Hz).","pos":[3006,3060]},{"content":"If you don't need high fidelity for a sound, you can choose a lower sample rate.","pos":[3061,3141]},{"content":"Higher rates may be appropriate for professional audio applications, but you probably don't need them unless your game demands professional fidelity sound.","pos":[3142,3297]},{"content":"Sound emitters (or sources).","pos":[3302,3330]},{"content":"In XAudio2, sound emitters are locations that emit a sound, be it a mere blip of a background noise or a snarling rock track played by an in-game jukebox.","pos":[3331,3485]},{"content":"You specify emitters by world coordinates.","pos":[3486,3528]},{"content":"Sound listeners.","pos":[3533,3549]},{"content":"A sound listener is often the player, or perhaps an AI entity in a more advanced game, that processes the sounds received from a listener.","pos":[3550,3688]},{"content":"You can submix that sound into the audio stream for playback to the player, or you can use it to take a specific in-game action, like awakening an AI guard marked as a listener.","pos":[3689,3866]},{"content":"Design considerations","pos":[3871,3892]},{"content":"Audio is a tremendously important part of game design and development.","pos":[3895,3965]},{"content":"Many gamers can recall a mediocre game elevated to legendary status just because of a memorable soundtrack, or great voice work and sound mixing, or overall stellar audio production.","pos":[3966,4148]},{"content":"Music and sound define a game's personality, and establish the main motive that defines the game and makes it stand apart from other similar games.","pos":[4149,4296]},{"content":"The effort you spend designing and developing your game's audio profile will be well worth it.","pos":[4297,4391]},{"content":"Positional 3D audio can add a level of immersion beyond that provided by 3D graphics.","pos":[4393,4478]},{"content":"If you are developing a complex game that simulates a world, or which demands a cinematic style, consider using 3D positional audio techniques to really draw the player in.","pos":[4479,4651]},{"content":"DirectX audio development roadmap","pos":[4656,4689]},{"content":"XAudio2 conceptual resources","pos":[4696,4724]},{"content":"XAudio2 is the audio mixing library for DirectX, and is primarily intended for developing high performance audio engines for games.","pos":[4726,4857]},{"content":"For game developers who want to add sound effects and background music to their modern games, XAudio2 offers an audio graph and mixing engine with low-latency and support for dynamic buffers, synchronous sample-accurate playback, and implicit source rate conversion.","pos":[4858,5124]},{"content":"Topic","pos":[5242,5247]},{"content":"Description","pos":[5270,5281]},{"content":"Introduction to XAudio2","pos":[5348,5371]},{"content":"The topic provides a list of the audio programming features supported by XAudio2.","pos":[5463,5544]},{"content":"Getting Started with XAudio2","pos":[5599,5627]},{"content":"This topic provides information on key XAudio2 concepts, XAudio2 versions, and the RIFF audio format.","pos":[5719,5820]},{"content":"Common Audio Programming Concepts","pos":[5874,5907]},{"content":"This topic provides an overview of common audio concepts with which an audio developer should be familiar.","pos":[5999,6105]},{"content":"XAudio2 Voices","pos":[6160,6174]},{"content":"This topic contains an overview of XAudio2 voices, which are used to submix, operate on, and master audio data.","pos":[6266,6377]},{"content":"XAudio2 Callbacks","pos":[6431,6448]},{"content":"This topic covers the XAudio 2 callbacks, which are used to prevent breaks in the audio playback.","pos":[6540,6637]},{"content":"XAudio2 Audio Graphs","pos":[6692,6712]},{"content":"This topic covers the XAudio2 audio processing graphs, which take a set of audio streams from the client as input, process them, and deliver the final result to an audio device.","pos":[6804,6981]},{"content":"XAudio2 Audio Effects","pos":[7035,7056]},{"content":"The topic covers XAudio2 audio effects, which take incoming audio data and perform some operation on the data (such as a reverb effect) before passing it on.","pos":[7148,7305]},{"content":"Streaming Audio Data with XAudio2","pos":[7360,7393]},{"content":"This topic covers audio streaming with XAudio2.","pos":[7485,7532]},{"content":"X3DAudio","pos":[7586,7594]},{"content":"this topic covers X3DAudio, an API used in conjunction with XAudio2 to create the illusion of a sound coming from a point in 3D space.","pos":[7686,7820]},{"content":"XAudio2 Programming Reference","pos":[7875,7904]},{"content":"This section contains the complete reference for the XAudio2 APIs.","pos":[7996,8062]},{"content":"XAudio2 \"how to\" resources","pos":[8104,8130]},{"content":"Topic","pos":[8248,8253]},{"content":"Description","pos":[8276,8287]},{"content":"How to: Initialize XAudio2","pos":[8354,8380]},{"content":"Learn how to initialize XAudio2 for audio playback by creating an instance of the XAudio2 engine, and creating a mastering voice.","pos":[8472,8601]},{"content":"How to: Load Audio Data Files in XAudio2","pos":[8656,8696]},{"content":"Learn how to populate the structures required to play audio data in XAudio2.","pos":[8788,8864]},{"content":"How to: Play a Sound with XAudio2","pos":[8918,8951]},{"content":"Learn how to play previously-loaded audio data in XAudio2.","pos":[9043,9101]},{"content":"How to: Use Submix Voices","pos":[9156,9181]},{"content":"Learn how to set groups of voices to send their output to the same submix voice.","pos":[9273,9353]},{"content":"How to: Use Source Voice Callbacks","pos":[9407,9441]},{"content":"Learn how to use XAudio2 source voice callbacks.","pos":[9533,9581]},{"content":"How to: Use Engine Callbacks","pos":[9636,9664]},{"content":"Learn how to use XAudio2 engine callbacks.","pos":[9756,9798]},{"content":"How to: Build a Basic Audio Processing Graph","pos":[9852,9896]},{"content":"Learn how to create an audio processing graph, constructed from a single mastering voice and a single source voice.","pos":[9988,10103]},{"content":"How to: Dynamically Add or Remove Voices From an Audio Graph","pos":[10158,10218]},{"content":"Learn how to add or remove submix voices from a graph that has been created following the steps in <bpt id=\"p1\">[</bpt>How to: Build a Basic Audio Processing Graph<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ee415767)</ept>.","pos":[10310,10517],"source":"Learn how to add or remove submix voices from a graph that has been created following the steps in [How to: Build a Basic Audio Processing Graph](https://msdn.microsoft.com/library/windows/desktop/ee415767)."},{"content":"How to: Create an Effect Chain","pos":[10571,10601]},{"content":"Learn how to apply an effect chain to a voice to allow custom processing of the audio data for that voice.","pos":[10693,10799]},{"content":"How to: Create an XAPO","pos":[10854,10876]},{"content":"Learn how to implement [<ph id=\"ph1\">&lt;strong&gt;</ph>IXAPO<ph id=\"ph2\">&lt;/strong&gt;</ph>](https://msdn.microsoft.com/library/windows/desktop/ee415893) to create an XAudio2 audio processing object (XAPO).","pos":[10968,11129],"source":"Learn how to implement [<strong>IXAPO</strong>](https://msdn.microsoft.com/library/windows/desktop/ee415893) to create an XAudio2 audio processing object (XAPO)."},{"content":"How to: Add Run-time Parameter Support to an XAPO","pos":[11183,11232]},{"content":"Learn how to add run-time parameter support to an XAPO by implementing the [<ph id=\"ph1\">&lt;strong&gt;</ph>IXAPOParameters<ph id=\"ph2\">&lt;/strong&gt;</ph>](https://msdn.microsoft.com/library/windows/desktop/ee415896) interface.","pos":[11324,11505],"source":"Learn how to add run-time parameter support to an XAPO by implementing the [<strong>IXAPOParameters</strong>](https://msdn.microsoft.com/library/windows/desktop/ee415896) interface."},{"content":"How to: Use an XAPO in XAudio2","pos":[11560,11590]},{"content":"Learn how to use an effect implemented as an XAPO in an XAudio2 effect chain.","pos":[11682,11759]},{"content":"How to: Use XAPOFX in XAudio2","pos":[11813,11842]},{"content":"Learn how to use one of the effects included in XAPOFX in an XAudio2 effect chain.","pos":[11934,12016]},{"content":"How to: Stream a Sound from Disk","pos":[12071,12103]},{"content":"Learn how to stream audio data in XAudio2 by creating a separate thread to read an audio buffer, and to use callbacks to control that thread.","pos":[12195,12336]},{"content":"How to: Integrate X3DAudio with XAudio2","pos":[12390,12429]},{"content":"Learn how to use X3DAudio to provide the volume and pitch values for XAudio2 voices as well as the parameters for the XAudio2 built-in reverb effect.","pos":[12521,12670]},{"content":"How to: Group Audio Methods as an Operation Set","pos":[12725,12772]},{"content":"Learn how to use XAudio2 operation sets to make a group of method calls take effect at the same time.","pos":[12864,12965]},{"content":"Debugging Audio Glitches in XAudio2","pos":[13019,13054]},{"content":"Learn how to set the debug logging level for XAudio2.","pos":[13146,13199]},{"content":"Media Foundation resources","pos":[13241,13267]},{"content":"Media Foundation (MF) is a media platform for streaming audio and video playback.","pos":[13269,13350]},{"content":"You can use the Media Foundation APIs to stream audio and video encoded and compressed with a variety of algorithms.","pos":[13351,13467]},{"content":"It is not designed for real-time gameplay scenarios; instead, it provides powerful tools and broad codec support for more linear capture and presentation of audio and video components.","pos":[13468,13652]},{"content":"Topic","pos":[13770,13775]},{"content":"Description","pos":[13798,13809]},{"content":"About Media Foundation","pos":[13876,13898]},{"content":"This section contains general information about the Media Foundation APIs, and the tools available to support them.","pos":[13990,14105]},{"content":"Media Foundation: Essential Concepts","pos":[14160,14196]},{"content":"This topic introduces some concepts that you will need to understand before writing a Media Foundation application.","pos":[14288,14403]},{"content":"Media Foundation Architecture","pos":[14457,14486]},{"content":"This section describes the general design of Microsoft Media Foundation, as well as the media primitives and processing pipeline it uses.","pos":[14578,14715]},{"content":"Audio/Video Capture","pos":[14770,14789]},{"content":"This topic describes how to use Microsoft Media Foundation to perform audio and video capture.","pos":[14881,14975]},{"content":"Audio/Video Playback","pos":[15029,15049]},{"content":"This topic describes how to implement audio/video playback in your app.","pos":[15141,15212]},{"content":"Supported Media Formats in Media Foundation","pos":[15267,15310]},{"content":"This topic lists the media formats that Microsoft Media Foundation supports natively.","pos":[15402,15487]},{"content":"(Third parties can support additional formats by writing custom plug-ins.)","pos":[15488,15562]},{"content":"Encoding and File Authoring","pos":[15616,15643]},{"content":"This topic describes how to use Microsoft Media Foundation to perform audio and video encoding, and author media files.","pos":[15735,15854]},{"content":"Windows Media Codecs","pos":[15909,15929]},{"content":"This topic describes how to use the features of the Windows Media Audio and Video codecs to produce and consume compressed data streams.","pos":[16021,16157]},{"content":"Media Foundation Programming Reference","pos":[16211,16249]},{"content":"This section contains reference information for the Media Foundation APIs.","pos":[16341,16415]},{"content":"Media Foundation SDK Samples","pos":[16470,16498]},{"content":"This section lists sample apps that demonstrate how to use Media Foundation.","pos":[16590,16666]},{"content":"Windows Runtime XAML media types","pos":[16708,16740]},{"pos":[16742,16976],"content":"If you are using <bpt id=\"p1\">[</bpt>DirectX-XAML interop<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/hh825871)</ept>, you can incorporate the Windows Runtime XAML media APIs into your Windows Store apps using DirectX with C++ for simpler game scenarios.","source":"If you are using [DirectX-XAML interop](https://msdn.microsoft.com/library/windows/apps/hh825871), you can incorporate the Windows Runtime XAML media APIs into your Windows Store apps using DirectX with C++ for simpler game scenarios."},{"content":"Topic","pos":[17094,17099]},{"content":"Description","pos":[17122,17133]},{"content":"[<ph id=\"ph1\">&lt;strong&gt;</ph>Windows.UI.Xaml.Controls.MediaElement<ph id=\"ph2\">&lt;/strong&gt;</ph>](https://msdn.microsoft.com/library/windows/apps/br242926)","pos":[17199,17313],"source":"[<strong>Windows.UI.Xaml.Controls.MediaElement</strong>](https://msdn.microsoft.com/library/windows/apps/br242926)"},{"content":"XAML element that represents an object that contains audio, video, or both.","pos":[17343,17418]},{"content":"Audio, video, and camera","pos":[17473,17497]},{"content":"Learn how to incorporate basic audio and video in your Universal Windows Platform (UWP) app.","pos":[17586,17678]},{"content":"MediaElement","pos":[17732,17744]},{"content":"Learn how to play a locally-stored media file in your UWP app.","pos":[17833,17895]},{"content":"MediaElement","pos":[17950,17962]},{"content":"Learn how to stream a media file with low-latency in your UWP app.","pos":[18051,18117]},{"content":"Media casting","pos":[18171,18184]},{"content":"Learn how to use the Play To contract to stream media from your UWP app to another device.","pos":[18273,18363]},{"content":"Reference","pos":[18404,18413]},{"content":"XAudio2 Introduction","pos":[18421,18441]},{"content":"XAudio2 Programming Guide","pos":[18509,18534]},{"content":"Microsoft Media Foundation overview","pos":[18602,18637]},{"content":"Note","pos":[18705,18709]},{"content":"This article is for Windows 10 developers writing Universal Windows Platform (UWP) apps.","pos":[18714,18802]},{"content":"If you’re developing for Windows 8.x or Windows Phone 8.x, see the <bpt id=\"p1\">[</bpt>archived documentation<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept>.","pos":[18803,18944],"source":" If you’re developing for Windows 8.x or Windows Phone 8.x, see the [archived documentation](http://go.microsoft.com/fwlink/p/?linkid=619132)."},{"content":"Related topics","pos":[18952,18966]},{"content":"XAudio2 Programming Guide","pos":[18974,18999]}],"content":"---\ntitle: Audio for games\ndescription: Learn how to develop and incorporate music and sounds into your DirectX game, and how to process the audio signals to create dynamic and positional sounds.\nms.assetid: ab29297a-9588-c79b-24c5-3b94b85e74a8\n---\n\n# Audio for games\n\n\n\\[ Updated for UWP apps on Windows 10. For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]\n\nLearn how to develop and incorporate music and sounds into your DirectX game, and how to process the audio signals to create dynamic and positional sounds.\n\nFor audio programming, we recommend using the XAudio2 library in DirectX, and we use it here. XAudio2 is a low-level audio library that provides a signal processing and mixing foundation for games, and it supports a variety of formats.\n\nYou can also implement simple sounds and music playback with [Microsoft Media Foundation](https://msdn.microsoft.com/library/windows/desktop/ms694197). Microsoft Media Foundation is designed for the playback of media files and streams, both audio and video, but can also be used in games, and is particularly useful for cinematic scenes or non-interactive components of your game.\n\n## Concepts at a glance\n\n\nHere are a few audio programming concepts we use in this section.\n\n-   Signals are the basic unit of sound programming, analogous to pixels in graphics. The digital signal processors (DSPs) that process them are like the pixel shaders of game audio. They can transform signals, or combine them, or filter them. By programming to the DSPs, you can alter your game's sound effects and music with as little or as much complexity as you need.\n-   Voices are the submixed composites of two or more signals. There are 3 types of XAudio2 voice objects: source, submix, and mastering voices. Source voices operate on audio data provided by the client. Source and submix voices send their output to one or more submix or mastering voices. Submix and mastering voices mix the audio from all voices feeding them, and operate on the result. Mastering voices write audio data to an audio device.\n-   Mixing is the process of combining several discrete voices, such as the sound effects and the background audio that are played back in a scene, into a single stream. Submixing is the process of combining several discrete signals, such as the component sounds of an engine noise, and creating a voice.\n-   Audio formats. Music and sound effects can be stored in a variety of digital formats for your game. There are uncompressed formats, like WAV, and compressed formats like MP3 and OGG. The more a sample is compressed -- typically designated by its bit rate, where the lower the bit rate is, the more lossy the compression -- the worse fidelity it has. Fidelity can vary across compression schemes and bit rates, so experiment with them to find what works best for your game.\n-   Sample rate and quality. Sounds can be sampled at different rates, and sounds sampled at a lower rate have much poorer fidelity. The sample rate for CD quality is 44.1 Khz (44100 Hz). If you don't need high fidelity for a sound, you can choose a lower sample rate. Higher rates may be appropriate for professional audio applications, but you probably don't need them unless your game demands professional fidelity sound.\n-   Sound emitters (or sources). In XAudio2, sound emitters are locations that emit a sound, be it a mere blip of a background noise or a snarling rock track played by an in-game jukebox. You specify emitters by world coordinates.\n-   Sound listeners. A sound listener is often the player, or perhaps an AI entity in a more advanced game, that processes the sounds received from a listener. You can submix that sound into the audio stream for playback to the player, or you can use it to take a specific in-game action, like awakening an AI guard marked as a listener.\n\n## Design considerations\n\n\nAudio is a tremendously important part of game design and development. Many gamers can recall a mediocre game elevated to legendary status just because of a memorable soundtrack, or great voice work and sound mixing, or overall stellar audio production. Music and sound define a game's personality, and establish the main motive that defines the game and makes it stand apart from other similar games. The effort you spend designing and developing your game's audio profile will be well worth it.\n\nPositional 3D audio can add a level of immersion beyond that provided by 3D graphics. If you are developing a complex game that simulates a world, or which demands a cinematic style, consider using 3D positional audio techniques to really draw the player in.\n\n## DirectX audio development roadmap\n\n\n### XAudio2 conceptual resources\n\nXAudio2 is the audio mixing library for DirectX, and is primarily intended for developing high performance audio engines for games. For game developers who want to add sound effects and background music to their modern games, XAudio2 offers an audio graph and mixing engine with low-latency and support for dynamic buffers, synchronous sample-accurate playback, and implicit source rate conversion.\n\n<table>\n<colgroup>\n<col width=\"50%\" />\n<col width=\"50%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th align=\"left\">Topic</th>\n<th align=\"left\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td align=\"left\"><p>[Introduction to XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415813)</p></td>\n<td align=\"left\"><p>The topic provides a list of the audio programming features supported by XAudio2.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[Getting Started with XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415762)</p></td>\n<td align=\"left\"><p>This topic provides information on key XAudio2 concepts, XAudio2 versions, and the RIFF audio format.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[Common Audio Programming Concepts](https://msdn.microsoft.com/library/windows/desktop/ee415692)</p></td>\n<td align=\"left\"><p>This topic provides an overview of common audio concepts with which an audio developer should be familiar.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[XAudio2 Voices](https://msdn.microsoft.com/library/windows/desktop/ee415825)</p></td>\n<td align=\"left\"><p>This topic contains an overview of XAudio2 voices, which are used to submix, operate on, and master audio data.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[XAudio2 Callbacks](https://msdn.microsoft.com/library/windows/desktop/ee415745)</p></td>\n<td align=\"left\"><p>This topic covers the XAudio 2 callbacks, which are used to prevent breaks in the audio playback.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[XAudio2 Audio Graphs](https://msdn.microsoft.com/library/windows/desktop/ee415739)</p></td>\n<td align=\"left\"><p>This topic covers the XAudio2 audio processing graphs, which take a set of audio streams from the client as input, process them, and deliver the final result to an audio device.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[XAudio2 Audio Effects](https://msdn.microsoft.com/library/windows/desktop/ee415756)</p></td>\n<td align=\"left\"><p>The topic covers XAudio2 audio effects, which take incoming audio data and perform some operation on the data (such as a reverb effect) before passing it on.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[Streaming Audio Data with XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415821)</p></td>\n<td align=\"left\"><p>This topic covers audio streaming with XAudio2.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[X3DAudio](https://msdn.microsoft.com/library/windows/desktop/ee415714)</p></td>\n<td align=\"left\"><p>this topic covers X3DAudio, an API used in conjunction with XAudio2 to create the illusion of a sound coming from a point in 3D space.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[XAudio2 Programming Reference](https://msdn.microsoft.com/library/windows/desktop/ee415899)</p></td>\n<td align=\"left\"><p>This section contains the complete reference for the XAudio2 APIs.</p></td>\n</tr>\n</tbody>\n</table>\n\n \n\n### XAudio2 \"how to\" resources\n\n<table>\n<colgroup>\n<col width=\"50%\" />\n<col width=\"50%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th align=\"left\">Topic</th>\n<th align=\"left\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td align=\"left\"><p>[How to: Initialize XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415779)</p></td>\n<td align=\"left\"><p>Learn how to initialize XAudio2 for audio playback by creating an instance of the XAudio2 engine, and creating a mastering voice.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[How to: Load Audio Data Files in XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415781)</p></td>\n<td align=\"left\"><p>Learn how to populate the structures required to play audio data in XAudio2.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[How to: Play a Sound with XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415787)</p></td>\n<td align=\"left\"><p>Learn how to play previously-loaded audio data in XAudio2.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[How to: Use Submix Voices](https://msdn.microsoft.com/library/windows/desktop/ee415794)</p></td>\n<td align=\"left\"><p>Learn how to set groups of voices to send their output to the same submix voice.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[How to: Use Source Voice Callbacks](https://msdn.microsoft.com/library/windows/desktop/ee415769)</p></td>\n<td align=\"left\"><p>Learn how to use XAudio2 source voice callbacks.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[How to: Use Engine Callbacks](https://msdn.microsoft.com/library/windows/desktop/ee415774)</p></td>\n<td align=\"left\"><p>Learn how to use XAudio2 engine callbacks.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[How to: Build a Basic Audio Processing Graph](https://msdn.microsoft.com/library/windows/desktop/ee415767)</p></td>\n<td align=\"left\"><p>Learn how to create an audio processing graph, constructed from a single mastering voice and a single source voice.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[How to: Dynamically Add or Remove Voices From an Audio Graph](https://msdn.microsoft.com/library/windows/desktop/ee415772)</p></td>\n<td align=\"left\"><p>Learn how to add or remove submix voices from a graph that has been created following the steps in [How to: Build a Basic Audio Processing Graph](https://msdn.microsoft.com/library/windows/desktop/ee415767).</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[How to: Create an Effect Chain](https://msdn.microsoft.com/library/windows/desktop/ee415789)</p></td>\n<td align=\"left\"><p>Learn how to apply an effect chain to a voice to allow custom processing of the audio data for that voice.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[How to: Create an XAPO](https://msdn.microsoft.com/library/windows/desktop/ee415730)</p></td>\n<td align=\"left\"><p>Learn how to implement [<strong>IXAPO</strong>](https://msdn.microsoft.com/library/windows/desktop/ee415893) to create an XAudio2 audio processing object (XAPO).</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[How to: Add Run-time Parameter Support to an XAPO](https://msdn.microsoft.com/library/windows/desktop/ee415728)</p></td>\n<td align=\"left\"><p>Learn how to add run-time parameter support to an XAPO by implementing the [<strong>IXAPOParameters</strong>](https://msdn.microsoft.com/library/windows/desktop/ee415896) interface.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[How to: Use an XAPO in XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415733)</p></td>\n<td align=\"left\"><p>Learn how to use an effect implemented as an XAPO in an XAudio2 effect chain.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[How to: Use XAPOFX in XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415723)</p></td>\n<td align=\"left\"><p>Learn how to use one of the effects included in XAPOFX in an XAudio2 effect chain.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[How to: Stream a Sound from Disk](https://msdn.microsoft.com/library/windows/desktop/ee415791)</p></td>\n<td align=\"left\"><p>Learn how to stream audio data in XAudio2 by creating a separate thread to read an audio buffer, and to use callbacks to control that thread.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[How to: Integrate X3DAudio with XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415798)</p></td>\n<td align=\"left\"><p>Learn how to use X3DAudio to provide the volume and pitch values for XAudio2 voices as well as the parameters for the XAudio2 built-in reverb effect.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[How to: Group Audio Methods as an Operation Set](https://msdn.microsoft.com/library/windows/desktop/ee415783)</p></td>\n<td align=\"left\"><p>Learn how to use XAudio2 operation sets to make a group of method calls take effect at the same time.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[Debugging Audio Glitches in XAudio2](https://msdn.microsoft.com/library/windows/desktop/ee415765)</p></td>\n<td align=\"left\"><p>Learn how to set the debug logging level for XAudio2.</p></td>\n</tr>\n</tbody>\n</table>\n\n \n\n### Media Foundation resources\n\nMedia Foundation (MF) is a media platform for streaming audio and video playback. You can use the Media Foundation APIs to stream audio and video encoded and compressed with a variety of algorithms. It is not designed for real-time gameplay scenarios; instead, it provides powerful tools and broad codec support for more linear capture and presentation of audio and video components.\n\n<table>\n<colgroup>\n<col width=\"50%\" />\n<col width=\"50%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th align=\"left\">Topic</th>\n<th align=\"left\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td align=\"left\"><p>[About Media Foundation](https://msdn.microsoft.com/library/windows/desktop/ms696274)</p></td>\n<td align=\"left\"><p>This section contains general information about the Media Foundation APIs, and the tools available to support them.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[Media Foundation: Essential Concepts](https://msdn.microsoft.com/library/windows/desktop/ee663601)</p></td>\n<td align=\"left\"><p>This topic introduces some concepts that you will need to understand before writing a Media Foundation application.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[Media Foundation Architecture](https://msdn.microsoft.com/library/windows/desktop/ms696219)</p></td>\n<td align=\"left\"><p>This section describes the general design of Microsoft Media Foundation, as well as the media primitives and processing pipeline it uses.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[Audio/Video Capture](https://msdn.microsoft.com/library/windows/desktop/dd317910)</p></td>\n<td align=\"left\"><p>This topic describes how to use Microsoft Media Foundation to perform audio and video capture.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[Audio/Video Playback](https://msdn.microsoft.com/library/windows/desktop/dd317914)</p></td>\n<td align=\"left\"><p>This topic describes how to implement audio/video playback in your app.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[Supported Media Formats in Media Foundation](https://msdn.microsoft.com/library/windows/desktop/dd757927)</p></td>\n<td align=\"left\"><p>This topic lists the media formats that Microsoft Media Foundation supports natively. (Third parties can support additional formats by writing custom plug-ins.)</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[Encoding and File Authoring](https://msdn.microsoft.com/library/windows/desktop/dd318778)</p></td>\n<td align=\"left\"><p>This topic describes how to use Microsoft Media Foundation to perform audio and video encoding, and author media files.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[Windows Media Codecs](https://msdn.microsoft.com/library/windows/desktop/ff819508)</p></td>\n<td align=\"left\"><p>This topic describes how to use the features of the Windows Media Audio and Video codecs to produce and consume compressed data streams.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[Media Foundation Programming Reference](https://msdn.microsoft.com/library/windows/desktop/ms704847)</p></td>\n<td align=\"left\"><p>This section contains reference information for the Media Foundation APIs.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[Media Foundation SDK Samples](https://msdn.microsoft.com/library/windows/desktop/aa371827)</p></td>\n<td align=\"left\"><p>This section lists sample apps that demonstrate how to use Media Foundation.</p></td>\n</tr>\n</tbody>\n</table>\n\n \n\n### Windows Runtime XAML media types\n\nIf you are using [DirectX-XAML interop](https://msdn.microsoft.com/library/windows/apps/hh825871), you can incorporate the Windows Runtime XAML media APIs into your Windows Store apps using DirectX with C++ for simpler game scenarios.\n\n<table>\n<colgroup>\n<col width=\"50%\" />\n<col width=\"50%\" />\n</colgroup>\n<thead>\n<tr class=\"header\">\n<th align=\"left\">Topic</th>\n<th align=\"left\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"odd\">\n<td align=\"left\"><p>[<strong>Windows.UI.Xaml.Controls.MediaElement</strong>](https://msdn.microsoft.com/library/windows/apps/br242926)</p></td>\n<td align=\"left\"><p>XAML element that represents an object that contains audio, video, or both.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[Audio, video, and camera](https://msdn.microsoft.com/library/windows/apps/mt203788)</p></td>\n<td align=\"left\"><p>Learn how to incorporate basic audio and video in your Universal Windows Platform (UWP) app.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[MediaElement](https://msdn.microsoft.com/library/windows/apps/mt187272)</p></td>\n<td align=\"left\"><p>Learn how to play a locally-stored media file in your UWP app.</p></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\"><p>[MediaElement](https://msdn.microsoft.com/library/windows/apps/mt187272)</p></td>\n<td align=\"left\"><p>Learn how to stream a media file with low-latency in your UWP app.</p></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\"><p>[Media casting](https://msdn.microsoft.com/library/windows/apps/mt282143)</p></td>\n<td align=\"left\"><p>Learn how to use the Play To contract to stream media from your UWP app to another device.</p></td>\n</tr>\n</tbody>\n</table>\n\n \n\n## Reference\n\n\n-   [XAudio2 Introduction](https://msdn.microsoft.com/library/windows/desktop/ee415813)\n-   [XAudio2 Programming Guide](https://msdn.microsoft.com/library/windows/desktop/ee415737)\n-   [Microsoft Media Foundation overview](https://msdn.microsoft.com/library/windows/desktop/ms694197)\n\n> **Note**  \nThis article is for Windows 10 developers writing Universal Windows Platform (UWP) apps. If you’re developing for Windows 8.x or Windows Phone 8.x, see the [archived documentation](http://go.microsoft.com/fwlink/p/?linkid=619132).\n\n \n\n## Related topics\n\n\n-   [XAudio2 Programming Guide](https://msdn.microsoft.com/library/windows/desktop/ee415737)\n\n \n\n \n\n\n\n\n"}
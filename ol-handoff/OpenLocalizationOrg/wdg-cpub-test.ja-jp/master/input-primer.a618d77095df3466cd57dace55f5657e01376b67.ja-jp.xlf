<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0" srcLang="en-US" trgLang="ja-jp" version="2.0" xml:space="preserve" xmlns="urn:oasis:names:tc:xliff:document:2.0">
	<file id="1">
		<mda:metadata>
			<mda:metaGroup>
				<mda:meta type="tool-id">mdxliff</mda:meta>
				<mda:meta type="tool-name">mdxliff</mda:meta>
				<mda:meta type="tool-version">1.0-00ddeee</mda:meta>
				<mda:meta type="tool-company">Microsoft</mda:meta>
			</mda:metaGroup>
		<mda:metaGroup><mda:meta type="olfilehash">7c2b86a02d7e0f1cfe102f1e269a6ddd864e69c5</mda:meta><mda:meta type="olfilepath">wdg-cpub-test\ndolci2\input-and-devices\input-primer.md</mda:meta><mda:meta type="oltranslationpriority"></mda:meta><mda:meta type="oltranslationtype">Human Translation</mda:meta><mda:meta type="olskeletonhash">87ec81b8940f04fb4eb39e9b7a46a557bb865336</mda:meta><mda:meta type="olxliffhash">dee3e36efcfac7c973db1c6aac28ccbbcf8bd11d</mda:meta></mda:metaGroup></mda:metadata>
		<group id="content">
			<unit id="101" translate="yes">
				<segment state="initial">
					<source>User interactions in the Universal Windows Platform (UWP) are a combination of input and output sources (such as mouse, keyboard, pen, touch, touchpad, speech, Cortana, controller, gesture, gaze, and so on), along with various modes or modifiers that enable extended experiences (including mouse wheel and buttons, pen eraser and barrel buttons, touch keyboard, and background app services).</source>
					<target>User interactions in the Universal Windows Platform (UWP) are a combination of input and output sources (such as mouse, keyboard, pen, touch, touchpad, speech, Cortana, controller, gesture, gaze, and so on), along with various modes or modifiers that enable extended experiences (including mouse wheel and buttons, pen eraser and barrel buttons, touch keyboard, and background app services).</target>
				</segment>
			</unit>
			<unit id="102" translate="yes">
				<segment state="initial">
					<source>Interaction primer</source>
					<target>Interaction primer</target>
				</segment>
			</unit>
			<unit id="103" translate="yes">
				<segment state="initial">
					<source>Interaction primer</source>
					<target>Interaction primer</target>
				</segment>
			</unit>
			<unit id="104" translate="yes">
				<segment state="initial">
					<source>\[ Updated for UWP apps on Windows 10.</source>
					<target>\[ Updated for UWP apps on Windows 10.</target>
				</segment>
			</unit>
			<unit id="105" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](http://go.microsoft.com/fwlink/p/?linkid=619132)</data>
				</originalData>
				<segment state="initial">
					<source>For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</source>
					<target>For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</target>
				</segment>
			</unit>
			<unit id="106" translate="yes">
				<segment state="initial">
					<source>windows input types</source>
					<target>windows input types</target>
				</segment>
			</unit>
			<unit id="107" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>User interactions in the Universal Windows Platform (UWP) are a combination of input and output sources (such as mouse, keyboard, pen, touch, touchpad, speech, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc>, controller, gesture, gaze, and so on), along with various modes or modifiers that enable extended experiences (including mouse wheel and buttons, pen eraser and barrel buttons, touch keyboard, and background app services).</source>
					<target>User interactions in the Universal Windows Platform (UWP) are a combination of input and output sources (such as mouse, keyboard, pen, touch, touchpad, speech, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc>, controller, gesture, gaze, and so on), along with various modes or modifiers that enable extended experiences (including mouse wheel and buttons, pen eraser and barrel buttons, touch keyboard, and background app services).</target>
				</segment>
			</unit>
			<unit id="108" translate="yes">
				<segment state="initial">
					<source>The UWP uses a "smart" contextual interaction system that, in most cases, eliminates the need to individually handle the unique types of input received by your app.</source>
					<target>The UWP uses a "smart" contextual interaction system that, in most cases, eliminates the need to individually handle the unique types of input received by your app.</target>
				</segment>
			</unit>
			<unit id="109" translate="yes">
				<segment state="initial">
					<source>This includes handling touch, touchpad, mouse, and pen input as a generic pointer type to support static gestures such as tap or press-and-hold, manipulation gestures such as slide for panning, or rendering digital ink.</source>
					<target>This includes handling touch, touchpad, mouse, and pen input as a generic pointer type to support static gestures such as tap or press-and-hold, manipulation gestures such as slide for panning, or rendering digital ink.</target>
				</segment>
			</unit>
			<unit id="110" translate="yes">
				<segment state="initial">
					<source>Familiarize yourself with each input device type and its behaviors, capabilities, and limitations when paired with certain form factors.</source>
					<target>Familiarize yourself with each input device type and its behaviors, capabilities, and limitations when paired with certain form factors.</target>
				</segment>
			</unit>
			<unit id="111" translate="yes">
				<segment state="initial">
					<source>This can help you decide whether the platform controls and affordances are sufficient for your app, or require you to provide customized interaction experiences.</source>
					<target>This can help you decide whether the platform controls and affordances are sufficient for your app, or require you to provide customized interaction experiences.</target>
				</segment>
			</unit>
			<unit id="112" translate="yes">
				<segment state="initial">
					<source>Cortana</source>
					<target>Cortana</target>
				</segment>
			</unit>
			<unit id="113" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>In Windows 10, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc> extensibility lets you handle voice commands from a user and launch your application to carry out a single action.</source>
					<target>In Windows 10, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc> extensibility lets you handle voice commands from a user and launch your application to carry out a single action.</target>
				</segment>
			</unit>
			<unit id="114" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="115" translate="yes">
				<segment state="initial">
					<source>Phones and phablets</source>
					<target>Phones and phablets</target>
				</segment>
			</unit>
			<unit id="116" translate="yes">
				<segment state="initial">
					<source>Tablet</source>
					<target>Tablet</target>
				</segment>
			</unit>
			<unit id="117" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="118" translate="yes">
				<segment state="initial">
					<source>Surface Hub</source>
					<target>Surface Hub</target>
				</segment>
			</unit>
			<unit id="119" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="120" translate="yes">
				<segment state="initial">
					<source>Xbox</source>
					<target>Xbox</target>
				</segment>
			</unit>
			<unit id="121" translate="yes">
				<segment state="initial">
					<source>HoloLens</source>
					<target>HoloLens</target>
				</segment>
			</unit>
			<unit id="122" translate="yes">
				<segment state="initial">
					<source>cortana</source>
					<target>cortana</target>
				</segment>
			</unit>
			<unit id="123" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Typical usage A voice command is a single utterance, defined in a Voice Command Definition (VCD) file, directed at an installed app through <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc>.</source>
					<target>Typical usage A voice command is a single utterance, defined in a Voice Command Definition (VCD) file, directed at an installed app through <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc>.</target>
				</segment>
			</unit>
			<unit id="124" translate="yes">
				<segment state="initial">
					<source>The app can be launched in the foreground or background, depending on the level and complexity of the interaction.</source>
					<target>The app can be launched in the foreground or background, depending on the level and complexity of the interaction.</target>
				</segment>
			</unit>
			<unit id="125" translate="yes">
				<segment state="initial">
					<source>For instance, voice commands that require additional context or user input are best handled in the foreground, while basic commands can be handled in the background.</source>
					<target>For instance, voice commands that require additional context or user input are best handled in the foreground, while basic commands can be handled in the background.</target>
				</segment>
			</unit>
			<unit id="126" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Integrating the basic functionality of your app, and providing a central entry point for the user to accomplish most of the tasks without opening your app directly, lets <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc> become a liaison between your app and the user.</source>
					<target>Integrating the basic functionality of your app, and providing a central entry point for the user to accomplish most of the tasks without opening your app directly, lets <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc> become a liaison between your app and the user.</target>
				</segment>
			</unit>
			<unit id="127" translate="yes">
				<segment state="initial">
					<source>In many cases, this can save the user significant time and effort.</source>
					<target>In many cases, this can save the user significant time and effort.</target>
				</segment>
			</unit>
			<unit id="128" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn974233)</data>
				</originalData>
				<segment state="initial">
					<source>For more info, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana design guidelines</pc>.</source>
					<target>For more info, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana design guidelines</pc>.</target>
				</segment>
			</unit>
			<unit id="129" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn974233)</data>
				</originalData>
				<segment state="initial">
					<source>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana design guidelines</pc></source>
					<target>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana design guidelines</pc></target>
				</segment>
			</unit>
			<unit id="130" translate="yes">
				<segment state="initial">
					<source>Speech</source>
					<target>Speech</target>
				</segment>
			</unit>
			<unit id="131" translate="yes">
				<segment state="initial">
					<source>Speech is an effective and natural way for people to interact with applications.</source>
					<target>Speech is an effective and natural way for people to interact with applications.</target>
				</segment>
			</unit>
			<unit id="132" translate="yes">
				<segment state="initial">
					<source>It's an easy and accurate way to communicate with applications, and lets people be productive and stay informed in a variety of situations.</source>
					<target>It's an easy and accurate way to communicate with applications, and lets people be productive and stay informed in a variety of situations.</target>
				</segment>
			</unit>
			<unit id="133" translate="yes">
				<segment state="initial">
					<source>Speech can complement or, in many cases, be the primary input type, depending on the user's device.</source>
					<target>Speech can complement or, in many cases, be the primary input type, depending on the user's device.</target>
				</segment>
			</unit>
			<unit id="134" translate="yes">
				<segment state="initial">
					<source>For example, devices such as HoloLens and Xbox do not support traditional input types (aside from a software keyboard in specifc scenarios).</source>
					<target>For example, devices such as HoloLens and Xbox do not support traditional input types (aside from a software keyboard in specifc scenarios).</target>
				</segment>
			</unit>
			<unit id="135" translate="yes">
				<segment state="initial">
					<source>Instead, they rely on speech input and output (often combined with other non-traditional input types such as gaze and gesture) for most user interactions.</source>
					<target>Instead, they rely on speech input and output (often combined with other non-traditional input types such as gaze and gesture) for most user interactions.</target>
				</segment>
			</unit>
			<unit id="136" translate="yes">
				<segment state="initial">
					<source>Text-to-speech (also known as TTS, or speech synthesis) is used to inform or direct the user.</source>
					<target>Text-to-speech (also known as TTS, or speech synthesis) is used to inform or direct the user.</target>
				</segment>
			</unit>
			<unit id="137" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="138" translate="yes">
				<segment state="initial">
					<source>Phones and phablets</source>
					<target>Phones and phablets</target>
				</segment>
			</unit>
			<unit id="139" translate="yes">
				<segment state="initial">
					<source>Tablet</source>
					<target>Tablet</target>
				</segment>
			</unit>
			<unit id="140" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="141" translate="yes">
				<segment state="initial">
					<source>Surface Hub</source>
					<target>Surface Hub</target>
				</segment>
			</unit>
			<unit id="142" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="143" translate="yes">
				<segment state="initial">
					<source>Xbox</source>
					<target>Xbox</target>
				</segment>
			</unit>
			<unit id="144" translate="yes">
				<segment state="initial">
					<source>HoloLens</source>
					<target>HoloLens</target>
				</segment>
			</unit>
			<unit id="145" translate="yes">
				<segment state="initial">
					<source>speech</source>
					<target>speech</target>
				</segment>
			</unit>
			<unit id="146" translate="yes">
				<segment state="initial">
					<source>Typical usage</source>
					<target>Typical usage</target>
				</segment>
			</unit>
			<unit id="147" translate="yes">
				<segment state="initial">
					<source>There are three modes of Speech interaction:</source>
					<target>There are three modes of Speech interaction:</target>
				</segment>
			</unit>
			<unit id="148" translate="yes">
				<segment state="initial">
					<source>Natural language</source>
					<target>Natural language</target>
				</segment>
			</unit>
			<unit id="149" translate="yes">
				<segment state="initial">
					<source>Natural language is how we verbally interact with people on a regular basis.</source>
					<target>Natural language is how we verbally interact with people on a regular basis.</target>
				</segment>
			</unit>
			<unit id="150" translate="yes">
				<segment state="initial">
					<source>Our speech varies from person to person and situation to situation, and is generally understood.</source>
					<target>Our speech varies from person to person and situation to situation, and is generally understood.</target>
				</segment>
			</unit>
			<unit id="151" translate="yes">
				<segment state="initial">
					<source>When it's not, we often use different words and word order to get the same idea across.</source>
					<target>When it's not, we often use different words and word order to get the same idea across.</target>
				</segment>
			</unit>
			<unit id="152" translate="yes">
				<segment state="initial">
					<source>Natural language interactions with an app are similar: we speak to the app through our device as if it were a person and expect it to understand and react accordingly.</source>
					<target>Natural language interactions with an app are similar: we speak to the app through our device as if it were a person and expect it to understand and react accordingly.</target>
				</segment>
			</unit>
			<unit id="153" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Natural language is the most advanced mode of speech interaction, and can be implemented and exposed through <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc>.</source>
					<target>Natural language is the most advanced mode of speech interaction, and can be implemented and exposed through <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc>.</target>
				</segment>
			</unit>
			<unit id="154" translate="yes">
				<segment state="initial">
					<source>Command and control</source>
					<target>Command and control</target>
				</segment>
			</unit>
			<unit id="155" translate="yes">
				<segment state="initial">
					<source>Command and control is the use of verbal commands to activate controls and functionality such as clicking a button or selecting a menu item.</source>
					<target>Command and control is the use of verbal commands to activate controls and functionality such as clicking a button or selecting a menu item.</target>
				</segment>
			</unit>
			<unit id="156" translate="yes">
				<segment state="initial">
					<source>As command and control is critical to a successful user experience, a single input type is generally not recommended.</source>
					<target>As command and control is critical to a successful user experience, a single input type is generally not recommended.</target>
				</segment>
			</unit>
			<unit id="157" translate="yes">
				<segment state="initial">
					<source>Speech is typically one of several input options for a user based on their preferences or hardware capabilities.</source>
					<target>Speech is typically one of several input options for a user based on their preferences or hardware capabilities.</target>
				</segment>
			</unit>
			<unit id="158" translate="yes">
				<segment state="initial">
					<source>Dictation</source>
					<target>Dictation</target>
				</segment>
			</unit>
			<unit id="159" translate="yes">
				<segment state="initial">
					<source>The most basic speech input method.</source>
					<target>The most basic speech input method.</target>
				</segment>
			</unit>
			<unit id="160" translate="yes">
				<segment state="initial">
					<source>Each utterance is converted to text.</source>
					<target>Each utterance is converted to text.</target>
				</segment>
			</unit>
			<unit id="161" translate="yes">
				<segment state="initial">
					<source>Dictation is typically used when an app doesn’t need to understand meaning or intent.</source>
					<target>Dictation is typically used when an app doesn’t need to understand meaning or intent.</target>
				</segment>
			</unit>
			<unit id="162" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn596121)</data>
				</originalData>
				<segment state="initial">
					<source>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech design guidelines</pc></source>
					<target>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech design guidelines</pc></target>
				</segment>
			</unit>
			<unit id="163" translate="yes">
				<segment state="initial">
					<source>Pen</source>
					<target>Pen</target>
				</segment>
			</unit>
			<unit id="164" translate="yes">
				<segment state="initial">
					<source>A pen (or stylus) can serve as a pixel precise pointing device, like a mouse, and is the optimal device for digital ink input.</source>
					<target>A pen (or stylus) can serve as a pixel precise pointing device, like a mouse, and is the optimal device for digital ink input.</target>
				</segment>
			</unit>
			<unit id="165" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  There are two types of pen devices: active and passive.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  There are two types of pen devices: active and passive.</target>
				</segment>
			</unit>
			<unit id="166" translate="yes">
				<segment state="initial">
					<source>Passive pens do not contain electronics, and effectively emulate touch input from a finger.</source>
					<target>Passive pens do not contain electronics, and effectively emulate touch input from a finger.</target>
				</segment>
			</unit>
			<unit id="167" translate="yes">
				<segment state="initial">
					<source>They require a basic device display that recognizes input based on contact pressure.</source>
					<target>They require a basic device display that recognizes input based on contact pressure.</target>
				</segment>
			</unit>
			<unit id="168" translate="yes">
				<segment state="initial">
					<source>Because users often rest their hand as they write on the input surface, input data can become polluted due to unsuccessful palm rejection.</source>
					<target>Because users often rest their hand as they write on the input surface, input data can become polluted due to unsuccessful palm rejection.</target>
				</segment>
			</unit>
			<unit id="169" translate="yes">
				<segment state="initial">
					<source>Active pens contain electronics and can work with complex device displays to provide much more extensive input data (including hover, or proximity data) to the system and your app.</source>
					<target>Active pens contain electronics and can work with complex device displays to provide much more extensive input data (including hover, or proximity data) to the system and your app.</target>
				</segment>
			</unit>
			<unit id="170" translate="yes">
				<segment state="initial">
					<source>Palm rejection is much more robust.</source>
					<target>Palm rejection is much more robust.</target>
				</segment>
			</unit>
			<unit id="171" translate="yes">
				<segment state="initial">
					<source>When we refer to pen devices here, we are referring to active pens that provide rich input data and are used primarily for precise ink and pointing interactions.</source>
					<target>When we refer to pen devices here, we are referring to active pens that provide rich input data and are used primarily for precise ink and pointing interactions.</target>
				</segment>
			</unit>
			<unit id="172" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="173" translate="yes">
				<segment state="initial">
					<source>Phones and phablets</source>
					<target>Phones and phablets</target>
				</segment>
			</unit>
			<unit id="174" translate="yes">
				<segment state="initial">
					<source>Tablet</source>
					<target>Tablet</target>
				</segment>
			</unit>
			<unit id="175" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="176" translate="yes">
				<segment state="initial">
					<source>Surface Hub</source>
					<target>Surface Hub</target>
				</segment>
			</unit>
			<unit id="177" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="178" translate="yes">
				<segment state="initial">
					<source>pen</source>
					<target>pen</target>
				</segment>
			</unit>
			<unit id="179" translate="yes">
				<segment state="initial">
					<source>Typical usage The Windows ink platform, together with a pen, provides a natural way to create handwritten notes, drawings, and annotations.</source>
					<target>Typical usage The Windows ink platform, together with a pen, provides a natural way to create handwritten notes, drawings, and annotations.</target>
				</segment>
			</unit>
			<unit id="180" translate="yes">
				<segment state="initial">
					<source>The platform supports capturing ink data from digitizer input, generating ink data, rendering that data as ink strokes on the output device, managing the ink data, and performing handwriting recognition.</source>
					<target>The platform supports capturing ink data from digitizer input, generating ink data, rendering that data as ink strokes on the output device, managing the ink data, and performing handwriting recognition.</target>
				</segment>
			</unit>
			<unit id="181" translate="yes">
				<segment state="initial">
					<source>In addition to capturing the spatial movements of the pen as the user writes or draws, your app can also collect info such as pressure, shape, color, and opacity, to offer user experiences that closely resemble drawing on paper with a pen, pencil, or brush.</source>
					<target>In addition to capturing the spatial movements of the pen as the user writes or draws, your app can also collect info such as pressure, shape, color, and opacity, to offer user experiences that closely resemble drawing on paper with a pen, pencil, or brush.</target>
				</segment>
			</unit>
			<unit id="182" translate="yes">
				<segment state="initial">
					<source>Where pen and touch input diverge is the ability for touch to emulate direct manipulation of UI elements on the screen through physical gestures performed on those objects (such as swiping, sliding, dragging, rotating, and so on).</source>
					<target>Where pen and touch input diverge is the ability for touch to emulate direct manipulation of UI elements on the screen through physical gestures performed on those objects (such as swiping, sliding, dragging, rotating, and so on).</target>
				</segment>
			</unit>
			<unit id="183" translate="yes">
				<segment state="initial">
					<source>You should provide pen-specific UI commands, or affordances, to support these interactions.</source>
					<target>You should provide pen-specific UI commands, or affordances, to support these interactions.</target>
				</segment>
			</unit>
			<unit id="184" translate="yes">
				<segment state="initial">
					<source>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</source>
					<target>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</target>
				</segment>
			</unit>
			<unit id="185" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn456352)</data>
				</originalData>
				<segment state="initial">
					<source>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Pen design guidelines</pc></source>
					<target>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Pen design guidelines</pc></target>
				</segment>
			</unit>
			<unit id="186" translate="yes">
				<segment state="initial">
					<source>Touch</source>
					<target>Touch</target>
				</segment>
			</unit>
			<unit id="187" translate="yes">
				<segment state="initial">
					<source>With touch, physical gestures from one or more fingers can be used to either emulate the direct manipulation of UI elements (such as panning, rotating, resizing, or moving), as an alternative input method (similar to mouse or pen), or as a complementary input method (to modify aspects of other input, such as smudging an ink stroke drawn with a pen).</source>
					<target>With touch, physical gestures from one or more fingers can be used to either emulate the direct manipulation of UI elements (such as panning, rotating, resizing, or moving), as an alternative input method (similar to mouse or pen), or as a complementary input method (to modify aspects of other input, such as smudging an ink stroke drawn with a pen).</target>
				</segment>
			</unit>
			<unit id="188" translate="yes">
				<segment state="initial">
					<source>Tactile experiences such as this can provide more natural, real-world sensations for users as they interact with elements on a screen.</source>
					<target>Tactile experiences such as this can provide more natural, real-world sensations for users as they interact with elements on a screen.</target>
				</segment>
			</unit>
			<unit id="189" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="190" translate="yes">
				<segment state="initial">
					<source>Phones and phablets</source>
					<target>Phones and phablets</target>
				</segment>
			</unit>
			<unit id="191" translate="yes">
				<segment state="initial">
					<source>Tablet</source>
					<target>Tablet</target>
				</segment>
			</unit>
			<unit id="192" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="193" translate="yes">
				<segment state="initial">
					<source>Surface Hub</source>
					<target>Surface Hub</target>
				</segment>
			</unit>
			<unit id="194" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="195" translate="yes">
				<segment state="initial">
					<source>touch</source>
					<target>touch</target>
				</segment>
			</unit>
			<unit id="196" translate="yes">
				<segment state="initial">
					<source>Typical usage Support for touch input can vary significantly, depending on the device.</source>
					<target>Typical usage Support for touch input can vary significantly, depending on the device.</target>
				</segment>
			</unit>
			<unit id="197" translate="yes">
				<segment state="initial">
					<source>Some devices don't support touch at all, some devices support a single touch contact, while others support multi-touch (two or more contacts).</source>
					<target>Some devices don't support touch at all, some devices support a single touch contact, while others support multi-touch (two or more contacts).</target>
				</segment>
			</unit>
			<unit id="198" translate="yes">
				<segment state="initial">
					<source>Most devices that support multi-touch input, typically recognize ten unique, concurrent contacts.</source>
					<target>Most devices that support multi-touch input, typically recognize ten unique, concurrent contacts.</target>
				</segment>
			</unit>
			<unit id="199" translate="yes">
				<segment state="initial">
					<source>Surface Hub devices recognize 100 unique, concurrent touch contacts.</source>
					<target>Surface Hub devices recognize 100 unique, concurrent touch contacts.</target>
				</segment>
			</unit>
			<unit id="200" translate="yes">
				<segment state="initial">
					<source>In general, touch is:</source>
					<target>In general, touch is:</target>
				</segment>
			</unit>
			<unit id="201" translate="yes">
				<segment state="initial">
					<source>Single user, unless being used with a Microsoft Team device like Surface Hub, where collaboration is emphasized.</source>
					<target>Single user, unless being used with a Microsoft Team device like Surface Hub, where collaboration is emphasized.</target>
				</segment>
			</unit>
			<unit id="202" translate="yes">
				<segment state="initial">
					<source>Not constrained to device orientation.</source>
					<target>Not constrained to device orientation.</target>
				</segment>
			</unit>
			<unit id="203" translate="yes">
				<segment state="initial">
					<source>Used for all interactions, including text input (touch keyboard) and inking (app-configured).</source>
					<target>Used for all interactions, including text input (touch keyboard) and inking (app-configured).</target>
				</segment>
			</unit>
			<unit id="204" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/hh465370)</data>
				</originalData>
				<segment state="initial">
					<source>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Touch design guidelines</pc></source>
					<target>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Touch design guidelines</pc></target>
				</segment>
			</unit>
			<unit id="205" translate="yes">
				<segment state="initial">
					<source>Touchpad</source>
					<target>Touchpad</target>
				</segment>
			</unit>
			<unit id="206" translate="yes">
				<segment state="initial">
					<source>A touchpad combines both indirect multi-touch input with the precision input of a pointing device, such as a mouse.</source>
					<target>A touchpad combines both indirect multi-touch input with the precision input of a pointing device, such as a mouse.</target>
				</segment>
			</unit>
			<unit id="207" translate="yes">
				<segment state="initial">
					<source>This combination makes the touchpad suited to both a touch-optimized UI and the smaller targets of productivity apps.</source>
					<target>This combination makes the touchpad suited to both a touch-optimized UI and the smaller targets of productivity apps.</target>
				</segment>
			</unit>
			<unit id="208" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="209" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="210" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="211" translate="yes">
				<segment state="initial">
					<source>touchpad</source>
					<target>touchpad</target>
				</segment>
			</unit>
			<unit id="212" translate="yes">
				<segment state="initial">
					<source>Typical usage Touchpads typically support a set of touch gestures that provide support similar to touch for direct manipulation of objects and UI.</source>
					<target>Typical usage Touchpads typically support a set of touch gestures that provide support similar to touch for direct manipulation of objects and UI.</target>
				</segment>
			</unit>
			<unit id="213" translate="yes">
				<segment state="initial">
					<source>Because of this convergence of interaction experiences supported by touchpads, we recommend also providing mouse-style UI commands or affordances rather than relying solely on support for touch input.</source>
					<target>Because of this convergence of interaction experiences supported by touchpads, we recommend also providing mouse-style UI commands or affordances rather than relying solely on support for touch input.</target>
				</segment>
			</unit>
			<unit id="214" translate="yes">
				<segment state="initial">
					<source>Provide touchpad-specific UI commands, or affordances, to support these interactions.</source>
					<target>Provide touchpad-specific UI commands, or affordances, to support these interactions.</target>
				</segment>
			</unit>
			<unit id="215" translate="yes">
				<segment state="initial">
					<source>You should provide mouse-specific UI commands, or affordances, to support these interactions.</source>
					<target>You should provide mouse-specific UI commands, or affordances, to support these interactions.</target>
				</segment>
			</unit>
			<unit id="216" translate="yes">
				<segment state="initial">
					<source>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</source>
					<target>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</target>
				</segment>
			</unit>
			<unit id="217" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn456353)</data>
				</originalData>
				<segment state="initial">
					<source>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Touchpad design guidelines</pc></source>
					<target>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Touchpad design guidelines</pc></target>
				</segment>
			</unit>
			<unit id="218" translate="yes">
				<segment state="initial">
					<source>Keyboard</source>
					<target>Keyboard</target>
				</segment>
			</unit>
			<unit id="219" translate="yes">
				<segment state="initial">
					<source>A keyboard is the primary input device for text, and is often indispensable to people with certain disabilities or users who consider it a faster and more efficient way to interact with an app.</source>
					<target>A keyboard is the primary input device for text, and is often indispensable to people with certain disabilities or users who consider it a faster and more efficient way to interact with an app.</target>
				</segment>
			</unit>
			<unit id="220" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](http://go.microsoft.com/fwlink/p/?LinkID=699431)</data>
				</originalData>
				<segment state="initial">
					<source>With <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Continuum for Phone</pc>, a new experience for compatible Windows 10 mobile devices, users can connect their phones to a mouse and keyboard to make their phones work like a laptop.</source>
					<target>With <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Continuum for Phone</pc>, a new experience for compatible Windows 10 mobile devices, users can connect their phones to a mouse and keyboard to make their phones work like a laptop.</target>
				</segment>
			</unit>
			<unit id="221" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="222" translate="yes">
				<segment state="initial">
					<source>Phones and phablets</source>
					<target>Phones and phablets</target>
				</segment>
			</unit>
			<unit id="223" translate="yes">
				<segment state="initial">
					<source>Tablet</source>
					<target>Tablet</target>
				</segment>
			</unit>
			<unit id="224" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="225" translate="yes">
				<segment state="initial">
					<source>Surface Hub</source>
					<target>Surface Hub</target>
				</segment>
			</unit>
			<unit id="226" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="227" translate="yes">
				<segment state="initial">
					<source>Xbox</source>
					<target>Xbox</target>
				</segment>
			</unit>
			<unit id="228" translate="yes">
				<segment state="initial">
					<source>HoloLens</source>
					<target>HoloLens</target>
				</segment>
			</unit>
			<unit id="229" translate="yes">
				<segment state="initial">
					<source>keyboard</source>
					<target>keyboard</target>
				</segment>
			</unit>
			<unit id="230" translate="yes">
				<segment state="initial">
					<source>Typical usage Users can interact with Universal Windows apps through a hardware keyboard and two software keyboards: the On-Screen Keyboard (OSK) and the touch keyboard.</source>
					<target>Typical usage Users can interact with Universal Windows apps through a hardware keyboard and two software keyboards: the On-Screen Keyboard (OSK) and the touch keyboard.</target>
				</segment>
			</unit>
			<unit id="231" translate="yes">
				<segment state="initial">
					<source>The OSK is a visual, software keyboard that you can use instead of the physical keyboard to type and enter data using touch, mouse, pen/stylus or other pointing device (a touch screen is not required).</source>
					<target>The OSK is a visual, software keyboard that you can use instead of the physical keyboard to type and enter data using touch, mouse, pen/stylus or other pointing device (a touch screen is not required).</target>
				</segment>
			</unit>
			<unit id="232" translate="yes">
				<segment state="initial">
					<source>The OSK is provided for systems that don't have a physical keyboard, or for users whose mobility impairments prevent them from using traditional physical input devices.</source>
					<target>The OSK is provided for systems that don't have a physical keyboard, or for users whose mobility impairments prevent them from using traditional physical input devices.</target>
				</segment>
			</unit>
			<unit id="233" translate="yes">
				<segment state="initial">
					<source>The OSK emulates most, if not all, the functionality of a hardware keyboard.</source>
					<target>The OSK emulates most, if not all, the functionality of a hardware keyboard.</target>
				</segment>
			</unit>
			<unit id="234" translate="yes">
				<segment state="initial">
					<source>The touch keyboard is a visual, software keyboard used for text entry with touch input.</source>
					<target>The touch keyboard is a visual, software keyboard used for text entry with touch input.</target>
				</segment>
			</unit>
			<unit id="235" translate="yes">
				<segment state="initial">
					<source>The touch keyboard is not a replacement for the OSK as it is used for text input only (it doesn't emulate the hardware keyboard) and appears only when a text field or other editable text control gets focus.</source>
					<target>The touch keyboard is not a replacement for the OSK as it is used for text input only (it doesn't emulate the hardware keyboard) and appears only when a text field or other editable text control gets focus.</target>
				</segment>
			</unit>
			<unit id="236" translate="yes">
				<segment state="initial">
					<source>The touch keyboard does not support app or system commands.</source>
					<target>The touch keyboard does not support app or system commands.</target>
				</segment>
			</unit>
			<unit id="237" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  The OSK has priority over the touch keyboard, which won't be shown if the OSK is present.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  The OSK has priority over the touch keyboard, which won't be shown if the OSK is present.</target>
				</segment>
			</unit>
			<unit id="238" translate="yes">
				<segment state="initial">
					<source>In general, a keyboard is:</source>
					<target>In general, a keyboard is:</target>
				</segment>
			</unit>
			<unit id="239" translate="yes">
				<segment state="initial">
					<source>Single user.</source>
					<target>Single user.</target>
				</segment>
			</unit>
			<unit id="240" translate="yes">
				<segment state="initial">
					<source>Not constrained to device orientation.</source>
					<target>Not constrained to device orientation.</target>
				</segment>
			</unit>
			<unit id="241" translate="yes">
				<segment state="initial">
					<source>Used for text input, navigation, gameplay, and accessibility.</source>
					<target>Used for text input, navigation, gameplay, and accessibility.</target>
				</segment>
			</unit>
			<unit id="242" translate="yes">
				<segment state="initial">
					<source>Always available, either proactively or reactively.</source>
					<target>Always available, either proactively or reactively.</target>
				</segment>
			</unit>
			<unit id="243" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/hh972345)</data>
				</originalData>
				<segment state="initial">
					<source>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Keyboard design guidelines</pc></source>
					<target>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Keyboard design guidelines</pc></target>
				</segment>
			</unit>
			<unit id="244" translate="yes">
				<segment state="initial">
					<source>Mouse</source>
					<target>Mouse</target>
				</segment>
			</unit>
			<unit id="245" translate="yes">
				<segment state="initial">
					<source>A mouse is best suited for productivity apps and high-density UI where user interactions require pixel-level precision for targeting and commanding.</source>
					<target>A mouse is best suited for productivity apps and high-density UI where user interactions require pixel-level precision for targeting and commanding.</target>
				</segment>
			</unit>
			<unit id="246" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="247" translate="yes">
				<segment state="initial">
					<source>Phones and phablets</source>
					<target>Phones and phablets</target>
				</segment>
			</unit>
			<unit id="248" translate="yes">
				<segment state="initial">
					<source>Tablet</source>
					<target>Tablet</target>
				</segment>
			</unit>
			<unit id="249" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="250" translate="yes">
				<segment state="initial">
					<source>Surface Hub</source>
					<target>Surface Hub</target>
				</segment>
			</unit>
			<unit id="251" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="252" translate="yes">
				<segment state="initial">
					<source>mouse</source>
					<target>mouse</target>
				</segment>
			</unit>
			<unit id="253" translate="yes">
				<segment state="initial">
					<source>Typical usage Mouse input can be modified with the addition of various keyboard keys (Ctrl, Shift, Alt, and so on).</source>
					<target>Typical usage Mouse input can be modified with the addition of various keyboard keys (Ctrl, Shift, Alt, and so on).</target>
				</segment>
			</unit>
			<unit id="254" translate="yes">
				<segment state="initial">
					<source>These keys can be combined with the left mouse button, the right mouse button, the wheel button, and the X buttons for an expanded mouse-optimized command set.</source>
					<target>These keys can be combined with the left mouse button, the right mouse button, the wheel button, and the X buttons for an expanded mouse-optimized command set.</target>
				</segment>
			</unit>
			<unit id="255" translate="yes">
				<segment state="initial">
					<source>(Some Microsoft mouse devices have two additional buttons, referred to as X buttons, typically used to navigate back and forward in Web browsers).</source>
					<target>(Some Microsoft mouse devices have two additional buttons, referred to as X buttons, typically used to navigate back and forward in Web browsers).</target>
				</segment>
			</unit>
			<unit id="256" translate="yes">
				<segment state="initial">
					<source>Similar to pen, where mouse and touch input diverge is the ability for touch to emulate direct manipulation of UI elements on the screen through physical gestures performed on those objects (such as swiping, sliding, dragging, rotating, and so on).</source>
					<target>Similar to pen, where mouse and touch input diverge is the ability for touch to emulate direct manipulation of UI elements on the screen through physical gestures performed on those objects (such as swiping, sliding, dragging, rotating, and so on).</target>
				</segment>
			</unit>
			<unit id="257" translate="yes">
				<segment state="initial">
					<source>You should provide mouse-specific UI commands, or affordances, to support these interactions.</source>
					<target>You should provide mouse-specific UI commands, or affordances, to support these interactions.</target>
				</segment>
			</unit>
			<unit id="258" translate="yes">
				<segment state="initial">
					<source>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</source>
					<target>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</target>
				</segment>
			</unit>
			<unit id="259" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn456351)</data>
				</originalData>
				<segment state="initial">
					<source>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Mouse design guidelines</pc></source>
					<target>More info <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Mouse design guidelines</pc></target>
				</segment>
			</unit>
			<unit id="260" translate="yes">
				<segment state="initial">
					<source>Gesture</source>
					<target>Gesture</target>
				</segment>
			</unit>
			<unit id="261" translate="yes">
				<segment state="initial">
					<source>A gesture is any form of user movement that is recognized as input for controlling or interacting with an application.</source>
					<target>A gesture is any form of user movement that is recognized as input for controlling or interacting with an application.</target>
				</segment>
			</unit>
			<unit id="262" translate="yes">
				<segment state="initial">
					<source>Gestures take many forms, from simply using a hand to target something on the screen, to specific, learned patterns of movement, to long stretches of continuous movement using the entire body.</source>
					<target>Gestures take many forms, from simply using a hand to target something on the screen, to specific, learned patterns of movement, to long stretches of continuous movement using the entire body.</target>
				</segment>
			</unit>
			<unit id="263" translate="yes">
				<segment state="initial">
					<source>Be careful when designing custom gestures, as their meaning can vary depending on locale and culture.</source>
					<target>Be careful when designing custom gestures, as their meaning can vary depending on locale and culture.</target>
				</segment>
			</unit>
			<unit id="264" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="265" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="266" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="267" translate="yes">
				<segment state="initial">
					<source>Xbox</source>
					<target>Xbox</target>
				</segment>
			</unit>
			<unit id="268" translate="yes">
				<segment state="initial">
					<source>HoloLens</source>
					<target>HoloLens</target>
				</segment>
			</unit>
			<unit id="269" translate="yes">
				<segment state="initial">
					<source>gesture</source>
					<target>gesture</target>
				</segment>
			</unit>
			<unit id="270" translate="yes">
				<segment state="initial">
					<source>Typical usage Touchpads typically support a set of touch gestures that provide support similar to touch for direct manipulation of objects and UI.</source>
					<target>Typical usage Touchpads typically support a set of touch gestures that provide support similar to touch for direct manipulation of objects and UI.</target>
				</segment>
			</unit>
			<unit id="271" translate="yes">
				<segment state="initial">
					<source>Because of this convergence of interaction experiences supported by touchpads, we recommend also providing mouse-style UI commands or affordances rather than relying solely on support for touch input.</source>
					<target>Because of this convergence of interaction experiences supported by touchpads, we recommend also providing mouse-style UI commands or affordances rather than relying solely on support for touch input.</target>
				</segment>
			</unit>
			<unit id="272" translate="yes">
				<segment state="initial">
					<source>Provide touchpad-specific UI commands, or affordances, to support these interactions.</source>
					<target>Provide touchpad-specific UI commands, or affordances, to support these interactions.</target>
				</segment>
			</unit>
			<unit id="273" translate="yes">
				<segment state="initial">
					<source>You should provide mouse-specific UI commands, or affordances, to support these interactions.</source>
					<target>You should provide mouse-specific UI commands, or affordances, to support these interactions.</target>
				</segment>
			</unit>
			<unit id="274" translate="yes">
				<segment state="initial">
					<source>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</source>
					<target>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</target>
				</segment>
			</unit>
			<unit id="275" translate="yes">
				<segment state="initial">
					<source>Gamepad/Controller</source>
					<target>Gamepad/Controller</target>
				</segment>
			</unit>
			<unit id="276" translate="yes">
				<segment state="initial">
					<source>The gamepad/controller is a highly specialized device typically dedicated to playing games.</source>
					<target>The gamepad/controller is a highly specialized device typically dedicated to playing games.</target>
				</segment>
			</unit>
			<unit id="277" translate="yes">
				<segment state="initial">
					<source>However, it is also used for to emulate basic keyboard input and provides a UI navigation experience very similar to the keyboard.</source>
					<target>However, it is also used for to emulate basic keyboard input and provides a UI navigation experience very similar to the keyboard.</target>
				</segment>
			</unit>
			<unit id="278" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="279" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="280" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="281" translate="yes">
				<segment state="initial">
					<source>Xbox</source>
					<target>Xbox</target>
				</segment>
			</unit>
			<unit id="282" translate="yes">
				<segment state="initial">
					<source>controller</source>
					<target>controller</target>
				</segment>
			</unit>
			<unit id="283" translate="yes">
				<segment state="initial">
					<source>Typical usage Touchpads typically support a set of touch gestures that provide support similar to touch for direct manipulation of objects and UI.</source>
					<target>Typical usage Touchpads typically support a set of touch gestures that provide support similar to touch for direct manipulation of objects and UI.</target>
				</segment>
			</unit>
			<unit id="284" translate="yes">
				<segment state="initial">
					<source>Because of this convergence of interaction experiences supported by touchpads, we recommend also providing mouse-style UI commands or affordances rather than relying solely on support for touch input.</source>
					<target>Because of this convergence of interaction experiences supported by touchpads, we recommend also providing mouse-style UI commands or affordances rather than relying solely on support for touch input.</target>
				</segment>
			</unit>
			<unit id="285" translate="yes">
				<segment state="initial">
					<source>Provide touchpad-specific UI commands, or affordances, to support these interactions.</source>
					<target>Provide touchpad-specific UI commands, or affordances, to support these interactions.</target>
				</segment>
			</unit>
			<unit id="286" translate="yes">
				<segment state="initial">
					<source>You should provide mouse-specific UI commands, or affordances, to support these interactions.</source>
					<target>You should provide mouse-specific UI commands, or affordances, to support these interactions.</target>
				</segment>
			</unit>
			<unit id="287" translate="yes">
				<segment state="initial">
					<source>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</source>
					<target>For example, use previous and next (or + and -) buttons to let users flip through pages of content, or rotate, resize, and zoom objects.</target>
				</segment>
			</unit>
			<unit id="288" translate="yes">
				<segment state="initial">
					<source>Multiple inputs</source>
					<target>Multiple inputs</target>
				</segment>
			</unit>
			<unit id="289" translate="yes">
				<segment state="initial">
					<source>Accommodating as many users and devices as possible and designing your apps to work with as many input types (gesture, speech, touch, touchpad, mouse, and keyboard) as possible maximizes flexibility, usability, and accessibility.</source>
					<target>Accommodating as many users and devices as possible and designing your apps to work with as many input types (gesture, speech, touch, touchpad, mouse, and keyboard) as possible maximizes flexibility, usability, and accessibility.</target>
				</segment>
			</unit>
			<unit id="290" translate="yes">
				<segment state="initial">
					<source>Device support</source>
					<target>Device support</target>
				</segment>
			</unit>
			<unit id="291" translate="yes">
				<segment state="initial">
					<source>Phones and phablets</source>
					<target>Phones and phablets</target>
				</segment>
			</unit>
			<unit id="292" translate="yes">
				<segment state="initial">
					<source>Tablet</source>
					<target>Tablet</target>
				</segment>
			</unit>
			<unit id="293" translate="yes">
				<segment state="initial">
					<source>PCs and laptops</source>
					<target>PCs and laptops</target>
				</segment>
			</unit>
			<unit id="294" translate="yes">
				<segment state="initial">
					<source>Surface Hub</source>
					<target>Surface Hub</target>
				</segment>
			</unit>
			<unit id="295" translate="yes">
				<segment state="initial">
					<source>IoT</source>
					<target>IoT</target>
				</segment>
			</unit>
			<unit id="296" translate="yes">
				<segment state="initial">
					<source>Xbox</source>
					<target>Xbox</target>
				</segment>
			</unit>
			<unit id="297" translate="yes">
				<segment state="initial">
					<source>HoloLens</source>
					<target>HoloLens</target>
				</segment>
			</unit>
			<unit id="298" translate="yes">
				<segment state="initial">
					<source>multiple inputs</source>
					<target>multiple inputs</target>
				</segment>
			</unit>
			<unit id="299" translate="yes">
				<segment state="initial">
					<source>Typical usage Just as people use a combination of voice and gesture when communicating with each other, multiple types and modes of input can also be useful when interacting with an app.</source>
					<target>Typical usage Just as people use a combination of voice and gesture when communicating with each other, multiple types and modes of input can also be useful when interacting with an app.</target>
				</segment>
			</unit>
			<unit id="300" translate="yes">
				<segment state="initial">
					<source>However, these combined interactions need to be as intuitive and natural as possible as they can also create a very confusing experience.</source>
					<target>However, these combined interactions need to be as intuitive and natural as possible as they can also create a very confusing experience.</target>
				</segment>
			</unit>
			<unit id="301" translate="yes">
				<segment state="initial">
					<source>\[This article contains information that is specific to UWP apps and Windows 10.</source>
					<target>\[This article contains information that is specific to UWP apps and Windows 10.</target>
				</segment>
			</unit>
			<unit id="302" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://go.microsoft.com/fwlink/p/?linkid=258743)</data>
				</originalData>
				<segment state="initial">
					<source>For Windows 8.1 guidance, please download the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Windows 8.1 guidelines PDF</pc>.\]</source>
					<target>For Windows 8.1 guidance, please download the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Windows 8.1 guidelines PDF</pc>.\]</target>
				</segment>
			</unit>
		</group>
	</file>
</xliff>
<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0" srcLang="en-US" trgLang="de-de" version="2.0" xml:space="preserve" xmlns="urn:oasis:names:tc:xliff:document:2.0">
	<file id="1">
		<mda:metadata>
			<mda:metaGroup>
				<mda:meta type="tool-id">mdxliff</mda:meta>
				<mda:meta type="tool-name">mdxliff</mda:meta>
				<mda:meta type="tool-version">1.0-10daaac</mda:meta>
				<mda:meta type="tool-company">Microsoft</mda:meta>
			</mda:metaGroup>
		<mda:metaGroup><mda:meta type="olfilehash">27ec64d42de952080eb477c073ab7f3a0f01293c</mda:meta><mda:meta type="olfilepath">wdg-cpub-test\ndolci2\input-and-devices\launch-a-foreground-app-with-voice-commands-in-cortana.md</mda:meta><mda:meta type="oltranslationpriority"></mda:meta><mda:meta type="oltranslationtype">Human Translation</mda:meta><mda:meta type="olskeletonhash">f9550f663e98dd6f4da8b8e7aa95cab4e59b5ccb</mda:meta><mda:meta type="olxliffhash">d146bdfbb5935d42f6986f217a8b8a44641f61ab</mda:meta></mda:metaGroup></mda:metadata>
		<group id="content">
			<unit id="101" translate="yes">
				<segment state="initial">
					<source>In addition to using voice commands within Cortana to access system features, you can also use voice commands through Cortana to launch a foreground app and specify an action or command to execute within the app.</source>
				</segment>
			</unit>
			<unit id="102" translate="yes">
				<segment state="initial">
					<source>Launch a foreground app with voice commands in Cortana</source>
				</segment>
			</unit>
			<unit id="103" translate="yes">
				<segment state="initial">
					<source>Launch a foreground app with voice commands in Cortana</source>
				</segment>
			</unit>
			<unit id="104" translate="yes">
				<segment state="initial">
					<source>\[ Updated for UWP apps on Windows 10.</source>
				</segment>
			</unit>
			<unit id="105" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](http://go.microsoft.com/fwlink/p/?linkid=619132)</data>
				</originalData>
				<segment state="initial">
					<source>For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</source>
				</segment>
			</unit>
			<unit id="106" translate="yes">
				<segment state="initial">
					<source>Important APIs</source>
				</segment>
			</unit>
			<unit id="107" translate="yes">
				<segment state="initial">
					<source>Windows.ApplicationModel.VoiceCommands</source>
				</segment>
			</unit>
			<unit id="108" translate="yes">
				<segment state="initial">
					<source>VCD elements and attributes v1.2</source>
				</segment>
			</unit>
			<unit id="109" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>In addition to using voice commands within <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc> to access system features, you can also use voice commands through <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Cortana</pc> to launch a foreground app and specify an action or command to execute within the app.</source>
				</segment>
			</unit>
			<unit id="110" translate="yes">
				<segment state="initial">
					<source>Note</source>
				</segment>
			</unit>
			<unit id="111" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>A voice command is a single utterance with a specific intent, defined in a Voice Command Definition (VCD) file, directed at an installed app through <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc>.</source>
				</segment>
			</unit>
			<unit id="112" translate="yes">
				<segment state="initial">
					<source>A voice command definition can vary in complexity.</source>
				</segment>
			</unit>
			<unit id="113" translate="yes">
				<segment state="initial">
					<source>It can support anything from a single, constrained utterance to a collection of more flexible, natural language utterances, all denoting the same intent.</source>
				</segment>
			</unit>
			<unit id="114" translate="yes">
				<segment state="initial">
					<source>A VCD file defines one or more voice commands, each with a unique intent.</source>
				</segment>
			</unit>
			<unit id="115" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The target app can be launched in the foreground (the app takes focus) or activated in the background (<pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc> retains focus but provides results from the app), depending on the complexity of the interaction.</source>
				</segment>
			</unit>
			<unit id="116" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>For example, voice commands that require additional context or user input (such as sending a message to a specific contact) are best handled in a foreground app, while basic commands can be handled in <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc> through a background app.</source>
				</segment>
			</unit>
			<unit id="117" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>We demonstrate these features here with a trip planning and management app named <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Adventure Works</pc>.</source>
				</segment>
			</unit>
			<unit id="118" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>To create a new <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Adventure Works</pc> trip without <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Cortana</pc>, a user would launch the app and navigate to the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">New trip</pc> page.</source>
				</segment>
			</unit>
			<unit id="119" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>To view an existing trip, a user would launch the app, navigate to the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Upcoming trips</pc> page, and select the trip.</source>
				</segment>
			</unit>
			<unit id="120" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Using voice commands through <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc>, the user can instead just say, "Adventure Works add a trip" or "Add a trip on Adventure Works" to launch the app and navigate to the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">New trip</pc> page.</source>
				</segment>
			</unit>
			<unit id="121" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>In turn, saying "Adventure Works, show my trip to London" will launch the app and navigate to the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Trip</pc> detail page, shown here.</source>
				</segment>
			</unit>
			<unit id="122" translate="yes">
				<segment state="initial">
					<source>cortana launching foreground app</source>
				</segment>
			</unit>
			<unit id="123" translate="yes">
				<segment state="initial">
					<source>These are the basic steps to add voice-command functionality and integrate Cortana with your app using speech or keyboard input:</source>
				</segment>
			</unit>
			<unit id="124" translate="yes">
				<segment state="initial">
					<source>Create a VCD file.</source>
				</segment>
			</unit>
			<unit id="125" translate="yes">
				<segment state="initial">
					<source>This is an XML document that defines all the spoken commands that the user can say to initiate actions or invoke commands when activating your app.</source>
				</segment>
			</unit>
			<unit id="126" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn706593)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>See <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">VCD elements and attributes v1.2</pc></pc>.</source>
				</segment>
			</unit>
			<unit id="127" translate="yes">
				<segment state="initial">
					<source>Register the command sets in the VCD file when the app is launched.</source>
				</segment>
			</unit>
			<unit id="128" translate="yes">
				<segment state="initial">
					<source>Handle the activation-by-voice-command, navigation within the app, and execution of the command.</source>
				</segment>
			</unit>
			<unit id="129" translate="yes">
				<segment state="initial">
					<source>**Prerequisites:  **</source>
				</segment>
			</unit>
			<unit id="130" translate="yes">
				<segment state="initial">
					<source>If you're new to developing Universal Windows Platform (UWP) apps, have a look through these topics to get familiar with the technologies discussed here.</source>
				</segment>
			</unit>
			<unit id="131" translate="yes">
				<segment state="initial">
					<source>Create your first app</source>
				</segment>
			</unit>
			<unit id="132" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/mt185584)</data>
				</originalData>
				<segment state="initial">
					<source>Learn about events with <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Events and routed events overview</pc></source>
				</segment>
			</unit>
			<unit id="133" translate="yes">
				<segment state="initial">
					<source>**User experience guidelines:  **</source>
				</segment>
			</unit>
			<unit id="134" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn974233)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn596121)</data>
				</originalData>
				<segment state="initial">
					<source>See <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana design guidelines</pc> for info about how to integrate your app with <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Cortana</pc> and <pc dataRefEnd="id6" dataRefStart="id5" id="p3">Speech design guidelines</pc> for helpful tips on designing a useful and engaging speech-enabled app.</source>
				</segment>
			</unit>
			<unit id="135" translate="yes">
				<segment state="initial">
					<source>Create a VCD file</source>
				</segment>
			</unit>
			<unit id="136" translate="yes">
				<originalData>
					<data id="id1">&amp;gt;</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
				</originalData>
				<segment state="initial">
					<source>In Microsoft Visual Studio, right-click the project name, select Add-<ph dataRef="id1" id="ph1" />New Item, and then select <pc dataRefEnd="id3" dataRefStart="id2" id="p1">XML File</pc>.</source>
				</segment>
			</unit>
			<unit id="137" translate="yes">
				<segment state="initial">
					<source>Type a name for the VCD file.</source>
				</segment>
			</unit>
			<unit id="138" translate="yes">
				<segment state="initial">
					<source>For example, "AdventureWorksCommands.xml".</source>
				</segment>
			</unit>
			<unit id="139" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Select <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Add</pc>.</source>
				</segment>
			</unit>
			<unit id="140" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>In <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Solution Explorer</pc>, select the VCD file.</source>
				</segment>
			</unit>
			<unit id="141" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
				</originalData>
				<segment state="initial">
					<source>In the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Properties</pc> window, set <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Build action</pc> to <pc dataRefEnd="id6" dataRefStart="id5" id="p3">Content</pc>, and then set <pc dataRefEnd="id8" dataRefStart="id7" id="p4">Copy to output directory</pc> to <pc dataRefEnd="id10" dataRefStart="id9" id="p5">Copy if newer</pc>.</source>
				</segment>
			</unit>
			<unit id="142" translate="yes">
				<segment state="initial">
					<source>Edit the VCD file</source>
				</segment>
			</unit>
			<unit id="143" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>For each language supported by your app, create a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CommandSet</pc> of voice commands that your app can handle.</source>
				</segment>
			</unit>
			<unit id="144" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Each <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Command</pc> declared in a VCD file must include this information:</source>
				</segment>
			</unit>
			<unit id="145" translate="yes">
				<segment state="initial">
					<source>A command Name used by the application to identify the voice command at runtime.</source>
				</segment>
			</unit>
			<unit id="146" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>An <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Example</pc> element that contains a phrase describing how a user can invoke the command.</source>
				</segment>
			</unit>
			<unit id="147" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Cortana</pc> shows this example when the user says "What can I say?", "Help", or they tap <pc dataRefEnd="id4" dataRefStart="id3" id="p2">See more</pc>.</source>
				</segment>
			</unit>
			<unit id="148" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>A <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ListenFor</pc> element that contains the words or phrases that your app recognizes to initiate a command.</source>
				</segment>
			</unit>
			<unit id="149" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Each command needs to have at least one <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ListenFor</pc> element.</source>
				</segment>
			</unit>
			<unit id="150" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>A <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Feedback</pc> element that contains the text for <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Cortana</pc> to display and speak as the application is launched.</source>
				</segment>
			</unit>
			<unit id="151" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>A <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Navigate</pc> element to indicate that the voice command is to launch the app in the foreground.</source>
				</segment>
			</unit>
			<unit id="152" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Specify a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">VoiceCommandService</pc> element if the voice command launches the app in the background instead.</source>
				</segment>
			</unit>
			<unit id="153" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](launch-a-background-app-with-voice-commands-in-cortana.md)</data>
				</originalData>
				<segment state="initial">
					<source>For more details, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Launch a background app with voice commands in Cortana</pc>.</source>
				</segment>
			</unit>
			<unit id="154" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn706593)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>For more detail, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">VCD elements and attributes v1.2</pc></pc> reference.</source>
				</segment>
			</unit>
			<unit id="155" translate="yes">
				<segment state="initial">
					<source>You can specify multiple language versions for the commands used to activate your app and execute a command.</source>
				</segment>
			</unit>
			<unit id="156" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>You can create multiple <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CommandSet</pc> elements, each with a different <pc dataRefEnd="id4" dataRefStart="id3" id="p2">xml:lang</pc> attribute to allow your app to be used in different markets.</source>
				</segment>
			</unit>
			<unit id="157" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>For example, an app for the United States might have a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CommandSet</pc> for English and a <pc dataRefEnd="id4" dataRefStart="id3" id="p2">CommandSet</pc> for Spanish.</source>
				</segment>
			</unit>
			<unit id="158" translate="yes">
				<segment state="initial">
					<source>Caution</source>
				</segment>
			</unit>
			<unit id="159" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>To activate an app and initiate an action using a voice command, the app must register a VCD file that contains a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CommandSet</pc> with a language that matches the speech language that the user selected on their device.</source>
				</segment>
			</unit>
			<unit id="160" translate="yes">
				<originalData>
					<data id="id1">&amp;gt;</data>
					<data id="id2">&amp;gt;</data>
					<data id="id3">&amp;gt;</data>
				</originalData>
				<segment state="initial">
					<source>This language is set by the user on the device Settings <ph dataRef="id1" id="ph1" /> System <ph dataRef="id2" id="ph2" /> Speech <ph dataRef="id3" id="ph3" /> Speech Language screen.</source>
				</segment>
			</unit>
			<unit id="161" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Here's a VCD file that defines a voice command for the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Adventure Works</pc> app.</source>
				</segment>
			</unit>
			<unit id="162" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
					<data id="id11">**</data>
					<data id="id12">**</data>
					<data id="id13">**</data>
					<data id="id14">**</data>
				</originalData>
				<segment state="initial">
					<source>For this example, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CommandPrefix</pc> is set to "Adventure Works", <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Command</pc>, identified by Name (" showTripToDestination"), specifies both what the user can say and what feedback is provided by Cortana, <pc dataRefEnd="id6" dataRefStart="id5" id="p3">ListenFor</pc> specifies the text that can be recognized (with a reference to a <pc dataRefEnd="id8" dataRefStart="id7" id="p4">PhraseList</pc> element that constrains the recognized destinations), <pc dataRefEnd="id10" dataRefStart="id9" id="p5">Navigate</pc> indicates that the voice command is handled by launching the app in the foreground, and <pc dataRefEnd="id12" dataRefStart="id11" id="p6">Feedback</pc> specifies what the user will hear when <pc dataRefEnd="id14" dataRefStart="id13" id="p7">Cortana</pc> launches the app.</source>
				</segment>
			</unit>
			<unit id="163" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">ListenFor</pc> elements cannot be programmatically modified.</source>
				</segment>
			</unit>
			<unit id="164" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>However, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">PhraseList</pc> elements associated with <pc dataRefEnd="id4" dataRefStart="id3" id="p2">ListenFor</pc> elements can be programmatically modified.</source>
				</segment>
			</unit>
			<unit id="165" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Applications should modify the content of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">PhraseList</pc> at runtime based on the data set generated as the user uses the app.</source>
				</segment>
			</unit>
			<unit id="166" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn747872)</data>
				</originalData>
				<segment state="initial">
					<source>See <pc dataRefEnd="id2" dataRefStart="id1" id="p1">How to dynamically modify VCD phrase lists</pc>.</source>
				</segment>
			</unit>
			<unit id="167" translate="yes">
				<segment state="initial">
					<source>Install the VCD commands</source>
				</segment>
			</unit>
			<unit id="168" translate="yes">
				<segment state="initial">
					<source>Your app must run once to install the command sets in the VCD.</source>
				</segment>
			</unit>
			<unit id="169" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn708205)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/br242335)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>When your app is activated, call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">InstallCommandDefinitionsFromStorageFileAsync</pc></pc> in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">OnLaunched</pc></pc> handler to register the commands that the system should listen for.</source>
				</segment>
			</unit>
			<unit id="170" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  If a device backup occurs and your app reinstalls automatically, voice command data is not preserved.</source>
				</segment>
			</unit>
			<unit id="171" translate="yes">
				<segment state="initial">
					<source>To ensure the voice command data for your app stays intact, consider initializing your VCD file each time your app launches or activates, or store a setting that indicates if the VCD is currently installed and check the setting each time your app launches or activates.</source>
				</segment>
			</unit>
			<unit id="172" translate="yes">
				<segment state="initial">
					<source>Here's an example that shows how to install the commands specified by a VCD file (vcd.xml).</source>
				</segment>
			</unit>
			<unit id="173" translate="yes">
				<segment state="initial">
					<source>Handle activation and execute voice commands</source>
				</segment>
			</unit>
			<unit id="174" translate="yes">
				<segment state="initial">
					<source>Once your app has been launched and the voice command sets installed, specify how your app responds to subsequent voice command activations.</source>
				</segment>
			</unit>
			<unit id="175" translate="yes">
				<segment state="initial">
					<source>For example, your app might navigate to a specific page of content, display a map or other navigation utility, or speak a confirmation or status.</source>
				</segment>
			</unit>
			<unit id="176" translate="yes">
				<segment state="initial">
					<source>You need to:</source>
				</segment>
			</unit>
			<unit id="177" translate="yes">
				<segment state="initial">
					<source>Confirm that your app was activated by a voice command.</source>
				</segment>
			</unit>
			<unit id="178" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/br242330)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/br224727)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">[</data>
					<data id="id10">](https://msdn.microsoft.com/library/windows/apps/br224728)</data>
					<data id="id11">**</data>
					<data id="id12">**</data>
					<data id="id13">[</data>
					<data id="id14">](https://msdn.microsoft.com/library/windows/apps/br224693)</data>
					<data id="id15">**</data>
					<data id="id16">**</data>
				</originalData>
				<segment state="initial">
					<source>Override the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Application.OnActivated</pc></pc> event and check whether <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IActivatedEventArgs</pc></pc>.<pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">Kind</pc></pc> is <pc dataRefEnd="id14" dataRefStart="id13" id="p7"><pc dataRefEnd="id16" dataRefStart="id15" id="p8">VoiceCommand</pc></pc>.</source>
				</segment>
			</unit>
			<unit id="179" translate="yes">
				<segment state="initial">
					<source>Determine the name of the command and what was spoken.</source>
				</segment>
			</unit>
			<unit id="180" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn609755)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/br224727)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">[</data>
					<data id="id10">](https://msdn.microsoft.com/library/windows/apps/dn609758)</data>
					<data id="id11">**</data>
					<data id="id12">**</data>
					<data id="id13">[</data>
					<data id="id14">](https://msdn.microsoft.com/library/windows/apps/dn631432)</data>
					<data id="id15">**</data>
					<data id="id16">**</data>
				</originalData>
				<segment state="initial">
					<source>Get a reference to a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">VoiceCommandActivatedEventArgs</pc></pc> object from the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IActivatedEventArgs</pc></pc> and query the <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">Result</pc></pc> property for a <pc dataRefEnd="id14" dataRefStart="id13" id="p7"><pc dataRefEnd="id16" dataRefStart="id15" id="p8">SpeechRecognitionResult</pc></pc> object.</source>
				</segment>
			</unit>
			<unit id="181" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631441)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn631443)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>To determine what the user said, check the value of <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Text</pc></pc> or the semantic properties of the recognized phrase in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SpeechRecognitionSemanticInterpretation</pc></pc> dictionary.</source>
				</segment>
			</unit>
			<unit id="182" translate="yes">
				<segment state="initial">
					<source>Take the appropriate action in your app, typically navigating to the relevant page.</source>
				</segment>
			</unit>
			<unit id="183" translate="yes">
				<segment state="initial">
					<source>For this example, we refer back to the VCD in Step 3: Edit the VCD file.</source>
				</segment>
			</unit>
			<unit id="184" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631438)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Once we get the speech-recognition result for the voice command, we get the command name from the first value in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">RulePath</pc></pc> array.</source>
				</segment>
			</unit>
			<unit id="185" translate="yes">
				<segment state="initial">
					<source>As the VCD file defined more than one possible voice command, we need to compare the value against the command names in the VCD and take the appropriate action.</source>
				</segment>
			</unit>
			<unit id="186" translate="yes">
				<segment state="initial">
					<source>The most common action an application can take is to navigate to a page with content relevant to the context of the voice command.</source>
				</segment>
			</unit>
			<unit id="187" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>For this example, we navigate to a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">TripPage</pc> page and pass in the value of the voice command, how the command was input, and the recognized "destination" phrase (if applicable).</source>
				</segment>
			</unit>
			<unit id="188" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631432)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Alternatively, the app could send a navigation parameter to the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionResult</pc></pc> when navigating to the page.</source>
				</segment>
			</unit>
			<unit id="189" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631445)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>You can find out whether the voice command that launched your app was actually spoken, or whether it was typed in as text, from the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionSemanticInterpretation.Properties</pc></pc> dictionary using the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">commandMode</pc> key.</source>
				</segment>
			</unit>
			<unit id="190" translate="yes">
				<segment state="initial">
					<source>The value of that key will be either "voice" or "text".</source>
				</segment>
			</unit>
			<unit id="191" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn278951)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>If the value of the key is "voice", consider using speech synthesis (<pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Windows.Media.SpeechSynthesis</pc></pc>) to provide the user with spoken feedback.</source>
				</segment>
			</unit>
			<unit id="192" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631445)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
				</originalData>
				<segment state="initial">
					<source>Use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionSemanticInterpretation.Properties</pc></pc> to find out the content spoken in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">PhraseList</pc> or <pc dataRefEnd="id8" dataRefStart="id7" id="p4">PhraseTopic</pc> constraints of a <pc dataRefEnd="id10" dataRefStart="id9" id="p5">ListenFor</pc> element.</source>
				</segment>
			</unit>
			<unit id="193" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>The dictionary key is the value of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Label</pc> attribute of the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">PhraseList</pc> or <pc dataRefEnd="id6" dataRefStart="id5" id="p3">PhraseTopic</pc> element.</source>
				</segment>
			</unit>
			<unit id="194" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Here, we show how to access the value of <pc dataRefEnd="id2" dataRefStart="id1" id="p1">{destination}</pc> phrase.</source>
				</segment>
			</unit>
			<unit id="195" translate="yes">
				<segment state="initial">
					<source>Related articles</source>
				</segment>
			</unit>
			<unit id="196" translate="yes">
				<segment state="initial">
					<source>Developers</source>
				</segment>
			</unit>
			<unit id="197" translate="yes">
				<segment state="initial">
					<source>Cortana interactions</source>
				</segment>
			</unit>
			<unit id="198" translate="yes">
				<segment state="initial">
					<source>Define custom recognition constraints</source>
				</segment>
			</unit>
			<unit id="199" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn706593)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">
</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">VCD elements and attributes v1.2</pc></pc><ph dataRef="id5" id="ph1" /><pc dataRefEnd="id7" dataRefStart="id6" id="p3">Designers</pc></source>
				</segment>
			</unit>
			<unit id="200" translate="yes">
				<segment state="initial">
					<source>Cortana design guidelines</source>
				</segment>
			</unit>
			<unit id="201" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn596121)</data>
					<data id="id3">
</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech design guidelines</pc><ph dataRef="id3" id="ph1" /><pc dataRefEnd="id5" dataRefStart="id4" id="p2">Samples</pc></source>
				</segment>
			</unit>
			<unit id="202" translate="yes">
				<segment state="initial">
					<source>Cortana voice command sample</source>
				</segment>
			</unit>
		</group>
	</file>
</xliff>
<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0" srcLang="en-US" trgLang="de-de" version="2.0" xml:space="preserve" xmlns="urn:oasis:names:tc:xliff:document:2.0">
	<file id="1">
		<mda:metadata>
			<mda:metaGroup>
				<mda:meta type="tool-id">mdxliff</mda:meta>
				<mda:meta type="tool-name">mdxliff</mda:meta>
				<mda:meta type="tool-version">1.0-10daaac</mda:meta>
				<mda:meta type="tool-company">Microsoft</mda:meta>
			</mda:metaGroup>
		<mda:metaGroup><mda:meta type="olfilehash">5127cd2ecd4010c15cedffb6ced9dc7604a5d3ed</mda:meta><mda:meta type="olfilepath">wdg-cpub-test\ndolci2\input-and-devices\enable-continuous-dictation.md</mda:meta><mda:meta type="oltranslationpriority"></mda:meta><mda:meta type="oltranslationtype">Human Translation</mda:meta><mda:meta type="olskeletonhash">66f5ffdd4757c14c22a1a5a23573a9cf7bdc0f82</mda:meta><mda:meta type="olxliffhash">c88507cc4f6b6b6edca987f92c10b7ffca5e9b31</mda:meta></mda:metaGroup></mda:metadata>
		<group id="content">
			<unit id="101" translate="yes">
				<segment state="initial">
					<source>Learn how to capture and recognize long-form, continuous dictation speech input.</source>
				</segment>
			</unit>
			<unit id="102" translate="yes">
				<segment state="initial">
					<source>Enable continuous dictation</source>
				</segment>
			</unit>
			<unit id="103" translate="yes">
				<segment state="initial">
					<source>Continuous dictation</source>
				</segment>
			</unit>
			<unit id="104" translate="yes">
				<segment state="initial">
					<source>\[ Updated for UWP apps on Windows 10.</source>
				</segment>
			</unit>
			<unit id="105" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](http://go.microsoft.com/fwlink/p/?linkid=619132)</data>
				</originalData>
				<segment state="initial">
					<source>For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</source>
				</segment>
			</unit>
			<unit id="106" translate="yes">
				<segment state="initial">
					<source>Learn how to capture and recognize long-form, continuous dictation speech input.</source>
				</segment>
			</unit>
			<unit id="107" translate="yes">
				<segment state="initial">
					<source>Important APIs</source>
				</segment>
			</unit>
			<unit id="108" translate="yes">
				<segment state="initial">
					<source>SpeechContinuousRecognitionSession</source>
				</segment>
			</unit>
			<unit id="109" translate="yes">
				<segment state="initial">
					<source>ContinuousRecognitionSession</source>
				</segment>
			</unit>
			<unit id="110" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](speech-recognition.md)</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn653244)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">[</data>
					<data id="id8">](https://msdn.microsoft.com/library/windows/apps/dn653245)</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
					<data id="id11">[</data>
					<data id="id12">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
					<data id="id13">**</data>
					<data id="id14">**</data>
				</originalData>
				<segment state="initial">
					<source>In <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech recognition</pc>, you learned how to capture and recognize relatively short speech input using the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">RecognizeAsync</pc></pc> or <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">RecognizeWithUIAsync</pc></pc> methods of a <pc dataRefEnd="id12" dataRefStart="id11" id="p6"><pc dataRefEnd="id14" dataRefStart="id13" id="p7">SpeechRecognizer</pc></pc> object, for example, when composing a short message service (SMS) message or when asking a question.</source>
				</segment>
			</unit>
			<unit id="111" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913913)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">[</data>
					<data id="id10">](https://msdn.microsoft.com/library/windows/apps/dn913896)</data>
					<data id="id11">**</data>
					<data id="id12">**</data>
				</originalData>
				<segment state="initial">
					<source>For longer, continuous speech recognition sessions, such as dictation or email, use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ContinuousRecognitionSession</pc></pc> property of a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SpeechRecognizer</pc></pc> to obtain a <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">SpeechContinuousRecognitionSession</pc></pc> object.</source>
				</segment>
			</unit>
			<unit id="112" translate="yes">
				<segment state="initial">
					<source>Set up</source>
				</segment>
			</unit>
			<unit id="113" translate="yes">
				<segment state="initial">
					<source>Your app needs a few objects to manage a continuous dictation session:</source>
				</segment>
			</unit>
			<unit id="114" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>An instance of a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognizer</pc></pc> object.</source>
				</segment>
			</unit>
			<unit id="115" translate="yes">
				<segment state="initial">
					<source>A reference to a UI dispatcher to update the UI during dictation.</source>
				</segment>
			</unit>
			<unit id="116" translate="yes">
				<segment state="initial">
					<source>A way to track the accumulated words spoken by the user.</source>
				</segment>
			</unit>
			<unit id="117" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Here, we declare a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognizer</pc></pc> instance as a private field of the code-behind class.</source>
				</segment>
			</unit>
			<unit id="118" translate="yes">
				<segment state="initial">
					<source>Your app needs to store a reference elsewhere if you want continuous dictation to persist beyond a single Extensible Application Markup Language (XAML) page.</source>
				</segment>
			</unit>
			<unit id="119" translate="yes">
				<segment state="initial">
					<source>During dictation, the recognizer raises events from a background thread.</source>
				</segment>
			</unit>
			<unit id="120" translate="yes">
				<segment state="initial">
					<source>Because a background thread cannot directly update the UI in XAML, your app must use a dispatcher to update the UI in response to recognition events.</source>
				</segment>
			</unit>
			<unit id="121" translate="yes">
				<segment state="initial">
					<source>Here, we declare a private field that will be initialized later with the UI dispatcher.</source>
				</segment>
			</unit>
			<unit id="122" translate="yes">
				<segment state="initial">
					<source>To track what the user is saying, you need to handle recognition events raised by the speech recognizer.</source>
				</segment>
			</unit>
			<unit id="123" translate="yes">
				<segment state="initial">
					<source>These events provide the recognition results for chunks of user utterances.</source>
				</segment>
			</unit>
			<unit id="124" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/system.text.stringbuilder.aspx)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Here, we use a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">StringBuilder</pc></pc> object to hold all the recognition results obtained during the session.</source>
				</segment>
			</unit>
			<unit id="125" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>New results are appended to the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">StringBuilder</pc> as they are processed.</source>
				</segment>
			</unit>
			<unit id="126" translate="yes">
				<segment state="initial">
					<source>Initialization</source>
				</segment>
			</unit>
			<unit id="127" translate="yes">
				<segment state="initial">
					<source>During the initialization of continuous speech recognition, you must:</source>
				</segment>
			</unit>
			<unit id="128" translate="yes">
				<segment state="initial">
					<source>Fetch the dispatcher for the UI thread if you update the UI of your app in the continuous recognition event handlers.</source>
				</segment>
			</unit>
			<unit id="129" translate="yes">
				<segment state="initial">
					<source>Initialize the speech recognizer.</source>
				</segment>
			</unit>
			<unit id="130" translate="yes">
				<segment state="initial">
					<source>Compile the built-in dictation grammar.</source>
				</segment>
			</unit>
			<unit id="131" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>   Speech recognition requires at least one constraint to define a recognizable vocabulary.</source>
				</segment>
			</unit>
			<unit id="132" translate="yes">
				<segment state="initial">
					<source>If no constraint is specified, a predefined dictation grammar is used.</source>
				</segment>
			</unit>
			<unit id="133" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](speech-recognition.md)</data>
				</originalData>
				<segment state="initial">
					<source>See <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech recognition</pc>.</source>
				</segment>
			</unit>
			<unit id="134" translate="yes">
				<segment state="initial">
					<source>Set up the event listeners for recognition events.</source>
				</segment>
			</unit>
			<unit id="135" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/br227508)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>We initialize speech recognition in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">OnNavigatedTo</pc></pc> page event.</source>
				</segment>
			</unit>
			<unit id="136" translate="yes">
				<segment state="initial">
					<source>Because events raised by the speech recognizer occur on a background thread, create a reference to the dispatcher for updates to the UI thread.</source>
				</segment>
			</unit>
			<unit id="137" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/br227508)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">OnNavigatedTo</pc></pc> is always invoked on the UI thread.</source>
				</segment>
			</unit>
			<unit id="138" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>We then initialize the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognizer</pc></pc> instance.</source>
				</segment>
			</unit>
			<unit id="139" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>We then add and compile the grammar that defines all of the words and phrases that can be recognized by the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognizer</pc></pc>.</source>
				</segment>
			</unit>
			<unit id="140" translate="yes">
				<segment state="initial">
					<source>If you don't specify a grammar explicitly, a predefined dictation grammar is used by default.</source>
				</segment>
			</unit>
			<unit id="141" translate="yes">
				<segment state="initial">
					<source>Typically, the default grammar is best for general dictation.</source>
				</segment>
			</unit>
			<unit id="142" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653240)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Here, we call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">CompileConstraintsAsync</pc></pc> immediately without adding a grammar.</source>
				</segment>
			</unit>
			<unit id="143" translate="yes">
				<segment state="initial">
					<source>Handle recognition events</source>
				</segment>
			</unit>
			<unit id="144" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653244)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn653245)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>Here, you can capture a single, brief utterance or phrase by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">RecognizeAsync</pc></pc> or <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">RecognizeWithUIAsync</pc></pc>.</source>
				</segment>
			</unit>
			<unit id="145" translate="yes">
				<segment state="initial">
					<source>However, we want to capture a longer, continuous recognition session.</source>
				</segment>
			</unit>
			<unit id="146" translate="yes">
				<segment state="initial">
					<source>To do this, we specify event listeners to run in the background as the user speaks and define handlers to build the dictation string.</source>
				</segment>
			</unit>
			<unit id="147" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913913)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn913896)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>We then use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ContinuousRecognitionSession</pc></pc> property of our recognizer to obtain a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SpeechContinuousRecognitionSession</pc></pc> object that provides methods and events for managing a continuous recognition session.</source>
				</segment>
			</unit>
			<unit id="148" translate="yes">
				<segment state="initial">
					<source>Two events in particular are critical:</source>
				</segment>
			</unit>
			<unit id="149" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc>, which occurs when the recognizer has generated some results.</source>
				</segment>
			</unit>
			<unit id="150" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913899)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Completed</pc></pc>, which occurs when the continuous recognition session has ended.</source>
				</segment>
			</unit>
			<unit id="151" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc> event is raised as the user speaks.</source>
				</segment>
			</unit>
			<unit id="152" translate="yes">
				<segment state="initial">
					<source>The recognizer continuously listens to the user and periodically raises an event that passes a chunk of speech input.</source>
				</segment>
			</unit>
			<unit id="153" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913895)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>You must examine the speech input, using the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Result</pc></pc> property of the event argument, and take appropriate action in the event handler, such as appending the text to a StringBuilder object.</source>
				</segment>
			</unit>
			<unit id="154" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631432)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn913895)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>As an instance of <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionResult</pc></pc>, the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Result</pc></pc> property is useful for determining whether you want to accept the speech input:</source>
				</segment>
			</unit>
			<unit id="155" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631440)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Status</pc></pc> indicates whether the recognition was successful.</source>
				</segment>
			</unit>
			<unit id="156" translate="yes">
				<segment state="initial">
					<source>Recognition can fail for a variety of reasons.</source>
				</segment>
			</unit>
			<unit id="157" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631434)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Confidence</pc></pc> indicates the relative confidence that the recognizer understood the correct words.</source>
				</segment>
			</unit>
			<unit id="158" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/br227508)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>Here, we register the handler for the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc> continuous recognition event in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">OnNavigatedTo</pc></pc> page event.</source>
				</segment>
			</unit>
			<unit id="159" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631434)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>We then check the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Confidence</pc></pc> property.</source>
				</segment>
			</unit>
			<unit id="160" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631409)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>If the value of Confidence is <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Medium</pc></pc> or better, we append the text to the StringBuilder.</source>
				</segment>
			</unit>
			<unit id="161" translate="yes">
				<segment state="initial">
					<source>We also update the UI as we collect input.</source>
				</segment>
			</unit>
			<unit id="162" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">ResultGenerated</pc></pc> event is raised on a background thread that cannot update the UI directly.</source>
				</segment>
			</unit>
			<unit id="163" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/hh750317)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>If a handler needs to update the UI (as the \[Speech and TTS sample\] does), you must dispatch the updates to the UI thread through the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">RunAsync</pc></pc> method of the dispatcher.</source>
				</segment>
			</unit>
			<unit id="164" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913899)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>We then handle the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Completed</pc></pc> event, which indicates the end of continuous dictation.</source>
				</segment>
			</unit>
			<unit id="165" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913908)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn913898)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>The session ends when you call the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">StopAsync</pc></pc> or <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CancelAsync</pc></pc> methods (described the next section).</source>
				</segment>
			</unit>
			<unit id="166" translate="yes">
				<segment state="initial">
					<source>The session can also end when an error occurs, or when the user has stopped speaking.</source>
				</segment>
			</unit>
			<unit id="167" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631440)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn631433)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>Check the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Status</pc></pc> property of the event argument to determine why the session ended (<pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SpeechRecognitionResultStatus</pc></pc>).</source>
				</segment>
			</unit>
			<unit id="168" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913899)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/br227508)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>Here, we register the handler for the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Completed</pc></pc> continuous recognition event in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">OnNavigatedTo</pc></pc> page event.</source>
				</segment>
			</unit>
			<unit id="169" translate="yes">
				<segment state="initial">
					<source>The event handler checks the Status property to determine whether the recognition was successful.</source>
				</segment>
			</unit>
			<unit id="170" translate="yes">
				<segment state="initial">
					<source>It also handles the case where the user has stopped speaking.</source>
				</segment>
			</unit>
			<unit id="171" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631433)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Often, a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">TimeoutExceeded</pc></pc> is considered successful recognition as it means the user has finished speaking.</source>
				</segment>
			</unit>
			<unit id="172" translate="yes">
				<segment state="initial">
					<source>You should handle this case in your code for a good experience.</source>
				</segment>
			</unit>
			<unit id="173" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">ResultGenerated</pc></pc> event is raised on a background thread that cannot update the UI directly.</source>
				</segment>
			</unit>
			<unit id="174" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/hh750317)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>If a handler needs to update the UI (as the \[Speech and TTS sample\] does), you must dispatch the updates to the UI thread through the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">RunAsync</pc></pc> method of the dispatcher.</source>
				</segment>
			</unit>
			<unit id="175" translate="yes">
				<segment state="initial">
					<source>Provide ongoing recognition feedback</source>
				</segment>
			</unit>
			<unit id="176" translate="yes">
				<segment state="initial">
					<source>When people converse, they often rely on context to fully understand what is being said.</source>
				</segment>
			</unit>
			<unit id="177" translate="yes">
				<segment state="initial">
					<source>Similarly, the speech recognizer often needs context to provide high-confidence recognition results.</source>
				</segment>
			</unit>
			<unit id="178" translate="yes">
				<segment state="initial">
					<source>For example, by themselves, the words "weight" and "wait" are indistinguishable until more context can be gleaned from surrounding words.</source>
				</segment>
			</unit>
			<unit id="179" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Until the recognizer has some confidence that a word, or words, have been recognized correctly, it will not raise the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc> event.</source>
				</segment>
			</unit>
			<unit id="180" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>This can result in a less than ideal experience for the user as they continue speaking and no results are provided until the recognizer has high enough confidence to raise the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc> event.</source>
				</segment>
			</unit>
			<unit id="181" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913914)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Handle the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">HypothesisGenerated</pc></pc> event to improve this apparent lack of responsiveness.</source>
				</segment>
			</unit>
			<unit id="182" translate="yes">
				<segment state="initial">
					<source>This event is raised whenever the recognizer generates a new set of potential matches for the word being processed.</source>
				</segment>
			</unit>
			<unit id="183" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913911)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The event argument provides an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Hypothesis</pc></pc> property that contains the current matches.</source>
				</segment>
			</unit>
			<unit id="184" translate="yes">
				<segment state="initial">
					<source>Show these to the user as they continue speaking and reassure them that processing is still active.</source>
				</segment>
			</unit>
			<unit id="185" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn913895)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">[</data>
					<data id="id8">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
				</originalData>
				<segment state="initial">
					<source>Once confidence is high and a recognition result has been determined, replace the interim <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Hypothesis</pc> results with the final <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">Result</pc></pc> provided in the <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">ResultGenerated</pc></pc> event.</source>
				</segment>
			</unit>
			<unit id="186" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/br209683)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Here, we append the hypothetical text and an ellipsis ("…") to the current value of the output <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">TextBox</pc></pc>.</source>
				</segment>
			</unit>
			<unit id="187" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The contents of the text box are updated as new hypotheses are generated and until the final results are obtained from the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc> event.</source>
				</segment>
			</unit>
			<unit id="188" translate="yes">
				<segment state="initial">
					<source>Start and stop recognition</source>
				</segment>
			</unit>
			<unit id="189" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913915)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Before starting a recognition session, check the value of the speech recognizer <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">State</pc></pc> property.</source>
				</segment>
			</unit>
			<unit id="190" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653227)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The speech recognizer must be in an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Idle</pc></pc> state.</source>
				</segment>
			</unit>
			<unit id="191" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913901)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn913913)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>After checking the state of the speech recognizer, we start the session by calling the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">StartAsync</pc></pc> method of the speech recognizer's <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">ContinuousRecognitionSession</pc></pc> property.</source>
				</segment>
			</unit>
			<unit id="192" translate="yes">
				<segment state="initial">
					<source>Recognition can be stopped in two ways:</source>
				</segment>
			</unit>
			<unit id="193" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913908)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">StopAsync</pc></pc> lets any pending recognition events complete (<pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">ResultGenerated</pc></pc> continues to be raised until all pending recognition operations are complete).</source>
				</segment>
			</unit>
			<unit id="194" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913898)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">CancelAsync</pc></pc> terminates the recognition session immediately and discards any pending results.</source>
				</segment>
			</unit>
			<unit id="195" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913898)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn913913)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>After checking the state of the speech recognizer, we stop the session by calling the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">CancelAsync</pc></pc> method of the speech recognizer's <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">ContinuousRecognitionSession</pc></pc> property.</source>
				</segment>
			</unit>
			<unit id="196" translate="yes">
				<segment state="initial">
					<source>Note</source>
				</segment>
			</unit>
			<unit id="197" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn913898)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>A <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc> event can occur after a call to <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CancelAsync</pc></pc>.</source>
				</segment>
			</unit>
			<unit id="198" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn913898)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>Because of multithreading, a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc> event might still remain on the stack when <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CancelAsync</pc></pc> is called.</source>
				</segment>
			</unit>
			<unit id="199" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>If so, the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ResultGenerated</pc> event still fires.</source>
				</segment>
			</unit>
			<unit id="200" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>If you set any private fields when canceling the recognition session, always confirm their values in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResultGenerated</pc></pc> handler.</source>
				</segment>
			</unit>
			<unit id="201" translate="yes">
				<segment state="initial">
					<source>For example, don't assume a field is initialized in your handler if you set them to null when you cancel the session.</source>
				</segment>
			</unit>
			<unit id="202" translate="yes">
				<segment state="initial">
					<source>Related articles</source>
				</segment>
			</unit>
			<unit id="203" translate="yes">
				<segment state="initial">
					<source>Speech interactions</source>
				</segment>
			</unit>
			<unit id="204" translate="yes">
				<segment state="initial">
					<source>Samples</source>
				</segment>
			</unit>
			<unit id="205" translate="yes">
				<segment state="initial">
					<source>Speech recognition and speech synthesis sample</source>
				</segment>
			</unit>
		</group>
	</file>
</xliff>
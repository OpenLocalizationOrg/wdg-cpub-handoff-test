<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0" srcLang="en-US" trgLang="it-it" version="2.0" xml:space="preserve" xmlns="urn:oasis:names:tc:xliff:document:2.0">
	<file id="1">
		<mda:metadata>
			<mda:metaGroup>
				<mda:meta type="tool-id">mdxliff</mda:meta>
				<mda:meta type="tool-name">mdxliff</mda:meta>
				<mda:meta type="tool-version">1.0-2eb3c86</mda:meta>
				<mda:meta type="tool-company">Microsoft</mda:meta>
			</mda:metaGroup>
		<mda:metaGroup><mda:meta type="olfilehash">fcea980e063757015756a9f6b533e3fce6858686</mda:meta><mda:meta type="olfilepath">wdg-cpub-test\ndolci2\gaming\adding-audio-to-the-marble-maze-sample.md</mda:meta><mda:meta type="oltranslationpriority"></mda:meta><mda:meta type="oltranslationtype">Human Translation</mda:meta><mda:meta type="olskeletonhash">faa3766f0e8afb2f6216f9f7c4293bd63c02b228</mda:meta><mda:meta type="olxliffhash">26b1c2de5e62f79815b8c5eae45231a4453f7ea0</mda:meta></mda:metaGroup></mda:metadata>
		<group id="content">
			<unit id="101" translate="yes">
				<segment state="initial">
					<source>Adding audio to the Marble Maze sample</source>
					<target>Adding audio to the Marble Maze sample</target>
				</segment>
			</unit>
			<unit id="102" translate="yes">
				<segment state="initial">
					<source>This document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices.</source>
					<target>This document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices.</target>
				</segment>
			</unit>
			<unit id="103" translate="yes">
				<segment state="initial">
					<source>Adding audio to the Marble Maze sample</source>
					<target>Adding audio to the Marble Maze sample</target>
				</segment>
			</unit>
			<unit id="104" translate="yes">
				<segment state="initial">
					<source>\[ Updated for UWP apps on Windows 10.</source>
					<target>\[ Updated for UWP apps on Windows 10.</target>
				</segment>
			</unit>
			<unit id="105" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](http://go.microsoft.com/fwlink/p/?linkid=619132)</data>
				</originalData>
				<segment state="initial">
					<source>For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</source>
					<target>For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</target>
				</segment>
			</unit>
			<unit id="106" translate="yes">
				<segment state="initial">
					<source>This document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices.</source>
					<target>This document describes the key practices to consider when you work with audio and shows how Marble Maze applies these practices.</target>
				</segment>
			</unit>
			<unit id="107" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses Microsoft Media Foundation to load audio resources from file, and XAudio2 to mix and play audio and to apply effects to audio.</source>
					<target>Marble Maze uses Microsoft Media Foundation to load audio resources from file, and XAudio2 to mix and play audio and to apply effects to audio.</target>
				</segment>
			</unit>
			<unit id="108" translate="yes">
				<segment state="initial">
					<source>Marble Maze plays music in the background, and also uses game-play sounds to indicate game events, such as when the marble hits a wall.</source>
					<target>Marble Maze plays music in the background, and also uses game-play sounds to indicate game events, such as when the marble hits a wall.</target>
				</segment>
			</unit>
			<unit id="109" translate="yes">
				<segment state="initial">
					<source>An important part of the implementation is that Marble Maze uses a reverb, or echo, effect to simulate the sound of a marble when it bounces.</source>
					<target>An important part of the implementation is that Marble Maze uses a reverb, or echo, effect to simulate the sound of a marble when it bounces.</target>
				</segment>
			</unit>
			<unit id="110" translate="yes">
				<segment state="initial">
					<source>The reverb effect implementation causes echoes to reach you more quickly and loudly in small rooms; echoes are quieter and reach you more slowly in larger rooms.</source>
					<target>The reverb effect implementation causes echoes to reach you more quickly and loudly in small rooms; echoes are quieter and reach you more slowly in larger rooms.</target>
				</segment>
			</unit>
			<unit id="111" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](http://go.microsoft.com/fwlink/?LinkId=624011)</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>   The sample code that corresponds to this document is found in the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">DirectX Marble Maze game sample</pc>.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>   The sample code that corresponds to this document is found in the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">DirectX Marble Maze game sample</pc>.</target>
				</segment>
			</unit>
			<unit id="112" translate="yes">
				<segment state="initial">
					<source>Here are some of the key points that this document discusses for when you work with audio in your game:</source>
					<target>Here are some of the key points that this document discusses for when you work with audio in your game:</target>
				</segment>
			</unit>
			<unit id="113" translate="yes">
				<segment state="initial">
					<source>Consider using Media Foundation to decode audio assets and XAudio2 to play audio.</source>
					<target>Consider using Media Foundation to decode audio assets and XAudio2 to play audio.</target>
				</segment>
			</unit>
			<unit id="114" translate="yes">
				<segment state="initial">
					<source>However, if you have an existing audio asset-loading mechanism that works in a Universal Windows Platform (UWP) app, you can use it.</source>
					<target>However, if you have an existing audio asset-loading mechanism that works in a Universal Windows Platform (UWP) app, you can use it.</target>
				</segment>
			</unit>
			<unit id="115" translate="yes">
				<segment state="initial">
					<source>An audio graph contains one source voice for each active sound, zero or more submix voices, and one mastering voice.</source>
					<target>An audio graph contains one source voice for each active sound, zero or more submix voices, and one mastering voice.</target>
				</segment>
			</unit>
			<unit id="116" translate="yes">
				<segment state="initial">
					<source>Source voices can feed into submix voices and/or the mastering voice.</source>
					<target>Source voices can feed into submix voices and/or the mastering voice.</target>
				</segment>
			</unit>
			<unit id="117" translate="yes">
				<segment state="initial">
					<source>Submix voices feed into other submix voices or the mastering voice.</source>
					<target>Submix voices feed into other submix voices or the mastering voice.</target>
				</segment>
			</unit>
			<unit id="118" translate="yes">
				<segment state="initial">
					<source>If your background music files are large, consider streaming your music into smaller buffers so that less memory is used.</source>
					<target>If your background music files are large, consider streaming your music into smaller buffers so that less memory is used.</target>
				</segment>
			</unit>
			<unit id="119" translate="yes">
				<segment state="initial">
					<source>If it makes sense to do so, pause audio playback when the app loses focus or visibility, or is suspended.</source>
					<target>If it makes sense to do so, pause audio playback when the app loses focus or visibility, or is suspended.</target>
				</segment>
			</unit>
			<unit id="120" translate="yes">
				<segment state="initial">
					<source>Resume playback when your app regains focus, becomes visible, or is resumed.</source>
					<target>Resume playback when your app regains focus, becomes visible, or is resumed.</target>
				</segment>
			</unit>
			<unit id="121" translate="yes">
				<segment state="initial">
					<source>Set audio categories to reflect the role of each sound.</source>
					<target>Set audio categories to reflect the role of each sound.</target>
				</segment>
			</unit>
			<unit id="122" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>For example, you typically use <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioCategory\_GameMedia</pc> for game background audio and <pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioCategory\_GameEffects</pc> for sound effects.</source>
					<target>For example, you typically use <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioCategory\_GameMedia</pc> for game background audio and <pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioCategory\_GameEffects</pc> for sound effects.</target>
				</segment>
			</unit>
			<unit id="123" translate="yes">
				<segment state="initial">
					<source>Handle device changes, including headphones, by releasing and recreating all audio resources and interfaces.</source>
					<target>Handle device changes, including headphones, by releasing and recreating all audio resources and interfaces.</target>
				</segment>
			</unit>
			<unit id="124" translate="yes">
				<segment state="initial">
					<source>Consider whether to compress audio files when minimizing disk space and streaming costs is a requirement.</source>
					<target>Consider whether to compress audio files when minimizing disk space and streaming costs is a requirement.</target>
				</segment>
			</unit>
			<unit id="125" translate="yes">
				<segment state="initial">
					<source>Otherwise, you can leave audio uncompressed so that it loads faster.</source>
					<target>Otherwise, you can leave audio uncompressed so that it loads faster.</target>
				</segment>
			</unit>
			<unit id="126" translate="yes">
				<segment state="initial">
					<source>Introducing XAudio2 and Microsoft Media Foundation</source>
					<target>Introducing XAudio2 and Microsoft Media Foundation</target>
				</segment>
			</unit>
			<unit id="127" translate="yes">
				<segment state="initial">
					<source>XAudio2 is a low-level audio library for Windows that specifically supports game audio.</source>
					<target>XAudio2 is a low-level audio library for Windows that specifically supports game audio.</target>
				</segment>
			</unit>
			<unit id="128" translate="yes">
				<segment state="initial">
					<source>It provides a digital signal processing (DSP) and audio-graph engine for games.</source>
					<target>It provides a digital signal processing (DSP) and audio-graph engine for games.</target>
				</segment>
			</unit>
			<unit id="129" translate="yes">
				<segment state="initial">
					<source>XAudio2 expands on its predecessors, DirectSound and XAudio, by supporting computing trends such as SIMD floating-point architectures and HD audio.</source>
					<target>XAudio2 expands on its predecessors, DirectSound and XAudio, by supporting computing trends such as SIMD floating-point architectures and HD audio.</target>
				</segment>
			</unit>
			<unit id="130" translate="yes">
				<segment state="initial">
					<source>It also supports the more complex sound processing demands of today’s games.</source>
					<target>It also supports the more complex sound processing demands of today’s games.</target>
				</segment>
			</unit>
			<unit id="131" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415764)</data>
				</originalData>
				<segment state="initial">
					<source>The document <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAudio2 Key Concepts</pc> explains the key concepts for using XAudio2.</source>
					<target>The document <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAudio2 Key Concepts</pc> explains the key concepts for using XAudio2.</target>
				</segment>
			</unit>
			<unit id="132" translate="yes">
				<segment state="initial">
					<source>In brief, the concepts are:</source>
					<target>In brief, the concepts are:</target>
				</segment>
			</unit>
			<unit id="133" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2</pc></pc> interface is the core of the XAudio2 engine.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2</pc></pc> interface is the core of the XAudio2 engine.</target>
				</segment>
			</unit>
			<unit id="134" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses this interface to create voices and to receive notification when the output device changes or fails.</source>
					<target>Marble Maze uses this interface to create voices and to receive notification when the output device changes or fails.</target>
				</segment>
			</unit>
			<unit id="135" translate="yes">
				<segment state="initial">
					<source>A voice processes, adjusts, and plays audio data.</source>
					<target>A voice processes, adjusts, and plays audio data.</target>
				</segment>
			</unit>
			<unit id="136" translate="yes">
				<segment state="initial">
					<source>A source voice is a collection of audio channels (mono, 5.1, and so on) and represents one stream of audio data.</source>
					<target>A source voice is a collection of audio channels (mono, 5.1, and so on) and represents one stream of audio data.</target>
				</segment>
			</unit>
			<unit id="137" translate="yes">
				<segment state="initial">
					<source>In XAudio2, a source voice is where audio processing begins.</source>
					<target>In XAudio2, a source voice is where audio processing begins.</target>
				</segment>
			</unit>
			<unit id="138" translate="yes">
				<segment state="initial">
					<source>Typically, sound data is loaded from an external source, such as a file or a network, and is sent to a source voice.</source>
					<target>Typically, sound data is loaded from an external source, such as a file or a network, and is sent to a source voice.</target>
				</segment>
			</unit>
			<unit id="139" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ms694197)</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze uses <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Media Foundation</pc> to load sound data from files.</source>
					<target>Marble Maze uses <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Media Foundation</pc> to load sound data from files.</target>
				</segment>
			</unit>
			<unit id="140" translate="yes">
				<segment state="initial">
					<source>Media Foundation is introduced later in this document.</source>
					<target>Media Foundation is introduced later in this document.</target>
				</segment>
			</unit>
			<unit id="141" translate="yes">
				<segment state="initial">
					<source>A submix voice processes audio data.</source>
					<target>A submix voice processes audio data.</target>
				</segment>
			</unit>
			<unit id="142" translate="yes">
				<segment state="initial">
					<source>This processing can include changing the audio stream or combining multiple streams into one.</source>
					<target>This processing can include changing the audio stream or combining multiple streams into one.</target>
				</segment>
			</unit>
			<unit id="143" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses submixes to create the reverb effect.</source>
					<target>Marble Maze uses submixes to create the reverb effect.</target>
				</segment>
			</unit>
			<unit id="144" translate="yes">
				<segment state="initial">
					<source>A mastering voice combines data from source and submix voices and sends that data to the audio hardware.</source>
					<target>A mastering voice combines data from source and submix voices and sends that data to the audio hardware.</target>
				</segment>
			</unit>
			<unit id="145" translate="yes">
				<segment state="initial">
					<source>An audio graph contains one source voice for each active sound, zero or more submix voices, and only one mastering voice.</source>
					<target>An audio graph contains one source voice for each active sound, zero or more submix voices, and only one mastering voice.</target>
				</segment>
			</unit>
			<unit id="146" translate="yes">
				<segment state="initial">
					<source>A callback informs client code that some event has occurred in a voice or in an engine object.</source>
					<target>A callback informs client code that some event has occurred in a voice or in an engine object.</target>
				</segment>
			</unit>
			<unit id="147" translate="yes">
				<segment state="initial">
					<source>By using callbacks, you can reuse memory when XAudio2 is finished with a buffer, react when the audio device changes (for example, when you connect or disconnect headphones), and more.</source>
					<target>By using callbacks, you can reuse memory when XAudio2 is finished with a buffer, react when the audio device changes (for example, when you connect or disconnect headphones), and more.</target>
				</segment>
			</unit>
			<unit id="148" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](#phones)</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Handling headphones and device changes section</pc> later in this document explains how Marble Maze uses this mechanism to handle device changes.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Handling headphones and device changes section</pc> later in this document explains how Marble Maze uses this mechanism to handle device changes.</target>
				</segment>
			</unit>
			<unit id="149" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze uses two audio engines (in other words, two <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2</pc></pc> objects) to process audio.</source>
					<target>Marble Maze uses two audio engines (in other words, two <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2</pc></pc> objects) to process audio.</target>
				</segment>
			</unit>
			<unit id="150" translate="yes">
				<segment state="initial">
					<source>One engine processes the background music, and the other engine processes game-play sounds.</source>
					<target>One engine processes the background music, and the other engine processes game-play sounds.</target>
				</segment>
			</unit>
			<unit id="151" translate="yes">
				<segment state="initial">
					<source>Marble Maze must also create one mastering voice for each engine.</source>
					<target>Marble Maze must also create one mastering voice for each engine.</target>
				</segment>
			</unit>
			<unit id="152" translate="yes">
				<segment state="initial">
					<source>Recall that a mastering engine combines audio streams into one stream and sends that stream to the audio hardware.</source>
					<target>Recall that a mastering engine combines audio streams into one stream and sends that stream to the audio hardware.</target>
				</segment>
			</unit>
			<unit id="153" translate="yes">
				<segment state="initial">
					<source>The background music stream, a source voice, outputs data to a mastering voice and to two submix voices.</source>
					<target>The background music stream, a source voice, outputs data to a mastering voice and to two submix voices.</target>
				</segment>
			</unit>
			<unit id="154" translate="yes">
				<segment state="initial">
					<source>The submix voices perform the reverb effect.</source>
					<target>The submix voices perform the reverb effect.</target>
				</segment>
			</unit>
			<unit id="155" translate="yes">
				<segment state="initial">
					<source>Media Foundation is a multimedia library that supports many audio and video formats.</source>
					<target>Media Foundation is a multimedia library that supports many audio and video formats.</target>
				</segment>
			</unit>
			<unit id="156" translate="yes">
				<segment state="initial">
					<source>XAudio2 and Media Foundation complement each other.</source>
					<target>XAudio2 and Media Foundation complement each other.</target>
				</segment>
			</unit>
			<unit id="157" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses Media Foundation to load audio assets from file and uses XAudio2 to play audio.</source>
					<target>Marble Maze uses Media Foundation to load audio assets from file and uses XAudio2 to play audio.</target>
				</segment>
			</unit>
			<unit id="158" translate="yes">
				<segment state="initial">
					<source>You don't have to use Media Foundation to load audio assets.</source>
					<target>You don't have to use Media Foundation to load audio assets.</target>
				</segment>
			</unit>
			<unit id="159" translate="yes">
				<segment state="initial">
					<source>If you have an existing audio asset loading mechanism that works in Universal Windows Platform (UWP) apps, use it.</source>
					<target>If you have an existing audio asset loading mechanism that works in Universal Windows Platform (UWP) apps, use it.</target>
				</segment>
			</unit>
			<unit id="160" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415737)</data>
				</originalData>
				<segment state="initial">
					<source>For more information about XAudio2, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Programming Guide</pc>.</source>
					<target>For more information about XAudio2, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Programming Guide</pc>.</target>
				</segment>
			</unit>
			<unit id="161" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ms694197)</data>
				</originalData>
				<segment state="initial">
					<source>For more information about Media Foundation, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Microsoft Media Foundation</pc>.</source>
					<target>For more information about Media Foundation, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Microsoft Media Foundation</pc>.</target>
				</segment>
			</unit>
			<unit id="162" translate="yes">
				<segment state="initial">
					<source>Initializing audio resources</source>
					<target>Initializing audio resources</target>
				</segment>
			</unit>
			<unit id="163" translate="yes">
				<segment state="initial">
					<source>Marble Mazes uses a Windows Media Audio (.wma) file for the background music, and WAV (.wav) files for game play sounds.</source>
					<target>Marble Mazes uses a Windows Media Audio (.wma) file for the background music, and WAV (.wav) files for game play sounds.</target>
				</segment>
			</unit>
			<unit id="164" translate="yes">
				<segment state="initial">
					<source>These formats are supported by Media Foundation.</source>
					<target>These formats are supported by Media Foundation.</target>
				</segment>
			</unit>
			<unit id="165" translate="yes">
				<segment state="initial">
					<source>Although the .wav file format is natively supported by XAudio2, a game has to parse the file format manually to fill out the appropriate XAudio2 data structures.</source>
					<target>Although the .wav file format is natively supported by XAudio2, a game has to parse the file format manually to fill out the appropriate XAudio2 data structures.</target>
				</segment>
			</unit>
			<unit id="166" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses Media Foundation to more easily work with .wav files.</source>
					<target>Marble Maze uses Media Foundation to more easily work with .wav files.</target>
				</segment>
			</unit>
			<unit id="167" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/dd757927)</data>
				</originalData>
				<segment state="initial">
					<source>For the complete list of the media formats that are supported by Media Foundation, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Supported Media Formats in Media Foundation</pc>.</source>
					<target>For the complete list of the media formats that are supported by Media Foundation, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Supported Media Formats in Media Foundation</pc>.</target>
				</segment>
			</unit>
			<unit id="168" translate="yes">
				<segment state="initial">
					<source>Marble Maze does not use separate design-time and run-time audio formats, and does not use XAudio2 ADPCM compression support.</source>
					<target>Marble Maze does not use separate design-time and run-time audio formats, and does not use XAudio2 ADPCM compression support.</target>
				</segment>
			</unit>
			<unit id="169" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415711)</data>
				</originalData>
				<segment state="initial">
					<source>For more information about ADPCM compression in XAudio2, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ADPCM Overview</pc>.</source>
					<target>For more information about ADPCM compression in XAudio2, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ADPCM Overview</pc>.</target>
				</segment>
			</unit>
			<unit id="170" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method, which is called from <pc dataRefEnd="id4" dataRefStart="id3" id="p2">MarbleMaze::CreateDeviceIndependentResources</pc>, loads the audio streams from file, initializes the XAudio2 engine objects, and creates the source, submix, and mastering voices.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method, which is called from <pc dataRefEnd="id4" dataRefStart="id3" id="p2">MarbleMaze::CreateDeviceIndependentResources</pc>, loads the audio streams from file, initializes the XAudio2 engine objects, and creates the source, submix, and mastering voices.</target>
				</segment>
			</unit>
			<unit id="171" translate="yes">
				<segment state="initial">
					<source>Creating the XAudio2 engines</source>
					<target>Creating the XAudio2 engines</target>
				</segment>
			</unit>
			<unit id="172" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Recall that Marble Maze creates one <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2</pc></pc> object to represent each audio engine that it uses.</source>
					<target>Recall that Marble Maze creates one <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2</pc></pc> object to represent each audio engine that it uses.</target>
				</segment>
			</unit>
			<unit id="173" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419212)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>To create an audio engine, call the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAudio2Create</pc></pc> function.</source>
					<target>To create an audio engine, call the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAudio2Create</pc></pc> function.</target>
				</segment>
			</unit>
			<unit id="174" translate="yes">
				<segment state="initial">
					<source>The following example shows how Marble Maze creates the audio engine that processes background music.</source>
					<target>The following example shows how Marble Maze creates the audio engine that processes background music.</target>
				</segment>
			</unit>
			<unit id="175" translate="yes">
				<segment state="initial">
					<source>Marble Maze performs a similar step to create the audio engine that plays game-play sounds.</source>
					<target>Marble Maze performs a similar step to create the audio engine that plays game-play sounds.</target>
				</segment>
			</unit>
			<unit id="176" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>How to work with the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2</pc></pc> interface in a UWP app differs from a desktop app in two ways.</source>
					<target>How to work with the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2</pc></pc> interface in a UWP app differs from a desktop app in two ways.</target>
				</segment>
			</unit>
			<unit id="177" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ee419212)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>First, you don't have to call <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CoInitializeEx</pc> before you call <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">XAudio2Create</pc></pc>.</source>
					<target>First, you don't have to call <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CoInitializeEx</pc> before you call <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">XAudio2Create</pc></pc>.</target>
				</segment>
			</unit>
			<unit id="178" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>In addition, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IXAudio2</pc> no longer supports device enumeration.</source>
					<target>In addition, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IXAudio2</pc> no longer supports device enumeration.</target>
				</segment>
			</unit>
			<unit id="179" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/apps/hh464977)</data>
				</originalData>
				<segment state="initial">
					<source>For information about how to enumerate audio devices, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Enumerating devices</pc>.</source>
					<target>For information about how to enumerate audio devices, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Enumerating devices</pc>.</target>
				</segment>
			</unit>
			<unit id="180" translate="yes">
				<segment state="initial">
					<source>Creating the mastering voices</source>
					<target>Creating the mastering voices</target>
				</segment>
			</unit>
			<unit id="181" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The following example shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method creates the mastering voice for the background music.</source>
					<target>The following example shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method creates the mastering voice for the background music.</target>
				</segment>
			</unit>
			<unit id="182" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/hh405048)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The call to <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::CreateMasteringVoice</pc></pc> specifies two input channels.</source>
					<target>The call to <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::CreateMasteringVoice</pc></pc> specifies two input channels.</target>
				</segment>
			</unit>
			<unit id="183" translate="yes">
				<segment state="initial">
					<source>This simplifies the logic for the reverb effect.</source>
					<target>This simplifies the logic for the reverb effect.</target>
				</segment>
			</unit>
			<unit id="184" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAUDIO2\_DEFAULT\_SAMPLERATE</pc> specification tells the audio engine to use the sample rate that is specified in the Sound Control Panel.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAUDIO2\_DEFAULT\_SAMPLERATE</pc> specification tells the audio engine to use the sample rate that is specified in the Sound Control Panel.</target>
				</segment>
			</unit>
			<unit id="185" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ee415912)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>In this example, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">m\_musicMasteringVoice</pc> is an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2MasteringVoice</pc></pc> object.</source>
					<target>In this example, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">m\_musicMasteringVoice</pc> is an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2MasteringVoice</pc></pc> object.</target>
				</segment>
			</unit>
			<unit id="186" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">*</data>
					<data id="id6">*</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method performs a similar step to create the mastering voice for the game play sounds, except that it specifies <pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioCategory\_GameEffects</pc> for the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">StreamCategory</pc> parameter, which is the default.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method performs a similar step to create the mastering voice for the game play sounds, except that it specifies <pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioCategory\_GameEffects</pc> for the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">StreamCategory</pc> parameter, which is the default.</target>
				</segment>
			</unit>
			<unit id="187" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze specifies <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioCategory\_GameMedia</pc> for background music so that users can listen to music from a different application as they play the game.</source>
					<target>Marble Maze specifies <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioCategory\_GameMedia</pc> for background music so that users can listen to music from a different application as they play the game.</target>
				</segment>
			</unit>
			<unit id="188" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>When a music app is playing, Windows mutes any voices that are created by the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioCategory\_GameMedia</pc> option.</source>
					<target>When a music app is playing, Windows mutes any voices that are created by the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioCategory\_GameMedia</pc> option.</target>
				</segment>
			</unit>
			<unit id="189" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The user still hears game-play sounds because they are created by the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioCategory\_GameEffects</pc> option.</source>
					<target>The user still hears game-play sounds because they are created by the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioCategory\_GameEffects</pc> option.</target>
				</segment>
			</unit>
			<unit id="190" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/hh404178)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>For more info about audio categories, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AUDIO\_STREAM\_CATEGORY</pc></pc> enumeration.</source>
					<target>For more info about audio categories, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AUDIO\_STREAM\_CATEGORY</pc></pc> enumeration.</target>
				</segment>
			</unit>
			<unit id="191" translate="yes">
				<segment state="initial">
					<source>Creating the reverb effect</source>
					<target>Creating the reverb effect</target>
				</segment>
			</unit>
			<unit id="192" translate="yes">
				<segment state="initial">
					<source>For each voice, you can use XAudio2 to create sequences of effects that process audio.</source>
					<target>For each voice, you can use XAudio2 to create sequences of effects that process audio.</target>
				</segment>
			</unit>
			<unit id="193" translate="yes">
				<segment state="initial">
					<source>Such a sequence is known as an effect chain.</source>
					<target>Such a sequence is known as an effect chain.</target>
				</segment>
			</unit>
			<unit id="194" translate="yes">
				<segment state="initial">
					<source>Use effect chains when you want to apply one or more effects to a voice.</source>
					<target>Use effect chains when you want to apply one or more effects to a voice.</target>
				</segment>
			</unit>
			<unit id="195" translate="yes">
				<segment state="initial">
					<source>Effect chains can be destructive; that is, each effect in the chain can overwrite the audio buffer.</source>
					<target>Effect chains can be destructive; that is, each effect in the chain can overwrite the audio buffer.</target>
				</segment>
			</unit>
			<unit id="196" translate="yes">
				<segment state="initial">
					<source>This property is important because XAudio2 makes no guarantee that output buffers are initialized with silence.</source>
					<target>This property is important because XAudio2 makes no guarantee that output buffers are initialized with silence.</target>
				</segment>
			</unit>
			<unit id="197" translate="yes">
				<segment state="initial">
					<source>Effect objects are represented in XAudio2 by cross-platform audio processing objects (XAPO).</source>
					<target>Effect objects are represented in XAudio2 by cross-platform audio processing objects (XAPO).</target>
				</segment>
			</unit>
			<unit id="198" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](o:microsoft.directx_sdk.xapo.audio_overview_xapo)</data>
				</originalData>
				<segment state="initial">
					<source>For more information about XAPO, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAPO Overviews</pc>.</source>
					<target>For more information about XAPO, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAPO Overviews</pc>.</target>
				</segment>
			</unit>
			<unit id="199" translate="yes">
				<segment state="initial">
					<source>When you create an effect chain, follow these steps:</source>
					<target>When you create an effect chain, follow these steps:</target>
				</segment>
			</unit>
			<unit id="200" translate="yes">
				<segment state="initial">
					<source>Create the effect object.</source>
					<target>Create the effect object.</target>
				</segment>
			</unit>
			<unit id="201" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419236)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Populate an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_DESCRIPTOR</pc></pc> structure with effect data.</source>
					<target>Populate an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_DESCRIPTOR</pc></pc> structure with effect data.</target>
				</segment>
			</unit>
			<unit id="202" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419235)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Populate an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_CHAIN</pc></pc> structure with data.</source>
					<target>Populate an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_CHAIN</pc></pc> structure with data.</target>
				</segment>
			</unit>
			<unit id="203" translate="yes">
				<segment state="initial">
					<source>Apply the effect chain to a voice.</source>
					<target>Apply the effect chain to a voice.</target>
				</segment>
			</unit>
			<unit id="204" translate="yes">
				<segment state="initial">
					<source>Populate an effect parameter structure and apply it to the effect.</source>
					<target>Populate an effect parameter structure and apply it to the effect.</target>
				</segment>
			</unit>
			<unit id="205" translate="yes">
				<segment state="initial">
					<source>Disable or enable the effect whenever appropriate.</source>
					<target>Disable or enable the effect whenever appropriate.</target>
				</segment>
			</unit>
			<unit id="206" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio</pc> class defines the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">CreateReverb</pc> method to create the effect chain that implements reverb.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio</pc> class defines the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">CreateReverb</pc> method to create the effect chain that implements reverb.</target>
				</segment>
			</unit>
			<unit id="207" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419213)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/desktop/ee415915)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>This method calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAudio2CreateReverb</pc></pc> function to create a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2SubmixVoice</pc></pc> object, which acts as the submix voice for the reverb effect.</source>
					<target>This method calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAudio2CreateReverb</pc></pc> function to create a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2SubmixVoice</pc></pc> object, which acts as the submix voice for the reverb effect.</target>
				</segment>
			</unit>
			<unit id="208" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419236)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_DESCRIPTOR</pc></pc> structure contains information about an XAPO for use in an effect chain, for example, the target number of output channels.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_DESCRIPTOR</pc></pc> structure contains information about an XAPO for use in an effect chain, for example, the target number of output channels.</target>
				</segment>
			</unit>
			<unit id="209" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/desktop/ee415915)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> method creates an <pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_DESCRIPTOR</pc> object that is set to the disabled state, uses two output channels, and references the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2SubmixVoice</pc></pc> object for the reverb effect.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> method creates an <pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_DESCRIPTOR</pc> object that is set to the disabled state, uses two output channels, and references the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2SubmixVoice</pc></pc> object for the reverb effect.</target>
				</segment>
			</unit>
			<unit id="210" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAUDIO2\_EFFECT\_DESCRIPTOR</pc> object starts in the disabled state because the game must set parameters before the effect starts modifying game sounds.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAUDIO2\_EFFECT\_DESCRIPTOR</pc> object starts in the disabled state because the game must set parameters before the effect starts modifying game sounds.</target>
				</segment>
			</unit>
			<unit id="211" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses two output channels to simplify the logic for the reverb effect.</source>
					<target>Marble Maze uses two output channels to simplify the logic for the reverb effect.</target>
				</segment>
			</unit>
			<unit id="212" translate="yes">
				<segment state="initial">
					<source>If your effect chain has multiple effects, each effect requires an object.</source>
					<target>If your effect chain has multiple effects, each effect requires an object.</target>
				</segment>
			</unit>
			<unit id="213" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419235)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/desktop/ee419236)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_CHAIN</pc></pc> structure holds the array of <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">XAUDIO2\_EFFECT\_DESCRIPTOR</pc></pc> objects that participate in the effect.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_CHAIN</pc></pc> structure holds the array of <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">XAUDIO2\_EFFECT\_DESCRIPTOR</pc></pc> objects that participate in the effect.</target>
				</segment>
			</unit>
			<unit id="214" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The following example shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> method specifies the one effect to implement reverb.</source>
					<target>The following example shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> method specifies the one effect to implement reverb.</target>
				</segment>
			</unit>
			<unit id="215" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ee418608)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> method calls the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2::CreateSubmixVoice</pc></pc> method to create the submix voice for the effect.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> method calls the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2::CreateSubmixVoice</pc></pc> method to create the submix voice for the effect.</target>
				</segment>
			</unit>
			<unit id="216" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419235)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">*</data>
					<data id="id6">*</data>
				</originalData>
				<segment state="initial">
					<source>It specifies the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_CHAIN</pc></pc> object for the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">pEffectChain</pc> parameter to associate the effect chain with the voice.</source>
					<target>It specifies the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_EFFECT\_CHAIN</pc></pc> object for the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">pEffectChain</pc> parameter to associate the effect chain with the voice.</target>
				</segment>
			</unit>
			<unit id="217" translate="yes">
				<segment state="initial">
					<source>Marble Maze also specifies two output channels and a sample rate of 48 kilohertz.</source>
					<target>Marble Maze also specifies two output channels and a sample rate of 48 kilohertz.</target>
				</segment>
			</unit>
			<unit id="218" translate="yes">
				<segment state="initial">
					<source>We chose this sample rate because it represented a balance between audio quality and the amount of required CPU processing.</source>
					<target>We chose this sample rate because it represented a balance between audio quality and the amount of required CPU processing.</target>
				</segment>
			</unit>
			<unit id="219" translate="yes">
				<segment state="initial">
					<source>A greater sample rate would have required more CPU processing without having a noticeable quality benefit.</source>
					<target>A greater sample rate would have required more CPU processing without having a noticeable quality benefit.</target>
				</segment>
			</unit>
			<unit id="220" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ee418594)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Tip</pc>   If you want to attach an existing effect chain to an existing submix voice, or you want to replace the current effect chain, use the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2Voice::SetEffectChain</pc></pc> method.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Tip</pc>   If you want to attach an existing effect chain to an existing submix voice, or you want to replace the current effect chain, use the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2Voice::SetEffectChain</pc></pc> method.</target>
				</segment>
			</unit>
			<unit id="221" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419213)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/desktop/ee418595)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Audio::XAudio2CreateReverb</pc></pc> method calls <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2Voice::SetEffectParameters</pc></pc> to set additional parameters that are associated with the effect.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Audio::XAudio2CreateReverb</pc></pc> method calls <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2Voice::SetEffectParameters</pc></pc> to set additional parameters that are associated with the effect.</target>
				</segment>
			</unit>
			<unit id="222" translate="yes">
				<segment state="initial">
					<source>This method takes a parameter structure that is specific to the effect.</source>
					<target>This method takes a parameter structure that is specific to the effect.</target>
				</segment>
			</unit>
			<unit id="223" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419224)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>An <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2FX\_REVERB\_PARAMETERS</pc></pc> object, which contains the effect parameters for reverb, is initialized in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">Audio::Initialize</pc> method because every reverb effect shares the same parameters.</source>
					<target>An <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2FX\_REVERB\_PARAMETERS</pc></pc> object, which contains the effect parameters for reverb, is initialized in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">Audio::Initialize</pc> method because every reverb effect shares the same parameters.</target>
				</segment>
			</unit>
			<unit id="224" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The following example shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::Initialize</pc> method initializes the reverb parameters for near-field reverb.</source>
					<target>The following example shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::Initialize</pc> method initializes the reverb parameters for near-field reverb.</target>
				</segment>
			</unit>
			<unit id="225" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>This example uses the default values for most of the reverb parameters, but it sets <pc dataRefEnd="id2" dataRefStart="id1" id="p1">DisableLateField</pc> to TRUE to specify near-field reverb, <pc dataRefEnd="id4" dataRefStart="id3" id="p2">EarlyDiffusion</pc> to 4 to simulate flat near surfaces, and <pc dataRefEnd="id6" dataRefStart="id5" id="p3">LateDiffusion</pc> to 15 to simulate very diffuse distant surfaces.</source>
					<target>This example uses the default values for most of the reverb parameters, but it sets <pc dataRefEnd="id2" dataRefStart="id1" id="p1">DisableLateField</pc> to TRUE to specify near-field reverb, <pc dataRefEnd="id4" dataRefStart="id3" id="p2">EarlyDiffusion</pc> to 4 to simulate flat near surfaces, and <pc dataRefEnd="id6" dataRefStart="id5" id="p3">LateDiffusion</pc> to 15 to simulate very diffuse distant surfaces.</target>
				</segment>
			</unit>
			<unit id="226" translate="yes">
				<segment state="initial">
					<source>Flat near surfaces cause echoes to reach you more quickly and loudly; diffuse distant surfaces cause echoes to be quieter and reach you more slowly.</source>
					<target>Flat near surfaces cause echoes to reach you more quickly and loudly; diffuse distant surfaces cause echoes to be quieter and reach you more slowly.</target>
				</segment>
			</unit>
			<unit id="227" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>You can experiment with reverb values to get the desired effect in your game or use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ReverbConvertI3DL2ToNative</pc> function to use industry-standard I3DL2 (Interactive 3D Audio Rendering Guidelines Level 2.0) parameters.</source>
					<target>You can experiment with reverb values to get the desired effect in your game or use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ReverbConvertI3DL2ToNative</pc> function to use industry-standard I3DL2 (Interactive 3D Audio Rendering Guidelines Level 2.0) parameters.</target>
				</segment>
			</unit>
			<unit id="228" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The following example shows how <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> sets the reverb parameters.</source>
					<target>The following example shows how <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> sets the reverb parameters.</target>
				</segment>
			</unit>
			<unit id="229" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419224)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The parameters parameter is an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2FX\_REVERB\_PARAMETERS</pc></pc> object.</source>
					<target>The parameters parameter is an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2FX\_REVERB\_PARAMETERS</pc></pc> object.</target>
				</segment>
			</unit>
			<unit id="230" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> method finishes by enabling the effect if the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">enableEffect</pc> flag is set and by setting its volume and output matrix.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateReverb</pc> method finishes by enabling the effect if the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">enableEffect</pc> flag is set and by setting its volume and output matrix.</target>
				</segment>
			</unit>
			<unit id="231" translate="yes">
				<segment state="initial">
					<source>This part sets the volume to full (1.0) and then specifies the volume matrix to be silence for both left and right inputs and left and right output speakers.</source>
					<target>This part sets the volume to full (1.0) and then specifies the volume matrix to be silence for both left and right inputs and left and right output speakers.</target>
				</segment>
			</unit>
			<unit id="232" translate="yes">
				<segment state="initial">
					<source>We do this because other code later cross-fades between the two reverbs (simulating the transition from being near a wall to being in a large room), or mutes both reverbs if required.</source>
					<target>We do this because other code later cross-fades between the two reverbs (simulating the transition from being near a wall to being in a large room), or mutes both reverbs if required.</target>
				</segment>
			</unit>
			<unit id="233" translate="yes">
				<segment state="initial">
					<source>When the reverb path is later unmuted, the game sets a matrix of {1.0f, 0.0f, 0.0f, 1.0f} to route left reverb output to the left input of the mastering voice and right reverb output to the right input of the mastering voice.</source>
					<target>When the reverb path is later unmuted, the game sets a matrix of {1.0f, 0.0f, 0.0f, 1.0f} to route left reverb output to the left input of the mastering voice and right reverb output to the right input of the mastering voice.</target>
				</segment>
			</unit>
			<unit id="234" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateReverb</pc> method four times; two times for the background music and two times for the game-play sounds.</source>
					<target>Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateReverb</pc> method four times; two times for the background music and two times for the game-play sounds.</target>
				</segment>
			</unit>
			<unit id="235" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The following shows how Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateReverb</pc> method for the background music.</source>
					<target>The following shows how Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateReverb</pc> method for the background music.</target>
				</segment>
			</unit>
			<unit id="236" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415756)</data>
				</originalData>
				<segment state="initial">
					<source>For a list of possible sources of effects for use with XAudio2, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAudio2 Audio Effects</pc>.</source>
					<target>For a list of possible sources of effects for use with XAudio2, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAudio2 Audio Effects</pc>.</target>
				</segment>
			</unit>
			<unit id="237" translate="yes">
				<segment state="initial">
					<source>Loading audio data from file</source>
					<target>Loading audio data from file</target>
				</segment>
			</unit>
			<unit id="238" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze defines the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer</pc> class, which uses Media Foundation to load audio resources from file.</source>
					<target>Marble Maze defines the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer</pc> class, which uses Media Foundation to load audio resources from file.</target>
				</segment>
			</unit>
			<unit id="239" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze uses one <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer</pc> object to load each audio file.</source>
					<target>Marble Maze uses one <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer</pc> object to load each audio file.</target>
				</segment>
			</unit>
			<unit id="240" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method to initialize each audio stream.</source>
					<target>Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method to initialize each audio stream.</target>
				</segment>
			</unit>
			<unit id="241" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Here's how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2">MediaStreamer::Initialize</pc> to initialize the audio stream for the background music:</source>
					<target>Here's how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2">MediaStreamer::Initialize</pc> to initialize the audio stream for the background music:</target>
				</segment>
			</unit>
			<unit id="242" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ms702238)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method starts by calling the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">MFStartup</pc></pc> function to initialize Media Foundation.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method starts by calling the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">MFStartup</pc></pc> function to initialize Media Foundation.</target>
				</segment>
			</unit>
			<unit id="243" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/dd388110)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">[</data>
					<data id="id8">](https://msdn.microsoft.com/library/windows/desktop/dd374655)</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> then calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">MFCreateSourceReaderFromURL</pc></pc> to create an <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">IMFSourceReader</pc></pc> object.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> then calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">MFCreateSourceReaderFromURL</pc></pc> to create an <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">IMFSourceReader</pc></pc> object.</target>
				</segment>
			</unit>
			<unit id="244" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>An <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMFSourceReader</pc> object reads media data from the file that is specified by url.</source>
					<target>An <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMFSourceReader</pc> object reads media data from the file that is specified by url.</target>
				</segment>
			</unit>
			<unit id="245" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ms704850)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method then creates an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IMFMediaType</pc></pc> object to describe the format of the audio stream.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method then creates an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IMFMediaType</pc></pc> object to describe the format of the audio stream.</target>
				</segment>
			</unit>
			<unit id="246" translate="yes">
				<segment state="initial">
					<source>An audio format has two types: a major type and a subtype.</source>
					<target>An audio format has two types: a major type and a subtype.</target>
				</segment>
			</unit>
			<unit id="247" translate="yes">
				<segment state="initial">
					<source>The major type defines the overall format of the media, such as video, audio, script, and so on.</source>
					<target>The major type defines the overall format of the media, such as video, audio, script, and so on.</target>
				</segment>
			</unit>
			<unit id="248" translate="yes">
				<segment state="initial">
					<source>The subtype defines the format, such as PCM, ADPCM, or WMA.</source>
					<target>The subtype defines the format, such as PCM, ADPCM, or WMA.</target>
				</segment>
			</unit>
			<unit id="249" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/bb970530)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method uses the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IMFMediaType::SetGUID</pc></pc> method to specify the major type as audio (<pc dataRefEnd="id8" dataRefStart="id7" id="p4">MFMediaType\_Audio</pc>) and the minor type as uncompressed PCM audio (<pc dataRefEnd="id10" dataRefStart="id9" id="p5">MFAudioFormat\_PCM</pc>).</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method uses the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IMFMediaType::SetGUID</pc></pc> method to specify the major type as audio (<pc dataRefEnd="id8" dataRefStart="id7" id="p4">MFMediaType\_Audio</pc>) and the minor type as uncompressed PCM audio (<pc dataRefEnd="id10" dataRefStart="id9" id="p5">MFAudioFormat\_PCM</pc>).</target>
				</segment>
			</unit>
			<unit id="250" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/bb970432)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IMFSourceReader::SetCurrentMediaType</pc></pc> method associates the media type with the stream reader.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IMFSourceReader::SetCurrentMediaType</pc></pc> method associates the media type with the stream reader.</target>
				</segment>
			</unit>
			<unit id="251" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ms702177)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">[</data>
					<data id="id8">](https://msdn.microsoft.com/library/windows/hardware/ff538799)</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method then obtains the complete output media format from Media Foundation and calls the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">MFCreateWaveFormatExFromMFMediaType</pc></pc> function to convert the Media Foundation audio media type to a <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">WAVEFORMATEX</pc></pc> structure.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method then obtains the complete output media format from Media Foundation and calls the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">MFCreateWaveFormatExFromMFMediaType</pc></pc> function to convert the Media Foundation audio media type to a <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">WAVEFORMATEX</pc></pc> structure.</target>
				</segment>
			</unit>
			<unit id="252" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">WAVEFORMATEX</pc> structure defines the format of waveform-audio data.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">WAVEFORMATEX</pc> structure defines the format of waveform-audio data.</target>
				</segment>
			</unit>
			<unit id="253" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses this structure to create the source voices and to apply the low-pass filter to the marble rolling sound.</source>
					<target>Marble Maze uses this structure to create the source voices and to apply the low-pass filter to the marble rolling sound.</target>
				</segment>
			</unit>
			<unit id="254" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ms702177)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">[</data>
					<data id="id10">](https://msdn.microsoft.com/library/windows/hardware/ff538799)</data>
					<data id="id11">**</data>
					<data id="id12">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Important</pc>   The <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">MFCreateWaveFormatExFromMFMediaType</pc></pc> function uses <pc dataRefEnd="id8" dataRefStart="id7" id="p4">CoTaskMemAlloc</pc> to allocate the <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">WAVEFORMATEX</pc></pc> object.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Important</pc>   The <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">MFCreateWaveFormatExFromMFMediaType</pc></pc> function uses <pc dataRefEnd="id8" dataRefStart="id7" id="p4">CoTaskMemAlloc</pc> to allocate the <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">WAVEFORMATEX</pc></pc> object.</target>
				</segment>
			</unit>
			<unit id="255" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Therefore, make sure that you call <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CoTaskMemFree</pc> when you are finished using this object.</source>
					<target>Therefore, make sure that you call <pc dataRefEnd="id2" dataRefStart="id1" id="p1">CoTaskMemFree</pc> when you are finished using this object.</target>
				</segment>
			</unit>
			<unit id="256" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">*</data>
					<data id="id4">*</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method finishes by computing the length of the stream, m\_<pc dataRefEnd="id4" dataRefStart="id3" id="p2">maxStreamLengthInBytes</pc>, in bytes.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaStreamer::Initialize</pc> method finishes by computing the length of the stream, m\_<pc dataRefEnd="id4" dataRefStart="id3" id="p2">maxStreamLengthInBytes</pc>, in bytes.</target>
				</segment>
			</unit>
			<unit id="257" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/dd374662)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>To do so, it calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IMFSourceReader::IMFSourceReader::GetPresentationAttribute</pc></pc> method to get the duration of the audio stream in 100-nanosecond units, converts the duration to sections, and then multiplies by the average data transfer rate in bytes per second.</source>
					<target>To do so, it calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IMFSourceReader::IMFSourceReader::GetPresentationAttribute</pc></pc> method to get the duration of the audio stream in 100-nanosecond units, converts the duration to sections, and then multiplies by the average data transfer rate in bytes per second.</target>
				</segment>
			</unit>
			<unit id="258" translate="yes">
				<segment state="initial">
					<source>Marble Maze later uses this value to allocate the buffer that holds each game play sound.</source>
					<target>Marble Maze later uses this value to allocate the buffer that holds each game play sound.</target>
				</segment>
			</unit>
			<unit id="259" translate="yes">
				<segment state="initial">
					<source>Creating the source voices</source>
					<target>Creating the source voices</target>
				</segment>
			</unit>
			<unit id="260" translate="yes">
				<segment state="initial">
					<source>Marble Maze creates XAudio2 source voices to play each of its game sounds and music in source voices.</source>
					<target>Marble Maze creates XAudio2 source voices to play each of its game sounds and music in source voices.</target>
				</segment>
			</unit>
			<unit id="261" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ee415914)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio</pc> class defines an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2SourceVoice</pc></pc> object for the background music and an array of <pc dataRefEnd="id8" dataRefStart="id7" id="p4">SoundEffectData</pc> objects to hold the game play sounds.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio</pc> class defines an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2SourceVoice</pc></pc> object for the background music and an array of <pc dataRefEnd="id8" dataRefStart="id7" id="p4">SoundEffectData</pc> objects to hold the game play sounds.</target>
				</segment>
			</unit>
			<unit id="262" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">SoundEffectData</pc> structure holds the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2SourceVoice</pc> object for an effect and also defines other effect-related data, such as the audio buffer.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">SoundEffectData</pc> structure holds the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2SourceVoice</pc> object for an effect and also defines other effect-related data, such as the audio buffer.</target>
				</segment>
			</unit>
			<unit id="263" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Audio.h defines the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">SoundEvent</pc> enumeration.</source>
					<target>Audio.h defines the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">SoundEvent</pc> enumeration.</target>
				</segment>
			</unit>
			<unit id="264" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses this enumeration to identify each game play sound.</source>
					<target>Marble Maze uses this enumeration to identify each game play sound.</target>
				</segment>
			</unit>
			<unit id="265" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The Audio class also uses this enumeration to index the array of <pc dataRefEnd="id2" dataRefStart="id1" id="p1">SoundEffectData</pc> objects.</source>
					<target>The Audio class also uses this enumeration to index the array of <pc dataRefEnd="id2" dataRefStart="id1" id="p1">SoundEffectData</pc> objects.</target>
				</segment>
			</unit>
			<unit id="266" translate="yes">
				<segment state="initial">
					<source>The following table shows the relationship between each of these values, the file that contains the associated sound data, and a brief description of what each sound represents.</source>
					<target>The following table shows the relationship between each of these values, the file that contains the associated sound data, and a brief description of what each sound represents.</target>
				</segment>
			</unit>
			<unit id="267" translate="yes">
				<segment state="initial">
					<source>The audio files are located in the \\Media\\Audio folder.</source>
					<target>The audio files are located in the \\Media\\Audio folder.</target>
				</segment>
			</unit>
			<unit id="268" translate="yes">
				<segment state="initial">
					<source>SoundEvent value</source>
					<target>SoundEvent value</target>
				</segment>
			</unit>
			<unit id="269" translate="yes">
				<segment state="initial">
					<source>File name</source>
					<target>File name</target>
				</segment>
			</unit>
			<unit id="270" translate="yes">
				<segment state="initial">
					<source>Description</source>
					<target>Description</target>
				</segment>
			</unit>
			<unit id="271" translate="yes">
				<segment state="initial">
					<source>RollingEvent</source>
					<target>RollingEvent</target>
				</segment>
			</unit>
			<unit id="272" translate="yes">
				<segment state="initial">
					<source>MarbleRoll.wav</source>
					<target>MarbleRoll.wav</target>
				</segment>
			</unit>
			<unit id="273" translate="yes">
				<segment state="initial">
					<source>Played as the marble rolls.</source>
					<target>Played as the marble rolls.</target>
				</segment>
			</unit>
			<unit id="274" translate="yes">
				<segment state="initial">
					<source>FallingEvent</source>
					<target>FallingEvent</target>
				</segment>
			</unit>
			<unit id="275" translate="yes">
				<segment state="initial">
					<source>MarbleFall.wav</source>
					<target>MarbleFall.wav</target>
				</segment>
			</unit>
			<unit id="276" translate="yes">
				<segment state="initial">
					<source>Played when the marble falls off the maze.</source>
					<target>Played when the marble falls off the maze.</target>
				</segment>
			</unit>
			<unit id="277" translate="yes">
				<segment state="initial">
					<source>CollisionEvent</source>
					<target>CollisionEvent</target>
				</segment>
			</unit>
			<unit id="278" translate="yes">
				<segment state="initial">
					<source>MarbleHit.wav</source>
					<target>MarbleHit.wav</target>
				</segment>
			</unit>
			<unit id="279" translate="yes">
				<segment state="initial">
					<source>Played when the marble collides with the maze.</source>
					<target>Played when the marble collides with the maze.</target>
				</segment>
			</unit>
			<unit id="280" translate="yes">
				<segment state="initial">
					<source>CheckpointEvent</source>
					<target>CheckpointEvent</target>
				</segment>
			</unit>
			<unit id="281" translate="yes">
				<segment state="initial">
					<source>Checkpoint.wav</source>
					<target>Checkpoint.wav</target>
				</segment>
			</unit>
			<unit id="282" translate="yes">
				<segment state="initial">
					<source>Played when the marble passes over a checkpoint.</source>
					<target>Played when the marble passes over a checkpoint.</target>
				</segment>
			</unit>
			<unit id="283" translate="yes">
				<segment state="initial">
					<source>MenuChangeEvent</source>
					<target>MenuChangeEvent</target>
				</segment>
			</unit>
			<unit id="284" translate="yes">
				<segment state="initial">
					<source>MenuChange.wav</source>
					<target>MenuChange.wav</target>
				</segment>
			</unit>
			<unit id="285" translate="yes">
				<segment state="initial">
					<source>Played when the game user changes the current menu item.</source>
					<target>Played when the game user changes the current menu item.</target>
				</segment>
			</unit>
			<unit id="286" translate="yes">
				<segment state="initial">
					<source>MenuSelectedEvent</source>
					<target>MenuSelectedEvent</target>
				</segment>
			</unit>
			<unit id="287" translate="yes">
				<segment state="initial">
					<source>MenuSelect.wav</source>
					<target>MenuSelect.wav</target>
				</segment>
			</unit>
			<unit id="288" translate="yes">
				<segment state="initial">
					<source>Played when the game user selects a menu item.</source>
					<target>Played when the game user selects a menu item.</target>
				</segment>
			</unit>
			<unit id="289" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The following example shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method creates the source voice for the background music.</source>
					<target>The following example shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method creates the source voice for the background music.</target>
				</segment>
			</unit>
			<unit id="290" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee418607)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::CreateSourceVoice</pc></pc> method creates and configures a source voice.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::CreateSourceVoice</pc></pc> method creates and configures a source voice.</target>
				</segment>
			</unit>
			<unit id="291" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/hardware/ff538799)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>It takes a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">WAVEFORMATEX</pc></pc> structure that defines the format of the audio buffers that are sent to the voice.</source>
					<target>It takes a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">WAVEFORMATEX</pc></pc> structure that defines the format of the audio buffers that are sent to the voice.</target>
				</segment>
			</unit>
			<unit id="292" translate="yes">
				<segment state="initial">
					<source>As mentioned previously, Marble Maze uses the PCM format.</source>
					<target>As mentioned previously, Marble Maze uses the PCM format.</target>
				</segment>
			</unit>
			<unit id="293" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419244)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_SEND\_DESCRIPTOR</pc></pc> structure defines the target destination voice from another voice and specifies whether a filter should be used.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_SEND\_DESCRIPTOR</pc></pc> structure defines the target destination voice from another voice and specifies whether a filter should be used.</target>
				</segment>
			</unit>
			<unit id="294" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::SetSoundEffectFilter</pc> function to use the filters to change the sound of the ball as it rolls.</source>
					<target>Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::SetSoundEffectFilter</pc> function to use the filters to change the sound of the ball as it rolls.</target>
				</segment>
			</unit>
			<unit id="295" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee419246)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_VOICE\_SENDS</pc></pc> structure defines the set of voices to receive data from a single output voice.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_VOICE\_SENDS</pc></pc> structure defines the set of voices to receive data from a single output voice.</target>
				</segment>
			</unit>
			<unit id="296" translate="yes">
				<segment state="initial">
					<source>Marble Maze sends data from the source voice to the mastering voice (for the dry, or unaltered, portion of a playing sound) and to the two submix voices that implement the wet, or reverberant, portion of a playing sound.</source>
					<target>Marble Maze sends data from the source voice to the mastering voice (for the dry, or unaltered, portion of a playing sound) and to the two submix voices that implement the wet, or reverberant, portion of a playing sound.</target>
				</segment>
			</unit>
			<unit id="297" translate="yes">
				<segment state="initial">
					<source>Playing background music</source>
					<target>Playing background music</target>
				</segment>
			</unit>
			<unit id="298" translate="yes">
				<segment state="initial">
					<source>A source voice is created in the stopped state.</source>
					<target>A source voice is created in the stopped state.</target>
				</segment>
			</unit>
			<unit id="299" translate="yes">
				<segment state="initial">
					<source>Marble Maze starts the background music in the game loop.</source>
					<target>Marble Maze starts the background music in the game loop.</target>
				</segment>
			</unit>
			<unit id="300" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The first call to <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Update</pc> calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Audio::Start</pc> to start the background music.</source>
					<target>The first call to <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Update</pc> calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Audio::Start</pc> to start the background music.</target>
				</segment>
			</unit>
			<unit id="301" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ee418471)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::Start</pc> method calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2SourceVoice::Start</pc></pc> to start to process the source voice for the background music.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::Start</pc> method calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2SourceVoice::Start</pc></pc> to start to process the source voice for the background music.</target>
				</segment>
			</unit>
			<unit id="302" translate="yes">
				<segment state="initial">
					<source>The source voice passes that audio data to the next stage of the audio graph.</source>
					<target>The source voice passes that audio data to the next stage of the audio graph.</target>
				</segment>
			</unit>
			<unit id="303" translate="yes">
				<segment state="initial">
					<source>In the case of Marble Maze, the next stage contains two submix voices that apply the two reverb effects to the audio.</source>
					<target>In the case of Marble Maze, the next stage contains two submix voices that apply the two reverb effects to the audio.</target>
				</segment>
			</unit>
			<unit id="304" translate="yes">
				<segment state="initial">
					<source>One submix voice applies a close late-field reverb; the second applies a far late-field reverb.</source>
					<target>One submix voice applies a close late-field reverb; the second applies a far late-field reverb.</target>
				</segment>
			</unit>
			<unit id="305" translate="yes">
				<segment state="initial">
					<source>The amount that each submix voice contributes to the final mix is determined by the size and shape of the room.</source>
					<target>The amount that each submix voice contributes to the final mix is determined by the size and shape of the room.</target>
				</segment>
			</unit>
			<unit id="306" translate="yes">
				<segment state="initial">
					<source>The near-field reverb contributes more when the ball is near a wall or in a small room, and the late-field reverb contributes more when the ball is in a large space.</source>
					<target>The near-field reverb contributes more when the ball is near a wall or in a small room, and the late-field reverb contributes more when the ball is in a large space.</target>
				</segment>
			</unit>
			<unit id="307" translate="yes">
				<segment state="initial">
					<source>This technique produces a more realistic echo effect as the marble moves through the maze.</source>
					<target>This technique produces a more realistic echo effect as the marble moves through the maze.</target>
				</segment>
			</unit>
			<unit id="308" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>To learn more about how Marble Maze implements this effect, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::SetRoomSize</pc> and <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Physics::CalculateCurrentRoomSize</pc> in the Marble Maze source code.</source>
					<target>To learn more about how Marble Maze implements this effect, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::SetRoomSize</pc> and <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Physics::CalculateCurrentRoomSize</pc> in the Marble Maze source code.</target>
				</segment>
			</unit>
			<unit id="309" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  In a game in which most room sizes are relatively the same, you can use a more basic reverb model.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  In a game in which most room sizes are relatively the same, you can use a more basic reverb model.</target>
				</segment>
			</unit>
			<unit id="310" translate="yes">
				<segment state="initial">
					<source>For example, you can use one reverb setting for all rooms or you can create a predefined reverb setting for each room.</source>
					<target>For example, you can use one reverb setting for all rooms or you can create a predefined reverb setting for each room.</target>
				</segment>
			</unit>
			<unit id="311" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method uses Media Foundation to load the background music.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::CreateResources</pc> method uses Media Foundation to load the background music.</target>
				</segment>
			</unit>
			<unit id="312" translate="yes">
				<segment state="initial">
					<source>At this point, however, the source voice does not have audio data to work with.</source>
					<target>At this point, however, the source voice does not have audio data to work with.</target>
				</segment>
			</unit>
			<unit id="313" translate="yes">
				<segment state="initial">
					<source>In addition, because the background music loops, the source voice must be regularly updated with data so that the music continues to play.</source>
					<target>In addition, because the background music loops, the source voice must be regularly updated with data so that the music continues to play.</target>
				</segment>
			</unit>
			<unit id="314" translate="yes">
				<segment state="initial">
					<source>To keep the source voice filled with data, the game loop updates the audio buffers every frame.</source>
					<target>To keep the source voice filled with data, the game loop updates the audio buffers every frame.</target>
				</segment>
			</unit>
			<unit id="315" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Render</pc> method calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Audio::Render</pc> to process the background music audio buffer.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Render</pc> method calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Audio::Render</pc> to process the background music audio buffer.</target>
				</segment>
			</unit>
			<unit id="316" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::Render</pc> defines an array of three audio buffers, <pc dataRefEnd="id4" dataRefStart="id3" id="p2">m\_audioBuffers</pc>.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::Render</pc> defines an array of three audio buffers, <pc dataRefEnd="id4" dataRefStart="id3" id="p2">m\_audioBuffers</pc>.</target>
				</segment>
			</unit>
			<unit id="317" translate="yes">
				<segment state="initial">
					<source>Each buffer holds 64 KB (65536 bytes) of data.</source>
					<target>Each buffer holds 64 KB (65536 bytes) of data.</target>
				</segment>
			</unit>
			<unit id="318" translate="yes">
				<segment state="initial">
					<source>The loop reads data from the Media Foundation object and writes that data to the source voice until the source voice has three queued buffers.</source>
					<target>The loop reads data from the Media Foundation object and writes that data to the source voice until the source voice has three queued buffers.</target>
				</segment>
			</unit>
			<unit id="319" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Caution</pc>  Although Marble Maze uses a 64 KB buffer to hold music data, you may need to use a larger or smaller buffer.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Caution</pc>  Although Marble Maze uses a 64 KB buffer to hold music data, you may need to use a larger or smaller buffer.</target>
				</segment>
			</unit>
			<unit id="320" translate="yes">
				<segment state="initial">
					<source>This amount depends on the requirements of your game.</source>
					<target>This amount depends on the requirements of your game.</target>
				</segment>
			</unit>
			<unit id="321" translate="yes">
				<segment state="initial">
					<source>The loop also handles when the Media Foundation object reaches the end of the stream.</source>
					<target>The loop also handles when the Media Foundation object reaches the end of the stream.</target>
				</segment>
			</unit>
			<unit id="322" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ms697215)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>In this case, it calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">MediaStreamer::OnClockRestart</pc></pc> method to reset the position of the audio source.</source>
					<target>In this case, it calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">MediaStreamer::OnClockRestart</pc></pc> method to reset the position of the audio source.</target>
				</segment>
			</unit>
			<unit id="323" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>To implement audio looping for a single buffer (or for an entire sound that is fully loaded into memory), you can set the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">LoopCount</pc> field to <pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_LOOP\_INFINITE</pc> when you initialize the sound.</source>
					<target>To implement audio looping for a single buffer (or for an entire sound that is fully loaded into memory), you can set the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">LoopCount</pc> field to <pc dataRefEnd="id4" dataRefStart="id3" id="p2">XAUDIO2\_LOOP\_INFINITE</pc> when you initialize the sound.</target>
				</segment>
			</unit>
			<unit id="324" translate="yes">
				<segment state="initial">
					<source>Marble Maze uses this technique to play the rolling sound for the marble.</source>
					<target>Marble Maze uses this technique to play the rolling sound for the marble.</target>
				</segment>
			</unit>
			<unit id="325" translate="yes">
				<segment state="initial">
					<source>However, for the background music, Marble Maze manages the buffers directly so that it can better control the amount of memory that is used.</source>
					<target>However, for the background music, Marble Maze manages the buffers directly so that it can better control the amount of memory that is used.</target>
				</segment>
			</unit>
			<unit id="326" translate="yes">
				<segment state="initial">
					<source>When your music files are large, you can stream the music data into smaller buffers.</source>
					<target>When your music files are large, you can stream the music data into smaller buffers.</target>
				</segment>
			</unit>
			<unit id="327" translate="yes">
				<segment state="initial">
					<source>Doing so can help balance memory size with the frequency of the game’s ability to process and stream audio data.</source>
					<target>Doing so can help balance memory size with the frequency of the game’s ability to process and stream audio data.</target>
				</segment>
			</unit>
			<unit id="328" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Tip</pc>  If your game has a low or varying frame rate, processing audio on the main thread can produce unexpected pauses or pops in the audio because the audio engine has insufficient buffered audio data to work with.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Tip</pc>  If your game has a low or varying frame rate, processing audio on the main thread can produce unexpected pauses or pops in the audio because the audio engine has insufficient buffered audio data to work with.</target>
				</segment>
			</unit>
			<unit id="329" translate="yes">
				<segment state="initial">
					<source>If your game is sensitive to this issue, consider processing audio on a separate thread that does not perform rendering.</source>
					<target>If your game is sensitive to this issue, consider processing audio on a separate thread that does not perform rendering.</target>
				</segment>
			</unit>
			<unit id="330" translate="yes">
				<segment state="initial">
					<source>This approach is especially useful on computers that have multiple processors because your game can use idle processors.</source>
					<target>This approach is especially useful on computers that have multiple processors because your game can use idle processors.</target>
				</segment>
			</unit>
			<unit id="331" translate="yes">
				<segment state="initial">
					<source>Reacting to game events</source>
					<target>Reacting to game events</target>
				</segment>
			</unit>
			<unit id="332" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
					<data id="id9">**</data>
					<data id="id10">**</data>
					<data id="id11">**</data>
					<data id="id12">**</data>
					<data id="id13">**</data>
					<data id="id14">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze</pc> class provides methods such as <pc dataRefEnd="id4" dataRefStart="id3" id="p2">PlaySoundEffect</pc>, <pc dataRefEnd="id6" dataRefStart="id5" id="p3">IsSoundEffectStarted</pc>, <pc dataRefEnd="id8" dataRefStart="id7" id="p4">StopSoundEffect</pc>, <pc dataRefEnd="id10" dataRefStart="id9" id="p5">SetSoundEffectVolume</pc>, <pc dataRefEnd="id12" dataRefStart="id11" id="p6">SetSoundEffectPitch</pc>, and <pc dataRefEnd="id14" dataRefStart="id13" id="p7">SetSoundEffectFilter</pc> to enable the game to control when sounds play and stop, and to control sound properties such as volume and pitch.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze</pc> class provides methods such as <pc dataRefEnd="id4" dataRefStart="id3" id="p2">PlaySoundEffect</pc>, <pc dataRefEnd="id6" dataRefStart="id5" id="p3">IsSoundEffectStarted</pc>, <pc dataRefEnd="id8" dataRefStart="id7" id="p4">StopSoundEffect</pc>, <pc dataRefEnd="id10" dataRefStart="id9" id="p5">SetSoundEffectVolume</pc>, <pc dataRefEnd="id12" dataRefStart="id11" id="p6">SetSoundEffectPitch</pc>, and <pc dataRefEnd="id14" dataRefStart="id13" id="p7">SetSoundEffectFilter</pc> to enable the game to control when sounds play and stop, and to control sound properties such as volume and pitch.</target>
				</segment>
			</unit>
			<unit id="333" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>For example, if the marble falls off the maze, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Update</pc> method calls the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Audio::PlaySoundEffect</pc> method to play the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">FallingEvent</pc> sound.</source>
					<target>For example, if the marble falls off the maze, <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Update</pc> method calls the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Audio::PlaySoundEffect</pc> method to play the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">FallingEvent</pc> sound.</target>
				</segment>
			</unit>
			<unit id="334" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/ee418471)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> method calls the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2SourceVoice::Start</pc></pc> method to begin playback of the sound.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> method calls the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2SourceVoice::Start</pc></pc> method to begin playback of the sound.</target>
				</segment>
			</unit>
			<unit id="335" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>If the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IXAudio2SourceVoice::Start</pc> method has already been called, it is not started again.</source>
					<target>If the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IXAudio2SourceVoice::Start</pc> method has already been called, it is not started again.</target>
				</segment>
			</unit>
			<unit id="336" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> then performs custom logic for certain sounds.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> then performs custom logic for certain sounds.</target>
				</segment>
			</unit>
			<unit id="337" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">[</data>
					<data id="id4">](https://msdn.microsoft.com/library/windows/desktop/hh405047)</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
				</originalData>
				<segment state="initial">
					<source>For sounds other than rolling, the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> method calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2SourceVoice::GetState</pc></pc> to determine the number of buffers that the source voice is playing.</source>
					<target>For sounds other than rolling, the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> method calls <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">IXAudio2SourceVoice::GetState</pc></pc> to determine the number of buffers that the source voice is playing.</target>
				</segment>
			</unit>
			<unit id="338" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee418473)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>It calls <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2SourceVoice::SubmitSourceBuffer</pc></pc> to add the audio data for the sound to the voice’s input queue if no buffers are active.</source>
					<target>It calls <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2SourceVoice::SubmitSourceBuffer</pc></pc> to add the audio data for the sound to the voice’s input queue if no buffers are active.</target>
				</segment>
			</unit>
			<unit id="339" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> method also enables the collision sound to be played two times in sequence.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> method also enables the collision sound to be played two times in sequence.</target>
				</segment>
			</unit>
			<unit id="340" translate="yes">
				<segment state="initial">
					<source>This occurs, for example, when the marble collides with a corner of the maze.</source>
					<target>This occurs, for example, when the marble collides with a corner of the maze.</target>
				</segment>
			</unit>
			<unit id="341" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>As already described, the Audio class uses the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAUDIO2\_LOOP\_INFINITE</pc> flag when it initializes the sound for the rolling event.</source>
					<target>As already described, the Audio class uses the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAUDIO2\_LOOP\_INFINITE</pc> flag when it initializes the sound for the rolling event.</target>
				</segment>
			</unit>
			<unit id="342" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The sound starts looped playback the first time that <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> is called for this event.</source>
					<target>The sound starts looped playback the first time that <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::PlaySoundEffect</pc> is called for this event.</target>
				</segment>
			</unit>
			<unit id="343" translate="yes">
				<segment state="initial">
					<source>To simplify the playback logic for the rolling sound, Marble Maze mutes the sound instead of stopping it.</source>
					<target>To simplify the playback logic for the rolling sound, Marble Maze mutes the sound instead of stopping it.</target>
				</segment>
			</unit>
			<unit id="344" translate="yes">
				<segment state="initial">
					<source>As the marble changes velocity, Marble Maze changes the pitch and volume of the sound to give it a more realistic effect.</source>
					<target>As the marble changes velocity, Marble Maze changes the pitch and volume of the sound to give it a more realistic effect.</target>
				</segment>
			</unit>
			<unit id="345" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The following shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Update</pc> method updates the pitch and volume of the marble as its velocity changes and how it mutes the sound by setting its volume to zero when the marble stops.</source>
					<target>The following shows how the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Update</pc> method updates the pitch and volume of the marble as its velocity changes and how it mutes the sound by setting its volume to zero when the marble stops.</target>
				</segment>
			</unit>
			<unit id="346" translate="yes">
				<segment state="initial">
					<source>Reacting to suspend and resume events</source>
					<target>Reacting to suspend and resume events</target>
				</segment>
			</unit>
			<unit id="347" translate="yes">
				<segment state="initial">
					<source>The document Marble Maze application structure describes how Marble Maze supports suspend and resume.</source>
					<target>The document Marble Maze application structure describes how Marble Maze supports suspend and resume.</target>
				</segment>
			</unit>
			<unit id="348" translate="yes">
				<segment state="initial">
					<source>When the game is suspended, the game pauses the audio.</source>
					<target>When the game is suspended, the game pauses the audio.</target>
				</segment>
			</unit>
			<unit id="349" translate="yes">
				<segment state="initial">
					<source>When the game resumes, the game resumes the audio where it left off.</source>
					<target>When the game resumes, the game resumes the audio where it left off.</target>
				</segment>
			</unit>
			<unit id="350" translate="yes">
				<segment state="initial">
					<source>We do so to follow the best practice of not using resources when you know they’re not needed.</source>
					<target>We do so to follow the best practice of not using resources when you know they’re not needed.</target>
				</segment>
			</unit>
			<unit id="351" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::SuspendAudio</pc> method is called when the game is suspended.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::SuspendAudio</pc> method is called when the game is suspended.</target>
				</segment>
			</unit>
			<unit id="352" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee418628)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>This method calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::StopEngine</pc></pc> method to stop all audio.</source>
					<target>This method calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::StopEngine</pc></pc> method to stop all audio.</target>
				</segment>
			</unit>
			<unit id="353" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Although <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IXAudio2::StopEngine</pc> stops all audio output immediately, it preserves the audio graph and its effect parameters (for example, the reverb effect that’s applied when the marble bounces).</source>
					<target>Although <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IXAudio2::StopEngine</pc> stops all audio output immediately, it preserves the audio graph and its effect parameters (for example, the reverb effect that’s applied when the marble bounces).</target>
				</segment>
			</unit>
			<unit id="354" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::ResumeAudio</pc> method is called when the game is resumed.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::ResumeAudio</pc> method is called when the game is resumed.</target>
				</segment>
			</unit>
			<unit id="355" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee418626)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>This method uses the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::StartEngine</pc></pc> method to restart the audio.</source>
					<target>This method uses the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::StartEngine</pc></pc> method to restart the audio.</target>
				</segment>
			</unit>
			<unit id="356" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee418628)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>Because the call to <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::StopEngine</pc></pc> preserves the audio graph and its effect parameters, the audio output resumes where it left off.</source>
					<target>Because the call to <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::StopEngine</pc></pc> preserves the audio graph and its effect parameters, the audio output resumes where it left off.</target>
				</segment>
			</unit>
			<unit id="357" translate="yes">
				<segment state="initial">
					<source>Handling headphones and device changes</source>
					<target>Handling headphones and device changes</target>
				</segment>
			</unit>
			<unit id="358" translate="yes">
				<segment state="initial">
					<source>Marble maze uses engine callbacks to handle XAudio2 engine failures, such as when the audio device changes.</source>
					<target>Marble maze uses engine callbacks to handle XAudio2 engine failures, such as when the audio device changes.</target>
				</segment>
			</unit>
			<unit id="359" translate="yes">
				<segment state="initial">
					<source>A likely cause of a device change is when the game user connects or disconnects the headphones.</source>
					<target>A likely cause of a device change is when the game user connects or disconnects the headphones.</target>
				</segment>
			</unit>
			<unit id="360" translate="yes">
				<segment state="initial">
					<source>We recommend that you implement the engine callback that handles device changes.</source>
					<target>We recommend that you implement the engine callback that handles device changes.</target>
				</segment>
			</unit>
			<unit id="361" translate="yes">
				<segment state="initial">
					<source>Otherwise, your game will stop playing sound when the user plugs in or removes headphones, until the game is restarted.</source>
					<target>Otherwise, your game will stop playing sound when the user plugs in or removes headphones, until the game is restarted.</target>
				</segment>
			</unit>
			<unit id="362" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Audio.h defines the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioEngineCallbacks</pc> class.</source>
					<target>Audio.h defines the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioEngineCallbacks</pc> class.</target>
				</segment>
			</unit>
			<unit id="363" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415910)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>This class implements the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2EngineCallback</pc></pc> interface.</source>
					<target>This class implements the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2EngineCallback</pc></pc> interface.</target>
				</segment>
			</unit>
			<unit id="364" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415910)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2EngineCallback</pc></pc> interface enables your code to be notified when audio processing events occur and when the engine encounters a critical error.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2EngineCallback</pc></pc> interface enables your code to be notified when audio processing events occur and when the engine encounters a critical error.</target>
				</segment>
			</unit>
			<unit id="365" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee418620)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/desktop/ee415908)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>To register for callbacks, Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::RegisterForCallbacks</pc></pc> method after it creates the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2</pc></pc> object for the music engine.</source>
					<target>To register for callbacks, Marble Maze calls the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2::RegisterForCallbacks</pc></pc> method after it creates the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2</pc></pc> object for the music engine.</target>
				</segment>
			</unit>
			<unit id="366" translate="yes">
				<segment state="initial">
					<source>Marble Maze does not require notification when audio processing starts or ends.</source>
					<target>Marble Maze does not require notification when audio processing starts or ends.</target>
				</segment>
			</unit>
			<unit id="367" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee418463)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">[</data>
					<data id="id6">](https://msdn.microsoft.com/library/windows/desktop/ee418462)</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>Therefore, it implements the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2EngineCallback::OnProcessingPassStart</pc></pc> and <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2EngineCallback::OnProcessingPassEnd</pc></pc> methods to do nothing.</source>
					<target>Therefore, it implements the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2EngineCallback::OnProcessingPassStart</pc></pc> and <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">IXAudio2EngineCallback::OnProcessingPassEnd</pc></pc> methods to do nothing.</target>
				</segment>
			</unit>
			<unit id="368" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee418461)</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
					<data id="id5">**</data>
					<data id="id6">**</data>
					<data id="id7">**</data>
					<data id="id8">**</data>
				</originalData>
				<segment state="initial">
					<source>For the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2EngineCallback::OnCriticalError</pc></pc> method, Marble Maze calls the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">SetEngineExperiencedCriticalError</pc> method, which sets the <pc dataRefEnd="id8" dataRefStart="id7" id="p4">m\_engineExperiencedCriticalError</pc> flag.</source>
					<target>For the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IXAudio2EngineCallback::OnCriticalError</pc></pc> method, Marble Maze calls the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">SetEngineExperiencedCriticalError</pc> method, which sets the <pc dataRefEnd="id8" dataRefStart="id7" id="p4">m\_engineExperiencedCriticalError</pc> flag.</target>
				</segment>
			</unit>
			<unit id="369" translate="yes">
				<segment state="initial">
					<source>When a critical error occurs, audio processing stops and all additional calls to XAudio2 fail.</source>
					<target>When a critical error occurs, audio processing stops and all additional calls to XAudio2 fail.</target>
				</segment>
			</unit>
			<unit id="370" translate="yes">
				<segment state="initial">
					<source>To recover from this situation, you must release the XAudio2 instance and create a new one.</source>
					<target>To recover from this situation, you must release the XAudio2 instance and create a new one.</target>
				</segment>
			</unit>
			<unit id="371" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
					<data id="id3">**</data>
					<data id="id4">**</data>
				</originalData>
				<segment state="initial">
					<source>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::Render</pc> method, which is called from the game loop every frame, first checks the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">m\_engineExperiencedCriticalError</pc> flag.</source>
					<target>The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Audio::Render</pc> method, which is called from the game loop every frame, first checks the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">m\_engineExperiencedCriticalError</pc> flag.</target>
				</segment>
			</unit>
			<unit id="372" translate="yes">
				<segment state="initial">
					<source>If this flag is set, it clears the flag, releases the current XAudio2 instance, initializes resources, and then starts the background music.</source>
					<target>If this flag is set, it clears the flag, releases the current XAudio2 instance, initializes resources, and then starts the background music.</target>
				</segment>
			</unit>
			<unit id="373" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze also uses the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">m\_engineExperiencedCriticalError</pc> flag to guard against calling into XAudio2 when no audio device is available.</source>
					<target>Marble Maze also uses the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">m\_engineExperiencedCriticalError</pc> flag to guard against calling into XAudio2 when no audio device is available.</target>
				</segment>
			</unit>
			<unit id="374" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>For example, the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Update</pc> method does not process audio for rolling or collision events when this flag is set.</source>
					<target>For example, the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MarbleMaze::Update</pc> method does not process audio for rolling or collision events when this flag is set.</target>
				</segment>
			</unit>
			<unit id="375" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>The app attempts to repair the audio engine every frame if it is required; however, the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">m\_engineExperiencedCriticalError</pc> flag might always be set if the computer does not have an audio device or the headphones are unplugged and there is no other available audio device.</source>
					<target>The app attempts to repair the audio engine every frame if it is required; however, the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">m\_engineExperiencedCriticalError</pc> flag might always be set if the computer does not have an audio device or the headphones are unplugged and there is no other available audio device.</target>
				</segment>
			</unit>
			<unit id="376" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Caution</pc>   As a rule, do not perform blocking operations in the body of an engine callback.</source>
					<target><pc dataRefEnd="id2" dataRefStart="id1" id="p1">Caution</pc>   As a rule, do not perform blocking operations in the body of an engine callback.</target>
				</segment>
			</unit>
			<unit id="377" translate="yes">
				<segment state="initial">
					<source>Doing so can cause performance issues.</source>
					<target>Doing so can cause performance issues.</target>
				</segment>
			</unit>
			<unit id="378" translate="yes">
				<originalData>
					<data id="id1">**</data>
					<data id="id2">**</data>
				</originalData>
				<segment state="initial">
					<source>Marble Maze sets a flag in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">OnCriticalError</pc> callback and later handles the error during the regular audio processing phase.</source>
					<target>Marble Maze sets a flag in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">OnCriticalError</pc> callback and later handles the error during the regular audio processing phase.</target>
				</segment>
			</unit>
			<unit id="379" translate="yes">
				<originalData>
					<data id="id1">[</data>
					<data id="id2">](https://msdn.microsoft.com/library/windows/desktop/ee415745)</data>
				</originalData>
				<segment state="initial">
					<source>For more information about XAudio2 callbacks, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAudio2 Callbacks</pc>.</source>
					<target>For more information about XAudio2 callbacks, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAudio2 Callbacks</pc>.</target>
				</segment>
			</unit>
			<unit id="380" translate="yes">
				<segment state="initial">
					<source>Related topics</source>
					<target>Related topics</target>
				</segment>
			</unit>
			<unit id="381" translate="yes">
				<segment state="initial">
					<source>Adding input and interactivity to the Marble Maze sample</source>
					<target>Adding input and interactivity to the Marble Maze sample</target>
				</segment>
			</unit>
			<unit id="382" translate="yes">
				<segment state="initial">
					<source>Developing Marble Maze, a UWP game in C++ and DirectX</source>
					<target>Developing Marble Maze, a UWP game in C++ and DirectX</target>
				</segment>
			</unit>
		</group>
	</file>
</xliff>